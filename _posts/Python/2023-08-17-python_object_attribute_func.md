---
title: "ğŸ‘¨â€ğŸ’»ğŸÂ [Python] Object Attribute Function"
excerpt: "getattr, setattr, delattr, hasattr ì‚¬ìš©ë°©ë²•"
permalink: "/python/attribute_function"
toc: true  # option for table of contents
toc_sticky: true  # option for table of content
categories:
  - Python
tags:
  - Python
  - Object
  - Attribute
  - ML
  - Deep Learning
  
last_modified_at: 2023-08-17T12:00:00-05:00
---

### `ğŸ§§ Attribute Function`

ì´ë²ˆ í¬ìŠ¤íŒ…ì€ `Python` ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ì„œ ê°ì²´ì™€ ë‚´ë¶€ ë©”ì„œë“œì— ê´€ë ¨í•œ ì²˜ë¦¬ê°€ í•„ìš”í•  ë•Œ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ” `getattr`, `setattr` , `delattr` , `hasttr` í•¨ìˆ˜ë“¤ì˜ ì‚¬ìš©ë²•ì— ëŒ€í•´ ë‹¤ë¤„ë³´ë ¤ í•œë‹¤. íŠ¹íˆ `getattr`, `setattr` ì˜ ê²½ìš° ë¨¸ì‹ ëŸ¬ë‹ í˜¹ì€ ë”¥ëŸ¬ë‹ ê´€ë ¨ ì½”ë“œë¥¼ ì½ë‹¤ê°€ ì‹¬ì‹¬ì¹˜ ì•Šê²Œ ì°¾ì•„ë³¼ ìˆ˜ ìˆë‹¤. ëª¨ë¸ì˜ `hyper-parameter`ë¥¼ íŠœë‹í•˜ê±°ë‚˜ ê¸°íƒ€ ì‹¤í—˜ì„ í•  ë•Œ ì •ì˜í•œ ê°ì²´ì˜ ë³€ìˆ˜ í˜¹ì€ ë©”ì„œë“œì— ì‰½ê³  ê°„ê²°í•˜ê²Œ ì ‘ê·¼í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ê³  ìˆê¸° ë•Œë¬¸ì´ë‹¤.

#### **`ğŸ“Œ getattr`**

```python
""" getattr(object, attribute_name, default) """

class CFG:
    """--------[Common]--------"""
    wandb, train, competition, seed, cfg_name = True, True, 'UPPPM', 42, 'CFG'
    device, gpu_id = torch.device('cuda' if torch.cuda.is_available() else 'cpu'), 0
    num_workers = 0
    """ Mixed Precision, Gradient Check Point """
    amp_scaler = True
    gradient_checkpoint = True # save parameter
    output_dir = './output/'
    """ Clipping Grad Norm, Gradient Accumulation """
    clipping_grad = True # clip_grad_norm
    n_gradient_accumulation_steps = 1 # Gradient Accumulation
    max_grad_norm = n_gradient_accumulation_steps * 1000
    """ Model """
    model_name = 'microsoft/deberta-v3-large'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
#    pooling = 'attention'
    max_len = 512
    """ CV, Epoch, Batch Size """
    n_folds = 4
    epochs = 180
    batch_size = 64
```

ìœ„ì˜ ê°ì²´ëŠ” ì‹¤ì œ ì œê°€ ìºê¸€ ëŒ€íšŒë¥¼ ì¤€ë¹„í•˜ë©´ì„œ ì‚¬ìš©í–ˆë˜ [`config.py`](http://config.py) ë¥¼ ê°€ì ¸ì™”ë‹¤. 

`getattr(object: object, attribute_name: str, default: Any)` í•¨ìˆ˜ëŠ” ì‚¬ìš©ìê°€ ì§€ì •í•œ ê°ì²´ì— ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•œ `attribute`ê°€ ì¡´ì¬í•˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³ , ì¡´ì¬í•œë‹¤ë©´ í•´ë‹¹ `attribute`ì˜ `value`ë¥¼ ë°˜í™˜í•œë‹¤. í•œí¸ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ `default`ë¡œ ì„¸íŒ…í•œ ê°’ì„ ë°˜í™˜í•œë‹¤.

```python
getattr(CFG, 'epochs', "This Attribute doesn't find")
getattr(CFG, 'MPL', "This Attribute doesn't find")
--------------- Result --------------- 
180
This Attribute doesn't find
```

`if-else` êµ¬ë¬¸ë³´ë‹¤ í›¨ì”¬ ê°„ê²°í•˜ê²Œ ê°ì²´ì˜ ë©”ì„œë“œì— ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•´ì¡Œìœ¼ë©°, `default` ê°’ì„ ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬ ë°›ê¸° ë•Œë¬¸ì— í´ë¼ì´ì–¸íŠ¸ê°€ ì§€ì •í•œ `attribute` ê°€ ê°ì²´ ë‚´ë¶€ì— ì—†ì–´ë„ `AttributeError` ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šì•„ ì˜ˆì™¸ ì²˜ë¦¬ë¥¼ ë³„ë„ë¡œ ì§€ì •í•  í•„ìš”ê°€ ì‚¬ë¼ì ¸ ì½”ë“œ ê°€ë…ì„± ë° ìœ ì§€ë³´ìˆ˜ì— ìš©ì´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.

```python
class Exmple:
    def __init__(self):
        self.test1 = 0
        self.test2 = 0
    def A(self):
        print("A")  
    def B(self):
        print("B")  
    def C(self):
        print("C")

if __name__ == '__main__':
    exmple = Exmple()
    class_list = ['A','B','C']

    for c in class_list:
        getattr(exmple, c)()
```

í•œí¸ `getattr()` ë’¤ì— ê´„í˜¸ë¥¼ í•˜ë‚˜ ë” ë¶™ì—¬ì„œ ì‚¬ìš©í•˜ê¸°ë„(ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹ í›ˆë ¨ ë£¨í”„ ì½”ë“œì— ì¢…ì¢… ë³´ì„) í•˜ëŠ”ë°,  í•´ë‹¹ ê´„í˜¸ëŠ” ì§€ì • `attribute` ì˜ í˜¸ì¶œì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ì“°ì¸ë‹¤. ì´ë²ˆ ì˜ˆì‹œì˜ ê°ì²´ ë‚´ë¶€ ë©”ì„œë“œë“¤ì€ í˜¸ì¶œì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆì§€ ì•Šê¸° ë•Œë¬¸ì— ê´„í˜¸ ì•ˆì„ ë¹„ì›Œë’€ë‹¤.

#### **`âœ‚ï¸ setattr`**

```python
""" setattr(object, attribute_name, value) """

class CFG:
    """--------[Common]--------"""
    wandb, train, competition, seed, cfg_name = True, True, 'UPPPM', 42, 'CFG'
    device, gpu_id = torch.device('cuda' if torch.cuda.is_available() else 'cpu'), 0
    num_workers = 0
    """ Mixed Precision, Gradient Check Point """
    amp_scaler = True
    gradient_checkpoint = True # save parameter
    output_dir = './output/'
    """ Clipping Grad Norm, Gradient Accumulation """
    clipping_grad = True # clip_grad_norm
    n_gradient_accumulation_steps = 1 # Gradient Accumulation
    max_grad_norm = n_gradient_accumulation_steps * 1000
    """ Model """
    model_name = 'microsoft/deberta-v3-large'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
#    pooling = 'attention'
    max_len = 512
    """ CV, Epoch, Batch Size """
    n_folds = 4
    epochs = 180
    batch_size = 64
```

`setattr(object: object, attribute_name: str, value: Any)` ëŠ” ì§€ì • ê°ì²´ì˜ ì§€ì • ë©”ì„œë“œ í˜¹ì€ ë³€ìˆ˜ì— ì ‘ê·¼í•˜ê³  ì œì–´í•˜ëŠ” ìš©ë„ë¡œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ë‹¤. ì§€ì • ê°ì²´ ë‹¨ìœ„ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ëª¨ë¸ì„ íŠœë‹í•  ë•Œ ì •ë§ ë§ì´ ì‚¬ìš©í•˜ê²Œ ëœë‹¤. `setattr()` ë¥¼ í™œìš©í•´ ìƒí™©ì— ë§ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ëª¨ë¸ì— ì£¼ì…í•˜ê³  í•´ë‹¹ `config`ë¥¼ `json` í˜¹ì€ `yaml` í˜•ì‹ìœ¼ë¡œ ì €ì¥í•´ë‘ë©´ ëª¨ë¸ì˜ ë²„ì „ë³„ íŒŒë¼ë¯¸í„° ê°’ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆìœ¼ë‹ˆ ê¸°ì–µí•´ë‘ì.

```python
CFG.wandb
setattr(CFG, 'wandb', False)
CFG.wandb
setattr(CFG, 'wandb', True)
CFG.wandb

--------------- Result --------------- 
True
False
True
```

#### **`ğŸ“Œ hasattr`**

`hasattr(object, attribute_name)` ëŠ” ì§€ì • ê°ì²´ì— ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•œ `attribute` ê°€ ì¡´ì¬í•˜ë©´ `True`, ì—†ë‹¤ë©´ `False` ë¥¼ ë°˜í™˜í•œë‹¤. ì‚¬ìš©ë²•ì€ `getattr()` ì™€ ë§¤ìš° ìœ ì‚¬í•˜ê¸° ë•Œë¬¸ì— ìƒëµí•œë‹¤.

#### **`âœï¸ delattr`**

`delattr(object, attribute_name)` ëŠ” ì§€ì • ê°ì²´ì— ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•œ `attribute`ë¥¼ ê°ì²´ ë‚´ë¶€ì—ì„œ ì‚­ì œí•˜ëŠ” ì—­í• ì„ í•œë‹¤. ì‚¬ìš© ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

```python
delattr(CFG, 'epochs')
hasattr(CFG, 'epochs')

--------------- Result --------------- 
False
```

í•œí¸, ëª¨ë“ˆ(ex: config,py, model.py, model_utils.py ë“±)ë„ ê°ì²´ë¡œ ê°„ì£¼ë˜ê¸° ë•Œë¬¸ì— ìœ„ì—ì„œ ì‚´í´ë³¸ 4ê°€ì§€ functionì€ ëª¨ë“ˆ ë ˆë²¨ì—ì„œë„ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.