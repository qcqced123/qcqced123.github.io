<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>üßë‚Äçüè´ [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter - AI/Business Study Log</title>
<meta name="description" content="DistilBERT Official Paper Review with Pytorch Implementation">


  <meta name="author" content="qcqced">
  
  <meta property="article:author" content="qcqced">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AI/Business Study Log">
<meta property="og:title" content="üßë‚Äçüè´ [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter">
<meta property="og:url" content="http://localhost:4000/nlp/distilbert">


  <meta property="og:description" content="DistilBERT Official Paper Review with Pytorch Implementation">







  <meta property="article:published_time" content="2024-03-11T00:00:00+09:00">



  <meta property="article:modified_time" content="2024-03-12T02:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/nlp/distilbert">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "qcqced",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="AI/Business Study Log Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<!-- Latex -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
<link rel="manifest" href="/assets/site.webmanifest">
<link rel="mask-icon" href="/assets/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          AI/Business Study Log
          <span class="site-subtitle">NLP, Marketing</span>
        </a>
        
        
        <ul class="visible-links">
              
              
                  <li class="masthead__menu-item">
                      <a href="https://qcqced123.github.io/">Home</a>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CS/AI  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/nlp/">    Natural Language Process</a>
                          
                              <a class = "dropdown-item" href="/multi-modal/">    Multi Modal</a>
                          
                              <a class = "dropdown-item" href="/cv/">    Computer Vision</a>
                          
                              <a class = "dropdown-item" href="/ml/">    Machine Learning</a>
                          
                              <a class = "dropdown-item" href="/framework-library/">    Framework & Library</a>
                          
                              <a class = "dropdown-item" href="/python/">    Python</a>
                          
                              <a class = "dropdown-item" href="/algorithm/">    Data Structure & Algorithm</a>
                          
                              <a class = "dropdown-item" href="/ps/">    Problem Solving</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Math  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/linear-algebra/">    Linear Algebra</a>
                          
                              <a class = "dropdown-item" href="/optimization-theory/">    Optimization Theory/Calculus</a>
                          
                              <a class = "dropdown-item" href="/signal-system/">    Signal & System</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Business/Marketing  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/device/">    Device</a>
                          
                              <a class = "dropdown-item" href="/semi-conductor/">    Semi-Conductor</a>
                          
                              <a class = "dropdown-item" href="/ai/">    AI</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/categories/">Category</a>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/about/">About</a>
                  </li>
              
          
       </ul>
       
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/huggingface_emoji.png" alt="qcqced" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">qcqced</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in NLP, Marketing</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Seoul, South Korea</span>
        </li>
      

      
        
          
            <li><a href="https://qcqced123.github.io" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
          
            <li><a href="https://github.com/qcqced123" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.kaggle.com/qcqced" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-kaggle" aria-hidden="true"></i><span class="label">Kaggle</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:qcqced123@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="qcqced123@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="üßë‚Äçüè´ [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter">
    <meta itemprop="description" content="DistilBERT Official Paper Review with Pytorch Implementation">
    <meta itemprop="datePublished" content="2024-03-11T00:00:00+09:00">
    <meta itemprop="dateModified" content="2024-03-12T02:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/nlp/distilbert" class="u-url" itemprop="url">üßë‚Äçüè´ [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter
</a>
          </h1>
          <p class="page__date">
            <a href="https://hits.seeyoufarm.com/localhost:4000/nlp/distilbert"target="_blank">
              <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://localhost:4000/nlp/distilbert&count_bg=%23399DE2&title_bg=%236D6D6D&icon=pytorch.svg&icon_color=%23E7E7E7&title=Views&edge_flat=false"/>
            </a>
            <i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2024-03-11T00:00:00+09:00">March 11, 2024</time>
            <!-- <div style="text-align: left;"> -->
            <!-- </div> -->
          </p>
          
          
        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#overview">üî≠¬†Overview</a></li><li><a href="#knowledge-distillations">üì≤¬†Knowledge Distillations</a><ul><li><a href="#distillation-loss-kl-divergence-loss">ü™¢¬†Distillation Loss: KL-Divergence Loss</a></li><li><a href="#student-loss-mlm-loss">üßë‚Äçüéì¬†Student Loss: MLM Loss</a></li><li><a href="#cosine-embedding-loss-contrastive-loss-by-cosine-similarity">üåÜ¬†Cosine Embedding Loss: Contrastive Loss by cosine similarity</a></li></ul></li><li><a href="#implementation-by-pytorch">üë©‚Äçüíª¬†Implementation by Pytorch</a><ul><li><a href="#knowledge-distillation-pipeline">üë©‚Äçüíª¬†Knowledge Distillation Pipeline</a></li><li><a href="#knowledge-distillation-model">üë©‚Äçüíª¬†Knowledge Distillation Model</a></li><li><a href="#distilbert-model">üë©‚Äçüíª¬†DistilBERT Model</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <h3 id="overview"><code class="language-plaintext highlighter-rouge">üî≠¬†Overview</code></h3>

<p><code class="language-plaintext highlighter-rouge">DistilBERT</code> Îäî ÌóàÍπÖ ÌéòÏù¥Ïä§ Ïó∞Íµ¨ÏßÑÏù¥ 2019ÎÖÑ Î∞úÌëúÌïú BERTÏùò Î≥ÄÌòïÏúºÎ°úÏÑú, On-Device Ai Í∞úÎ∞úÏùÑ Î™©ÌëúÎ°ú Í≤ΩÎüâÌôîÏóê Ï¥àÏ†êÏùÑ ÎßûÏ∂ò Î™®Îç∏Ïù¥Îã§. GPT, BERTÏùò Îì±Ïû• Ïù¥ÌõÑ, NLP Î∂ÑÏïºÏóêÏÑú ÎπÑÏïΩÏ†ÅÏù∏ ÏÑ±Îä• Ìñ•ÏÉÅÏù¥ Ïù¥Î§ÑÏ°åÏùåÏóêÎèÑ Î∂àÍµ¨ÌïòÍ≥†, ÌÑ∞Î¨¥Îãà ÏóÜÎäî Î™®Îç∏ ÏÇ¨Ïù¥Ï¶àÏôÄ Ïª¥Ìì®ÌåÖ Î¶¨ÏÜåÏä§ ÏöîÍµ¨Î°ú Ïù∏Ìï¥ Ïã§ÏÉùÌôú Ï†ÅÏö© Í∞ôÏùÄ ÌôúÏö©ÏÑ±ÏùÄ Ïó¨Ï†ÑÌûà Ìï¥Í≤∞Ìï¥ÏïºÌï† Î¨∏Ï†úÎ°ú ÎÇ®ÏïÑ ÏûàÏóàÎã§. GoogleÏóêÏÑú Î∞úÌëúÌïú Ï¥àÍ∏∞ <code class="language-plaintext highlighter-rouge">BERT-base-uncased</code> Îßå Ìï¥ÎèÑ ÌååÎùºÎØ∏ÌÑ∞Í∞Ä 1Ïñµ 1Ï≤úÎßåÍ∞ú ÏàòÏ§ÄÏóê Îã¨ÌïúÎã§.</p>

<p>Ïù¥Î•º Îã§ÏñëÌïú ÎπÑÏ¶àÎãàÏä§ ÏöîÍµ¨ ÏÉÅÌô©Ïóê Ï†ÅÏö©Ìï† Ïàò ÏûàÏúºÎ†§Î©¥ ÏµúÏÜåÌïú 8GB Ïù¥ÏÉÅÏùò Í∞ÄÏÜçÍ∏∞ Ï†ÑÏö© RAM Í≥µÍ∞ÑÏùÑ ÏöîÍµ¨Î°ú ÌïúÎã§. Ïò§ÎäòÎÇ† Í∞úÏù∏Ïö© PC ÌòπÏùÄ ÏÑúÎ≤Ñ Ïª¥Ìì®ÌÑ∞Ïùò Í≤ΩÏö∞, 8GB Ïù¥ÏÉÅÏùò VRAMÏù¥ Îã¨Î¶∞ GPUÍ∞Ä ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÌÉëÏû¨ÎêòÍ∏∞ ÎïåÎ¨∏Ïóê ÌÅ¨Í≤å Î¨∏Ï†ú Îê† Í≤É ÏóÜÎäî ÏöîÍµ¨ÏÇ¨Ìï≠Ïù¥ÏßÄÎßå, On-Device ÌôòÍ≤ΩÏóêÏÑúÎäî Ïù¥ÏïºÍ∏∞Í∞Ä Îã¨ÎùºÏßÑÎã§. ÏµúÏã† ÌïòÏù¥ÏóîÎìú Ïä§ÎßàÌä∏Ìè∞Ïù∏ Galaxy S24 Ultra, iPhone 15 ProÏùò Í≤ΩÏö∞ 12GB, 8GBÏùò Îû® Ïö©ÎüâÏùÑ Î≥¥Ïú†ÌïòÍ≥† ÏûàÎã§. Í∑∏ÎßàÏ†ÄÎèÑ ÎåÄÎ∂ÄÎ∂ÑÏùò Ïò®ÎîîÎ∞îÏù¥Ïä§ ÌôòÍ≤ΩÏùÄ SoC Íµ¨Ï°∞Î•º Ï±ÑÌÉùÌïòÍ≥† ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê Ï†ÑÏö© Í∞ÄÏÜçÍ∏∞Í∞Ä Ïò®Ï†ÑÌûà Ï†Ä Î™®Îì† Îû® Í≥µÍ∞ÑÏùÑ ÌôúÏö©Ìï† Ïàò ÏóÜÎã§.</p>

<p>Îî∞ÎùºÏÑú Ïò®ÎîîÎ∞îÏù¥Ïä§Ïóê AiÎ•º Ï†ÅÏö©ÌïòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî ÌöçÍ∏∞Ï†ÅÏù∏ Î™®Îç∏ Í≤ΩÎüâÌôîÍ∞Ä ÌïÑÏöîÌïú ÏÉÅÌô©Ïù¥Í≥† Í∑∏ Ï∂úÎ∞úÏ†êÏù¥ Îêú Ïó∞Íµ¨Í∞Ä Î∞îÎ°ú <code class="language-plaintext highlighter-rouge">DistilBERT</code>Îã§. Î°úÏª¨ ÎîîÎ∞îÏù¥Ïä§ ÌôòÍ≤ΩÏóêÏÑúÎèÑ Ïñ∏Ïñ¥ Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÍ∏∞ ÏúÑÌï¥ ÌóàÍπÖ ÌéòÏù¥Ïä§ Ïó∞Íµ¨ÏßÑÏùÄ ÏßÄÏãù Ï¶ùÎ•ò Í∏∞Î≤ïÏùÑ ÌôúÏö©Ìï¥ Ïù∏ÏΩîÎçî Í∏∞Î∞ò Ïñ∏Ïñ¥ Î™®Îç∏Ïùò ÌååÎùºÎØ∏ÌÑ∞Î•º ÌöçÍ∏∞Ï†ÅÏúºÎ°ú Ï§ÑÏù¥ÎäîÎç∞ ÏÑ±Í≥µÌïúÎã§.</p>

<p>Ï†ïÎ¶¨ÌïòÏûêÎ©¥, <code class="language-plaintext highlighter-rouge">DistilBERT</code> Î™®Îç∏ÏùÄ Í∏∞Ï°¥ BERTÏùò Íµ¨Ï°∞Ï†Å Ï∏°Î©¥ Í∞úÏÑ†Ïù¥ ÏïÑÎãå, ÏÇ¨Ï†ÑÌïôÏäµ Î∞©Î≤ï ÌäπÌûà Í≤ΩÎüâÌôîÏóê Ï¥àÏ†êÏùÑ ÎßûÏ∂ò ÏãúÎèÑÎùºÍ≥† Î≥º Ïàò ÏûàÎã§. Îî∞ÎùºÏÑú Ïñ¥Îñ§ Î™®Îç∏Ïù¥ÎçîÎùºÎèÑ, Ïù∏ÏΩîÎçî Ïñ∏Ïñ¥ Î™®Îç∏Ïù¥ÎùºÎ©¥ Î™®Îëê <code class="language-plaintext highlighter-rouge">DistilBERT</code> Íµ¨Ï°∞Î•º ÏÇ¨Ïö©Ìï† Ïàò ÏûàÏúºÎ©∞, Í∏∞Ï°¥ ÎÖºÎ¨∏ÏóêÏÑúÎäî ÏõêÎ≥∏ BERT Íµ¨Ï°∞Î•º ÏÇ¨Ïö©ÌñàÎã§. Ïù¥Î≤à Ìè¨Ïä§ÌåÖÏóêÏÑúÎèÑ BERT Íµ¨Ï°∞Ïóê ÎåÄÌïú ÏÑ§Î™Ö ÎåÄÏã†, <code class="language-plaintext highlighter-rouge">DistilBERT</code>Ïùò ÏÇ¨Ï†Ñ ÌïôÏäµ Î∞©Î≤ïÎ°†Ïù∏ <code class="language-plaintext highlighter-rouge">Knowledge Distillation</code>Ïóê ÎåÄÌï¥ÏÑúÎßå Îã§Î£®Î†§Í≥† ÌïúÎã§.</p>

<h3 id="knowledge-distillations"><code class="language-plaintext highlighter-rouge">üì≤¬†Knowledge Distillations</code></h3>

\[\min_{\theta}\sum_{x \in X} \alpha \mathcal{L}_{\text{KL}}(x, \theta) + \beta \mathcal{L}_{\text{MLM}}(x, \theta) + \gamma \mathcal{L}_{\text{Cos}}(x, \theta)\]

<p><code class="language-plaintext highlighter-rouge">DistilBERT</code>Îäî Teacher-Student ArchitectureÎ•º Ï∞®Ïö©Ìï¥ ÏÉÅÎåÄÏ†ÅÏúºÎ°ú ÏûëÏùÄ ÌååÎùºÎØ∏ÌÑ∞ ÏÇ¨Ïù¥Ï¶àÎ•º Í∞ñÎäî <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏ÏóêÍ≤å <code class="language-plaintext highlighter-rouge">Teacher</code>Ïùò ÏßÄÏãùÏùÑ Ï†ÑÏàòÌïòÎäî Í≤ÉÏùÑ Î™©ÌëúÎ°ú ÌïúÎã§. Îî∞ÎùºÏÑú <code class="language-plaintext highlighter-rouge">Teacher</code> Î™®Îç∏ÏùÄ Ïù¥ÎØ∏ ÏÇ¨Ï†Ñ ÌïôÏäµÏùÑ ÎßàÏπòÍ≥† ÏàòÎ†¥Îêú ÏÉÅÌÉúÏùò Í∞ÄÏ§ëÏπòÎ•º Í∞ñÍ≥† ÏûàÎäî Î™®Îç∏ÏùÑ ÏÇ¨Ïö©Ìï¥Ïïº ÌïúÎã§. ÎçîÎ∂àÏñ¥ Teacher Î™®Îç∏ÏùÄ Íµ¨Ï°∞Îßå Í∏∞Ï°¥ BERTÎ•º Îî∞Î•¥Îêò, ÏÇ¨Ï†Ñ ÌïôÏäµ Î∞©ÏãùÏùÄ RoBERTaÏùò Î∞©ÏãùÍ≥º ÎèôÏùº(NSP Ï†úÍ±∞, Dynamic Masking Ï†ÅÏö©)ÌïòÍ≤å ÌõàÎ†®ÎêòÏñ¥Ïïº ÌïúÎã§.</p>

<p>ÌïúÌé∏, <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏ÏùÄ <code class="language-plaintext highlighter-rouge">Teacher</code>Ïùò 60%Ï†ïÎèÑ ÌååÎùºÎØ∏ÌÑ∞ ÏÇ¨Ïù¥Ï¶àÎ•º Í∞ñÎèÑÎ°ù Ï∂ïÏÜåÌïòÏó¨ ÏÇ¨Ïö©ÌïúÎã§. Ïù¥ Îïå Ï∂ïÏÜåÎäî Î™®Îç∏Ïùò <code class="language-plaintext highlighter-rouge">depth</code>(Î†àÏù¥Ïñ¥ Í∞úÏàò)ÏóêÎßå Ï†ÅÏö©ÌïòÎäîÎç∞, Ïó∞Íµ¨ÏßÑÏóê Îî∞Î•¥Î©¥ <code class="language-plaintext highlighter-rouge">width</code>(ÏùÄÎãâÏ∏µ ÌÅ¨Í∏∞)Îäî Ï∂ïÏÜåÎ•º Ï†ÅÏö©Ìï¥ÎèÑ Ïó∞ÏÇ∞ Ìö®Ïú®Ïù¥ Ï¶ùÍ∞ÄÌïòÏßÄ ÏïäÎäîÎã§Í≥† ÌïúÎã§. Ï†ïÎ¶¨ÌïòÎ©¥ <code class="language-plaintext highlighter-rouge">Teacher</code> Î™®Îç∏Ïùò <code class="language-plaintext highlighter-rouge">Î†àÏù¥Ïñ¥ Í∞úÏàò*0.6</code>Ïùò Í∞úÏàòÎßåÌÅº Ïù∏ÏΩîÎçîÎ•º ÏåìÏúºÎ©¥ ÎêúÎã§Îäî Í≤ÉÏù¥Îã§.</p>

<p>Í∑∏Î¶¨Í≥† ÏµúÎåÄÌïú <code class="language-plaintext highlighter-rouge">Teacher</code>Ïùò ÏßÄÏãùÏùÑ Ï†ÑÏàòÌï¥Ïïº ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê, Îç∞Ïù¥ÌÑ∞Îäî <code class="language-plaintext highlighter-rouge">Teacher</code> Î•º ÏàòÎ†¥ÏãúÌÇ® Í≤ÉÍ≥º ÎèôÏùºÌïú ÏÑ∏Ìä∏Î•º Ïù¥Ïö©Ìï¥Ïïº ÌïúÎã§. Ïù¥ Îïå, Teacher Î™®Îç∏ÏùÄ Ïù¥ÎØ∏ MLE Î∞©ÏãùÏúºÎ°ú ÌõàÎ†®Ïù¥ Îêú ÏÉÅÌÉúÎùºÏÑú Î°úÏßìÏù¥ Îã®Ïùº ÌÜ†ÌÅ∞ ÌïòÎÇò Ï™ΩÏúºÎ°ú Ïè†Î†§ ÏûàÏùÑ Í∞ÄÎä•ÏÑ±Ïù¥ Îß§Ïö∞ ÎÜíÎã§. Ïù¥Îäî <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏Ïùò ÏùºÎ∞òÌôî Îä•Î†•Ïóê ÏïÖÏòÅÌñ•ÏùÑ ÎØ∏Ïπ† Í∞ÄÎä•ÏÑ±Ïù¥ ÎÜíÎã§. Îî∞ÎùºÏÑú Temperature Î≥ÄÏàò $T$ ÎèÑÏûÖÌï¥ ÏÜåÌîÑÌä∏ Îß•Ïä§(Î°úÏßì)Ïùò Î∂ÑÌè¨Î•º ÌèâÌÉÑÌôî ÌïúÎã§. Ïù¥Î†áÍ≤å ÌïòÎ©¥, <code class="language-plaintext highlighter-rouge">argmax()</code> Í∞Ä ÏïÑÎãå Îã§Î•∏ ÌÜ†ÌÅ∞ ÌëúÌòÑÏóê ÎåÄÌï¥ÏÑúÎèÑ <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏Ïù¥ ÏßÄÏãùÏùÑ ÏäµÎìùÌï† Ïàò ÏûàÏñ¥ÏÑú ÌíçÎ∂ÄÌïú Î¨∏Îß•ÏùÑ ÌïôÏäµÌïòÍ≥† ÏùºÎ∞òÌôî Îä•Î†•ÏùÑ ÎÜíÏù¥ÎäîÎç∞ ÎèÑÏõÄÏù¥ ÎêúÎã§. Ïù¥Î•º <code class="language-plaintext highlighter-rouge">ÏïîÌùë ÏßÄÏãù(Dark Knowledge)</code> ÏùÑ ÌôúÏö©ÌïúÎã§Í≥† ÌëúÌòÑÌïúÎã§. Temperature Î≥ÄÏàò $T$ ÎèÑÏûÖÌïú ÏÜåÌîÑÌä∏Îß•Ïä§ Ìï®Ïàò ÏàòÏãùÏùÄ ÏïÑÎûòÏôÄ Í∞ôÎã§.</p>

\[\text{softmax}(x_i) = \frac{e^{\frac{x_i}{\tau}}}{\sum_{j} e^{\frac{x_j}{\tau}}}\]

<p>ÏàòÏãùÏÉÅ Î≥ÄÏàò $T$Ïùò Í∞íÏùÑ 1Ïù¥ÏÉÅÏúºÎ°ú ÏÑ∏ÌåÖÌï¥Ïïº ÌèâÌÉÑÌôîÎ•º Ìï† Ïàò ÏûàÎã§. Îî∞ÎùºÏÑú Ïó∞Íµ¨ÏßÑÏùÄ $T =2$ Î°ú ÎëêÍ≥† ÏÇ¨Ï†Ñ ÌïôÏäµÏùÑ ÏßÑÌñâÌñàÎã§(ÎÖºÎ¨∏Ïóê Í≥µÍ∞úÏïàÎê®, GitHubÏóê ÏûàÏùå). Ïù¥Î≤à ÌååÌä∏ Îß® Ï≤òÏùåÏóê Îì±Ïû•Ìïú ÏàòÏãùÏùÑ Îã§Ïãú Î≥¥Ïûê. Í≤∞Íµ≠ <code class="language-plaintext highlighter-rouge">DisilBERT</code>Ïùò Î™©Ï†ÅÌï®ÏàòÎäî 3Í∞ÄÏßÄ ÏÜêÏã§Ïùò Í∞ÄÏ§ëÌï©ÏúºÎ°ú Íµ¨ÏÑ±ÎêúÎã§. Ïù¥Ï†úÎ∂ÄÌÑ∞Îäî Í∞úÎ≥Ñ ÏÜêÏã§Ïóê ÎåÄÌï¥ÏÑú ÏûêÏÑ∏Ìûà ÏÇ¥Ìé¥Î≥¥Ïûê.</p>

<h4 id="distillation-loss-kl-divergence-loss"><code class="language-plaintext highlighter-rouge">ü™¢¬†Distillation Loss: KL-Divergence Loss</code></h4>

\[\text{KL-Divergence}(P || Q) = \sum_{i} P(i) \log \frac{P(i)}{Q(i)}\]

<p>Ï¶ùÎ•ò ÏÜêÏã§Î°ú ÏÇ¨Ïö©ÎêòÎäî <code class="language-plaintext highlighter-rouge">KL-Divergence Loss</code>Îäî Îëê ÌôïÎ•† Î∂ÑÌè¨ Í∞ÑÏùò Ï∞®Ïù¥Î•º Ï∏°Ï†ïÌïòÎäî ÏßÄÌëú Ï§ë ÌïòÎÇòÎã§. Ï£ºÎ°ú ÌôïÎ•† Î∂ÑÌè¨ PÏôÄ Q ÏÇ¨Ïù¥Ïùò Ï∞®Ïù¥Î•º ÎÇòÌÉÄÎÇ¥ÎäîÎç∞, Í∞úÎ≥Ñ ÏöîÏÜåÏùò ÌôïÎ•†Í∞í Ï∞®Ïù¥Í∞Ä ÌÅ¥ÏàòÎ°ù Ìï©ÏÇ∞Í∞íÏùÄ Ïª§Ï†∏ ÏÜêÏã§Ïù¥ Ïª§ÏßÄÍ≤å ÎêúÎã§. Î∞òÎåÄÎ°ú Îëê Î∂ÑÌè¨Ïùò Í∞úÎ≥Ñ ÏöîÏÜå ÌôïÎ•†Í∞í Ï∞®Ïù¥Í∞Ä ÏûëÎã§Î©¥ ÎãπÏó∞Ìûà, Îëê Î∂ÑÌè¨Í∞Ä Ïú†ÏÇ¨ÌïòÎã§Îäî ÏùòÎØ∏Ïù¥ÎØÄÎ°ú ÏÜêÏã§ Ïó≠Ïãú ÏûëÏïÑÏßÄÍ≤å ÎêúÎã§. ÏùºÎ∞òÏ†ÅÏúºÎ°ú <code class="language-plaintext highlighter-rouge">KL-Divergence Loss</code> ÏóêÏÑú ÌôïÎ•†Î∂ÑÌè¨ $P$ Í∞Ä Ïù¥ÏÉÅÏ†ÅÏù∏ ÌôïÎ•† Î∂ÑÌè¨Î•º, $Q$ Í∞Ä Î™®Îç∏Ïù¥ ÏòàÏ∏°Ìïú ÌôïÎ•†Î∂ÑÌè¨Î•º ÏùòÎØ∏ÌïúÎã§. Îî∞ÎùºÏÑú <code class="language-plaintext highlighter-rouge">DistilBERT</code>Ïùò Í≤ΩÏö∞ ÌôïÎ•†Î∂ÑÌè¨ $P$ ÏûêÎ¶¨ÏóêÎäî <code class="language-plaintext highlighter-rouge">Teacher</code> Î™®Îç∏Ïùò ÏÜåÌîÑÌä∏Îß•Ïä§ Î∂ÑÌè¨Í∞Ä, $Q$ ÏóêÎäî <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏Ïùò ÏÜåÌîÑÌä∏Îß•Ïä§ Î∂ÑÌè¨Í∞Ä ÎåÄÏûÖÎêòÎ©¥ ÎêúÎã§. Ïù¥ Îïå Îëê ÌôïÎ•†Î∂ÑÌè¨ Î™®Îëê, ÏïîÌùë ÏßÄÏãù ÌöçÎìùÏùÑ ÏúÑÌï¥ ÏÜåÌîÑÌä∏Îß•Ïä§ ÌèâÌÉÑÌôîÎ•º Ï†ÅÏö©Ìïú Í≤∞Í≥ºÎ•º ÏÇ¨Ïö©ÌïúÎã§. ÎÖºÎ¨∏ÏóêÏÑú, ÏÑ†ÏÉù Î™®Îç∏ ÏòàÏ∏°Ïóê ÌèâÌÉÑÌôîÎ•º Ï†ÅÏö©Ìïú Í≤ÉÏùÑ <code class="language-plaintext highlighter-rouge">ÏÜåÌîÑÌä∏ ÎùºÎ≤®</code>, ÌïôÏÉù Î™®Îç∏Ïùò Í≤ÉÏóê Ï†ÅÏö©Ìïú Í≤∞Í≥ºÎäî <code class="language-plaintext highlighter-rouge">ÏÜåÌîÑÌä∏ ÏòàÏ∏°</code>Ïù¥ÎùºÍ≥† Î∂ÄÎ•∏Îã§.</p>

<h4 id="student-loss-mlm-loss"><code class="language-plaintext highlighter-rouge">üßë‚Äçüéì¬†Student Loss: MLM Loss</code></h4>

\[\mathcal{L}_{\text{MLM}} = - \sum_{i=1}^{N} \sum_{j=1}^{L} \mathbb{1}_{m_{ij}} \log \text{softmax}(x_{ij})\]

<p>ÌïôÏÉù ÏÜêÏã§ÏùÄ ÎßêÍ∑∏ÎåÄÎ°ú Í∏∞Î≥∏Ï†ÅÏù∏ MLM ÏÜêÏã§ÏùÑ ÎßêÌïúÎã§. Ï†ïÌôïÌïú ÏÜêÏã§Í∞í Í≥ÑÏÇ∞ÏùÑ ÏúÑÌï¥ÏÑú ÌïôÏÉùÏùò ÏÜåÌîÑÌä∏Îß•Ïä§ Î∂ÑÌè¨Ïóê ÌèâÌÉÑÌôîÎ•º Ï†ÅÏö©ÌïòÏßÄ ÏïäÎäîÎã§. Ïù¥Î•º ÎÖºÎ¨∏ÏóêÏÑúÎäî <code class="language-plaintext highlighter-rouge">ÌïòÎìú ÏòàÏ∏°</code>Ïù¥ÎùºÍ≥† Î∂ÄÎ•∏Îã§. ÎùºÎ≤® Ïó≠Ïãú <code class="language-plaintext highlighter-rouge">Teacher</code>Î°úÎ∂ÄÌÑ∞ ÎÇòÏò® Í≤ÉÏù¥ ÏïÑÎãå ÏõêÎûò MLM ÏàòÌñâÏóê ÏÇ¨Ïö©ÎêòÎäî ÎßàÏä§ÌÇπ ÎùºÎ≤®ÏùÑ ÏÇ¨Ïö©ÌïúÎã§.</p>

<h4 id="cosine-embedding-loss-contrastive-loss-by-cosine-similarity"><code class="language-plaintext highlighter-rouge">üåÜ¬†Cosine Embedding Loss: Contrastive Loss by cosine similarity</code></h4>

\[\mathcal{L}_{\text{COS}}(x,y) = \begin{cases} 1 - \cos(x_1, x_2), &amp; \text{if } y = 1 \\ \max(0, \cos(x_1, x_2) - \text{margin}), &amp; \text{if } y = -1 \end{cases}\]

<p><code class="language-plaintext highlighter-rouge">Teacher</code> Î™®Îç∏Í≥º <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏Ïùò ÎßàÏßÄÎßâ Ïù∏ÏΩîÎçî Î™®Îç∏Ïù¥ Ï∂úÎ†•ÌïòÎäî ÏùÄÎãâÍ∞íÏóê ÎåÄÌïú <code class="language-plaintext highlighter-rouge">Contrastive Loss</code>Î•º ÏùòÎØ∏ÌïúÎã§. Ïù¥ Îïå <code class="language-plaintext highlighter-rouge">Distance Metric</code>ÏùÄ ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑÎ•º ÏÇ¨Ïö©ÌïúÎã§. Í∑∏ÎûòÏÑú ÏΩîÏÇ¨Ïù∏ ÏûÑÎ≤†Îî© ÏÜêÏã§Ïù¥ÎùºÍ≥† ÎÖºÎ¨∏ÏóêÏÑú Ï†ïÏùòÌïòÎäî Í≤ÉÏúºÎ°ú Ï∂îÏ†ïÎêúÎã§. ÏúÑ ÏàòÏãùÏùÑ ÏµúÏ†ÅÌôîÌïòÎäî Í≤ÉÏùÑ Î™©Ï†ÅÏúºÎ°ú ÌïúÎã§. Ïù¥ Îïå ÎùºÎ≤®ÏùÄ <code class="language-plaintext highlighter-rouge">[BS, Seq_len]</code>Ïùò ÌÅ¨Í∏∞Î•º Í∞ñÎêò, Î™®Îì† ÏõêÏÜåÎäî 1Ïù¥ ÎêòÎèÑÎ°ù ÎßåÎì†Îã§. Ïù¥Ïú†Îäî Í∞ÑÎã®ÌïòÎã§. <code class="language-plaintext highlighter-rouge">Student</code> Î™®Îç∏Ïùò ÏùÄÎãâÍ∞íÏù¥ <code class="language-plaintext highlighter-rouge">Teacher</code> Î™®Îç∏Ïùò Í≤ÉÍ≥º ÏµúÎåÄÌïú ÎπÑÏä∑Ìï¥ÏßÄÎèÑÎ°ù ÎßåÎìúÎäîÍ≤å Ïö∞Î¶¨ Î™©Ï†ÅÏù¥Í∏∞ ÎïåÎ¨∏Ïù¥Îã§.</p>

<h3 id="implementation-by-pytorch"><code class="language-plaintext highlighter-rouge">üë©‚Äçüíª¬†Implementation by Pytorch</code></h3>
<p>ÎÖºÎ¨∏Ïùò ÎÇ¥Ïö©Í≥º Ïò§ÌîºÏÖúÎ°ú Í≥µÍ∞úÎêú ÏΩîÎìúÎ•º Ï¢ÖÌï©ÌïòÏó¨ ÌååÏù¥ÌÜ†ÏπòÎ°ú <code class="language-plaintext highlighter-rouge">DistilBERT</code>Î•º Íµ¨ÌòÑÌï¥Î¥§Îã§. ÎÖºÎ¨∏Ïóê Ìè¨Ìï®Îêú ÏïÑÏù¥ÎîîÏñ¥Î•º Ïù¥Ìï¥ÌïòÎäîÎç∞Îäî Ïó≠Ïãú Ïñ¥Î†µÏßÄ ÏïäÏïòÏßÄÎßå, ÌéòÏù¥ÌçºÏóê hyper-param ÌÖåÏù¥Î∏îÏù¥ Îî∞Î°ú Ï†úÏãúÎêòÏñ¥ ÏûàÏßÄ ÏïäÏïÑ Í≥µÍ∞úÎêú ÏΩîÎìúÎ•º Ïïà Î≥ºÏàòÍ∞Ä ÏóÜÏóàÎã§.</p>

<p>Ï†ÑÏ≤¥ Î™®Îç∏ Íµ¨Ï°∞ ÎåÄÌïú ÏΩîÎìúÎäî <strong><a href="https://github.com/qcqced123/model_study">Ïó¨Í∏∞ ÎßÅÌÅ¨</a></strong>Î•º ÌÜµÌï¥ Ï∞∏Í≥†Î∞îÎûÄÎã§.</p>

<h4 id="knowledge-distillation-pipeline"><code class="language-plaintext highlighter-rouge">üë©‚Äçüíª¬†Knowledge Distillation Pipeline</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_val_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader_train</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">criterion</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">],</span> <span class="n">optimizer</span><span class="p">,</span><span class="n">scheduler</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
    <span class="s">""" Function for train loop with validation for each batch*N Steps
    DistillBERT has three loss:

        1) distillation loss, calculated by soft targets &amp; soft predictions
            (nn.KLDIVLoss(reduction='batchmean'))

        2) student loss, calculated by hard targets &amp; hard predictions
            (nn.CrossEntropyLoss(reduction='mean')), same as pure MLM Loss

        3) cosine similarity loss, calculated by student &amp; teacher logit similarity
            (nn.CosineEmbeddingLoss(reduction='mean')), similar as contrastive loss

    Those 3 losses are summed jointly and then backward to student model
    """</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">amp_scaler</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">loader_train</span><span class="p">)):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'labels'</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">padding_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'padding_mask'</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">padding_mask</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">dim_model</span><span class="p">)</span>  <span class="c1"># for hidden states dim
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">t_hidden_state</span><span class="p">,</span> <span class="n">soft_target</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">teacher_fw</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">padding_mask</span><span class="o">=</span><span class="n">padding_mask</span><span class="p">,</span>
                <span class="n">mask</span><span class="o">=</span><span class="n">mask</span>
            <span class="p">)</span>  <span class="c1"># teacher model's pred =&gt; hard logit
</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">amp_scaler</span><span class="p">):</span>
            <span class="n">s_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span><span class="p">,</span> <span class="n">soft_pred</span><span class="p">,</span> <span class="n">c_labels</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">student_fw</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">padding_mask</span><span class="o">=</span><span class="n">padding_mask</span><span class="p">,</span>
                <span class="n">mask</span><span class="o">=</span><span class="n">mask</span>
            <span class="p">)</span>
            <span class="n">d_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">[</span><span class="s">"KLDivLoss"</span><span class="p">](</span><span class="n">soft_pred</span><span class="p">.</span><span class="n">log</span><span class="p">(),</span> <span class="n">soft_target</span><span class="p">)</span>  <span class="c1"># nn.KLDIVLoss
</span>            <span class="n">s_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">[</span><span class="s">"CrossEntropyLoss"</span><span class="p">](</span><span class="n">s_logit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># nn.CrossEntropyLoss
</span>            <span class="n">c_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">[</span><span class="s">"CosineEmbeddingLoss"</span><span class="p">](</span><span class="n">s_hidden_state</span><span class="p">,</span> <span class="n">t_hidden_state</span><span class="p">,</span> <span class="n">c_labels</span><span class="p">)</span>  <span class="c1"># nn.CosineEmbeddingLoss
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">d_loss</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">alpha_distillation</span> <span class="o">+</span> <span class="n">s_loss</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">alpha_student</span> <span class="o">+</span> <span class="n">c_loss</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">alpha_cosine</span>  <span class="c1"># linear combination loss
</span>
        <span class="n">scaler</span><span class="p">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">).</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">scaler</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">scaler</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="knowledge-distillation-model"><code class="language-plaintext highlighter-rouge">üë©‚Äçüíª¬†Knowledge Distillation Model</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DistillationKnowledge</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">AbstractTask</span><span class="p">):</span>
    <span class="s">""" Custom Task Module for Knowledge Distillation by DistilBERT Style Architecture
    DistilBERT Style Architecture is Teacher-Student Framework for Knowledge Distillation,

    And then they have 3 objective functions:
        1) distillation loss, calculated by soft targets &amp; soft predictions
            (nn.KLDIVLoss(reduction='batchmean'))
        2) student loss, calculated by hard targets &amp; hard predictions
            (nn.CrossEntropyLoss(reduction='mean')), same as pure MLM Loss
        3) cosine similarity loss, calculated by student &amp; teacher logit similarity
            (nn.CosineEmbeddingLoss(reduction='mean')), similar as contrastive loss

    References:
        https://arxiv.org/pdf/1910.01108.pdf
        https://github.com/huggingface/transformers/blob/main/examples/research_projects/distillation/distiller.py
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CFG</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistillationKnowledge</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">CFG</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">DistilBERT</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">select_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">teacher_load_pretrained</span><span class="p">:</span>  <span class="c1"># for teacher model
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">checkpoint_dir</span> <span class="o">+</span> <span class="n">cfg</span><span class="p">.</span><span class="n">teacher_state_dict</span><span class="p">),</span>
                <span class="n">strict</span><span class="o">=</span><span class="bp">False</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">student_load_pretrained</span><span class="p">:</span>  <span class="c1"># for student model
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">student</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">checkpoint_dir</span> <span class="o">+</span> <span class="n">cfg</span><span class="p">.</span><span class="n">student_state_dict</span><span class="p">),</span>
                <span class="n">strict</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">freeze</span><span class="p">:</span>
            <span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher</span><span class="p">)</span>
            <span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">mlm_head</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">gradient_checkpoint</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">teacher_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">is_valid</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" teacher forward pass to make soft target, last_hidden_state for distillation loss """</span>
        <span class="c1"># 1) make soft target
</span>        <span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">is_valid</span> <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">t_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher_fw</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="o">~</span><span class="n">mask</span><span class="p">)</span>  <span class="c1"># for inverse select
</span>        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">dim_model</span><span class="p">)</span>  <span class="c1"># flatten last_hidden_state
</span>        <span class="n">soft_target</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">t_logit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># flatten softmax distribution
</span>            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># [bs* seq, vocab_size]
</span>        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">soft_target</span>

    <span class="k">def</span> <span class="nf">student_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">is_valid</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" student forward pass to make soft prediction, hard prediction for student loss """</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">is_valid</span> <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher_fw</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="o">~</span><span class="n">mask</span><span class="p">)</span>  <span class="c1"># for inverse select
</span>        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">dim_model</span><span class="p">)</span>  <span class="c1"># flatten last_hidden_state
</span>        <span class="n">c_labels</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)).</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">soft_pred</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">s_logit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># flatten softmax distribution
</span>            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span><span class="p">,</span> <span class="n">soft_pred</span><span class="p">,</span> <span class="n">c_labels</span>
</code></pre></div></div>

<h4 id="distilbert-model"><code class="language-plaintext highlighter-rouge">üë©‚Äçüíª¬†DistilBERT Model</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DistilBERT</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">AbstractModel</span><span class="p">):</span>
    <span class="s">""" Main class for DistilBERT Style Model, Teacher-Student Framework
    for Knowledge Distillation aim to lighter Large Scale LLM model. This model have 3 objective functions:

        1) distillation loss, calculated by soft targets &amp; soft predictions
            (nn.KLDIVLoss(reduction='batchmean'))

        2) student loss, calculated by hard targets &amp; hard predictions
            (nn.CrossEntropyLoss(reduction='mean')), same as pure MLM Loss

        3) cosine similarity loss, calculated by student &amp; teacher logit similarity
            (nn.CosineEmbeddingLoss(reduction='mean')), similar as contrastive loss

    soft targets &amp; soft predictions are meaning that logit are passed through softmax function applied with temperature T
    temperature T aim to flatten softmax layer distribution for making "Dark Knowledge" from teacher model

    hard targets &amp; hard predictions are meaning that logit are passed through softmax function without temperature T
    hard targets are same as just simple labels from MLM Collator returns for calculating cross entropy loss

    cosine similarity loss is calculated by cosine similarity between student &amp; teacher
    in official repo, they mask padding tokens for calculating cosine similarity, target for this task is 1
    cosine similarity is calculated by nn.CosineSimilarity() function, values are range to [-1, 1]

    you can select any other backbone model architecture for Teacher &amp; Student Model for knowledge distillation
    but, in original paper, BERT is used for Teacher Model &amp; Student
    and you must select pretrained model for Teacher Model, because Teacher Model is used for knowledge distillation,
    which is containing pretrained mlm head

    Do not pass gradient backward to teacher model!!
    (teacher model must be frozen or register_buffer to model or use no_grad() context manager)

    Args:
        cfg: configuration.CFG
        model_func: make model instance in runtime from config.json

    References:
        https://arxiv.org/pdf/1910.01108.pdf
        https://github.com/huggingface/transformers/blob/main/examples/research_projects/distillation/distiller.py
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CFG</span><span class="p">,</span> <span class="n">model_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistilBERT</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="n">model_func</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">teacher_num_layers</span><span class="p">)</span>  <span class="c1"># must be loading pretrained model containing mlm head
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span> <span class="o">=</span> <span class="n">MLMHead</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">)</span>  <span class="c1"># must be loading pretrained model's mlm head
</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">student</span> <span class="o">=</span> <span class="n">model_func</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">student_num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">s_mlm_head</span> <span class="o">=</span> <span class="n">MLMHead</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">teacher_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" forward pass for teacher model
        """</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">teacher</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">t_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">)</span>  <span class="c1"># hard logit =&gt; to make soft logit
</span>        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">t_logit</span>

    <span class="k">def</span> <span class="nf">student_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" forward pass for student model
        """</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">student</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">s_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">s_mlm_head</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">)</span>  <span class="c1"># hard logit =&gt; to make soft logit
</span>        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#bert" class="page__taxonomy-item p-category" rel="tag">BERT</a><span class="sep">, </span>
    
      <a href="/tags/#distilbert" class="page__taxonomy-item p-category" rel="tag">DistilBERT</a><span class="sep">, </span>
    
      <a href="/tags/#natural-language-process" class="page__taxonomy-item p-category" rel="tag">Natural Language Process</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">Pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#self-attention" class="page__taxonomy-item p-category" rel="tag">Self-Attention</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#nlp" class="page__taxonomy-item p-category" rel="tag">NLP</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-03-11">March 11, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%F0%9F%A7%91%E2%80%8D%F0%9F%8F%AB+%5BDistilBERT%5D+DistilBERT%2C+a+distilled+version+of+BERT%3A+smaller%2C+faster%2C+cheaper+and+lighter%20http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdistilbert" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdistilbert" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdistilbert" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/nlp/deberta_v3" class="pagination--pager" title="ü™¢¬†[DeBERTa-V3] DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing
">Previous</a>
    
    
      <a href="/nlp/electra" class="pagination--pager" title="üëÆ [ELECTRA] Pre-training Text Encoders as Discriminators Rather Than Generators
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/linear_attention" rel="permalink">üåÜ [Linear Attention] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 14 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Linear Attention Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/spanbert" rel="permalink">üóÇÔ∏è[SpanBERT] SpanBERT: Improving Pre-training by Representing and Predicting Spans
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 11 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">SpanBERT Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/roformer" rel="permalink">üé° [Roformer] RoFormer: Enhanced Transformer with Rotary Position Embedding
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 11 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Roformer Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/electra" rel="permalink">üëÆ [ELECTRA] Pre-training Text Encoders as Discriminators Rather Than Generators
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 11 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ELECTRA Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 qcqced. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'qcqced123/qcqced123.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
});
</script>

  </body>
</html>
