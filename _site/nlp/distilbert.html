<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>ğŸ§‘â€ğŸ« [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter - AI/Business Study Log</title>
<meta name="description" content="DistilBERT Official Paper Review with Pytorch Implementation">


  <meta name="author" content="qcqced">
  
  <meta property="article:author" content="qcqced">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AI/Business Study Log">
<meta property="og:title" content="ğŸ§‘â€ğŸ« [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter">
<meta property="og:url" content="http://localhost:4000/nlp/distilbert">


  <meta property="og:description" content="DistilBERT Official Paper Review with Pytorch Implementation">







  <meta property="article:published_time" content="2024-03-11T00:00:00+09:00">



  <meta property="article:modified_time" content="2024-03-12T02:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/nlp/distilbert">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "qcqced",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="AI/Business Study Log Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<!-- Latex -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
<link rel="manifest" href="/assets/site.webmanifest">
<link rel="mask-icon" href="/assets/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          AI/Business Study Log
          <span class="site-subtitle">NLP, Marketing</span>
        </a>
        
        
        <ul class="visible-links">
              
              
                  <li class="masthead__menu-item">
                      <a href="https://qcqced123.github.io/">Home</a>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CS/AI  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/nlp/">    Natural Language Process</a>
                          
                              <a class = "dropdown-item" href="/multi-modal/">    Multi Modal</a>
                          
                              <a class = "dropdown-item" href="/cv/">    Computer Vision</a>
                          
                              <a class = "dropdown-item" href="/ml/">    Machine Learning</a>
                          
                              <a class = "dropdown-item" href="/framework-library/">    Framework & Library</a>
                          
                              <a class = "dropdown-item" href="/python/">    Python</a>
                          
                              <a class = "dropdown-item" href="/algorithm/">    Data Structure & Algorithm</a>
                          
                              <a class = "dropdown-item" href="/ps/">    Problem Solving</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Math  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/linear-algebra/">    Linear Algebra</a>
                          
                              <a class = "dropdown-item" href="/optimization-theory/">    Optimization Theory/Calculus</a>
                          
                              <a class = "dropdown-item" href="/signal-system/">    Signal & System</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Business/Marketing  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/device/">    Device</a>
                          
                              <a class = "dropdown-item" href="/semi-conductor/">    Semi-Conductor</a>
                          
                              <a class = "dropdown-item" href="/ai/">    AI</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/categories/">Category</a>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/about/">About</a>
                  </li>
              
          
       </ul>
       
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/huggingface_emoji.png" alt="qcqced" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">qcqced</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in NLP, Marketing</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Seoul, South Korea</span>
        </li>
      

      
        
          
            <li><a href="https://qcqced123.github.io" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
          
            <li><a href="https://github.com/qcqced123" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.kaggle.com/qcqced" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-kaggle" aria-hidden="true"></i><span class="label">Kaggle</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:qcqced123@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="qcqced123@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="ğŸ§‘â€ğŸ« [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter">
    <meta itemprop="description" content="DistilBERT Official Paper Review with Pytorch Implementation">
    <meta itemprop="datePublished" content="2024-03-11T00:00:00+09:00">
    <meta itemprop="dateModified" content="2024-03-12T02:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/nlp/distilbert" class="u-url" itemprop="url">ğŸ§‘â€ğŸ« [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter
</a>
          </h1>
          <p class="page__date">
            <a href="https://hits.seeyoufarm.com/localhost:4000/nlp/distilbert"target="_blank">
              <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://localhost:4000/nlp/distilbert&count_bg=%23399DE2&title_bg=%236D6D6D&icon=pytorch.svg&icon_color=%23E7E7E7&title=Views&edge_flat=false"/>
            </a>
            <i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2024-03-11T00:00:00+09:00">March 11, 2024</time>
            <!-- <div style="text-align: left;"> -->
            <!-- </div> -->
          </p>
          
          
        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#overview">ğŸ”­Â Overview</a></li><li><a href="#knowledge-distillations">ğŸ“²Â Knowledge Distillations</a><ul><li><a href="#distillation-loss-kl-divergence-loss">ğŸª¢Â Distillation Loss: KL-Divergence Loss</a></li><li><a href="#student-loss-mlm-loss">ğŸ§‘â€ğŸ“Â Student Loss: MLM Loss</a></li><li><a href="#cosine-embedding-loss-contrastive-loss-by-cosine-similarity">ğŸŒ†Â Cosine Embedding Loss: Contrastive Loss by cosine similarity</a></li></ul></li><li><a href="#implementation-by-pytorch">ğŸ‘©â€ğŸ’»Â Implementation by Pytorch</a><ul><li><a href="#knowledge-distillation-pipeline">ğŸ‘©â€ğŸ’»Â Knowledge Distillation Pipeline</a></li><li><a href="#knowledge-distillation-model">ğŸ‘©â€ğŸ’»Â Knowledge Distillation Model</a></li><li><a href="#distilbert-model">ğŸ‘©â€ğŸ’»Â DistilBERT Model</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <h3 id="overview"><code class="language-plaintext highlighter-rouge">ğŸ”­Â Overview</code></h3>

<p><code class="language-plaintext highlighter-rouge">DistilBERT</code> ëŠ” í—ˆê¹… í˜ì´ìŠ¤ ì—°êµ¬ì§„ì´ 2019ë…„ ë°œí‘œí•œ BERTì˜ ë³€í˜•ìœ¼ë¡œì„œ, On-Device Ai ê°œë°œì„ ëª©í‘œë¡œ ê²½ëŸ‰í™”ì— ì´ˆì ì„ ë§ì¶˜ ëª¨ë¸ì´ë‹¤. GPT, BERTì˜ ë“±ì¥ ì´í›„, NLP ë¶„ì•¼ì—ì„œ ë¹„ì•½ì ì¸ ì„±ëŠ¥ í–¥ìƒì´ ì´ë¤„ì¡ŒìŒì—ë„ ë¶ˆêµ¬í•˜ê³ , í„°ë¬´ë‹ˆ ì—†ëŠ” ëª¨ë¸ ì‚¬ì´ì¦ˆì™€ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ ìš”êµ¬ë¡œ ì¸í•´ ì‹¤ìƒí™œ ì ìš© ê°™ì€ í™œìš©ì„±ì€ ì—¬ì „íˆ í•´ê²°í•´ì•¼í•  ë¬¸ì œë¡œ ë‚¨ì•„ ìˆì—ˆë‹¤. Googleì—ì„œ ë°œí‘œí•œ ì´ˆê¸° <code class="language-plaintext highlighter-rouge">BERT-base-uncased</code> ë§Œ í•´ë„ íŒŒë¼ë¯¸í„°ê°€ 1ì–µ 1ì²œë§Œê°œ ìˆ˜ì¤€ì— ë‹¬í•œë‹¤.</p>

<p>ì´ë¥¼ ë‹¤ì–‘í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ ìƒí™©ì— ì ìš©í•  ìˆ˜ ìˆìœ¼ë ¤ë©´ ìµœì†Œí•œ 8GB ì´ìƒì˜ ê°€ì†ê¸° ì „ìš© RAM ê³µê°„ì„ ìš”êµ¬ë¡œ í•œë‹¤. ì˜¤ëŠ˜ë‚  ê°œì¸ìš© PC í˜¹ì€ ì„œë²„ ì»´í“¨í„°ì˜ ê²½ìš°, 8GB ì´ìƒì˜ VRAMì´ ë‹¬ë¦° GPUê°€ ì¼ë°˜ì ìœ¼ë¡œ íƒ‘ì¬ë˜ê¸° ë•Œë¬¸ì— í¬ê²Œ ë¬¸ì œ ë  ê²ƒ ì—†ëŠ” ìš”êµ¬ì‚¬í•­ì´ì§€ë§Œ, On-Device í™˜ê²½ì—ì„œëŠ” ì´ì•¼ê¸°ê°€ ë‹¬ë¼ì§„ë‹¤. ìµœì‹  í•˜ì´ì—”ë“œ ìŠ¤ë§ˆíŠ¸í°ì¸ Galaxy S24 Ultra, iPhone 15 Proì˜ ê²½ìš° 12GB, 8GBì˜ ë¨ ìš©ëŸ‰ì„ ë³´ìœ í•˜ê³  ìˆë‹¤. ê·¸ë§ˆì €ë„ ëŒ€ë¶€ë¶„ì˜ ì˜¨ë””ë°”ì´ìŠ¤ í™˜ê²½ì€ SoC êµ¬ì¡°ë¥¼ ì±„íƒí•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì „ìš© ê°€ì†ê¸°ê°€ ì˜¨ì „íˆ ì € ëª¨ë“  ë¨ ê³µê°„ì„ í™œìš©í•  ìˆ˜ ì—†ë‹¤.</p>

<p>ë”°ë¼ì„œ ì˜¨ë””ë°”ì´ìŠ¤ì— Aië¥¼ ì ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” íšê¸°ì ì¸ ëª¨ë¸ ê²½ëŸ‰í™”ê°€ í•„ìš”í•œ ìƒí™©ì´ê³  ê·¸ ì¶œë°œì ì´ ëœ ì—°êµ¬ê°€ ë°”ë¡œ <code class="language-plaintext highlighter-rouge">DistilBERT</code>ë‹¤. ë¡œì»¬ ë””ë°”ì´ìŠ¤ í™˜ê²½ì—ì„œë„ ì–¸ì–´ ëª¨ë¸ì„ í™œìš©í•˜ê¸° ìœ„í•´ í—ˆê¹… í˜ì´ìŠ¤ ì—°êµ¬ì§„ì€ ì§€ì‹ ì¦ë¥˜ ê¸°ë²•ì„ í™œìš©í•´ ì¸ì½”ë” ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ íšê¸°ì ìœ¼ë¡œ ì¤„ì´ëŠ”ë° ì„±ê³µí•œë‹¤.</p>

<p>ì •ë¦¬í•˜ìë©´, <code class="language-plaintext highlighter-rouge">DistilBERT</code> ëª¨ë¸ì€ ê¸°ì¡´ BERTì˜ êµ¬ì¡°ì  ì¸¡ë©´ ê°œì„ ì´ ì•„ë‹Œ, ì‚¬ì „í•™ìŠµ ë°©ë²• íŠ¹íˆ ê²½ëŸ‰í™”ì— ì´ˆì ì„ ë§ì¶˜ ì‹œë„ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì–´ë–¤ ëª¨ë¸ì´ë”ë¼ë„, ì¸ì½”ë” ì–¸ì–´ ëª¨ë¸ì´ë¼ë©´ ëª¨ë‘ <code class="language-plaintext highlighter-rouge">DistilBERT</code> êµ¬ì¡°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ê¸°ì¡´ ë…¼ë¬¸ì—ì„œëŠ” ì›ë³¸ BERT êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆë‹¤. ì´ë²ˆ í¬ìŠ¤íŒ…ì—ì„œë„ BERT êµ¬ì¡°ì— ëŒ€í•œ ì„¤ëª… ëŒ€ì‹ , <code class="language-plaintext highlighter-rouge">DistilBERT</code>ì˜ ì‚¬ì „ í•™ìŠµ ë°©ë²•ë¡ ì¸ <code class="language-plaintext highlighter-rouge">Knowledge Distillation</code>ì— ëŒ€í•´ì„œë§Œ ë‹¤ë£¨ë ¤ê³  í•œë‹¤.</p>

<h3 id="knowledge-distillations"><code class="language-plaintext highlighter-rouge">ğŸ“²Â Knowledge Distillations</code></h3>

\[\min_{\theta}\sum_{x \in X} \alpha \mathcal{L}_{\text{KL}}(x, \theta) + \beta \mathcal{L}_{\text{MLM}}(x, \theta) + \gamma \mathcal{L}_{\text{Cos}}(x, \theta)\]

<p><code class="language-plaintext highlighter-rouge">DistilBERT</code>ëŠ” Teacher-Student Architectureë¥¼ ì°¨ìš©í•´ ìƒëŒ€ì ìœ¼ë¡œ ì‘ì€ íŒŒë¼ë¯¸í„° ì‚¬ì´ì¦ˆë¥¼ ê°–ëŠ” <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì—ê²Œ <code class="language-plaintext highlighter-rouge">Teacher</code>ì˜ ì§€ì‹ì„ ì „ìˆ˜í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ë”°ë¼ì„œ <code class="language-plaintext highlighter-rouge">Teacher</code> ëª¨ë¸ì€ ì´ë¯¸ ì‚¬ì „ í•™ìŠµì„ ë§ˆì¹˜ê³  ìˆ˜ë ´ëœ ìƒíƒœì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°–ê³  ìˆëŠ” ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤. ë”ë¶ˆì–´ Teacher ëª¨ë¸ì€ êµ¬ì¡°ë§Œ ê¸°ì¡´ BERTë¥¼ ë”°ë¥´ë˜, ì‚¬ì „ í•™ìŠµ ë°©ì‹ì€ RoBERTaì˜ ë°©ì‹ê³¼ ë™ì¼(NSP ì œê±°, Dynamic Masking ì ìš©)í•˜ê²Œ í›ˆë ¨ë˜ì–´ì•¼ í•œë‹¤.</p>

<p>í•œí¸, <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì€ <code class="language-plaintext highlighter-rouge">Teacher</code>ì˜ 60%ì •ë„ íŒŒë¼ë¯¸í„° ì‚¬ì´ì¦ˆë¥¼ ê°–ë„ë¡ ì¶•ì†Œí•˜ì—¬ ì‚¬ìš©í•œë‹¤. ì´ ë•Œ ì¶•ì†ŒëŠ” ëª¨ë¸ì˜ <code class="language-plaintext highlighter-rouge">depth</code>(ë ˆì´ì–´ ê°œìˆ˜)ì—ë§Œ ì ìš©í•˜ëŠ”ë°, ì—°êµ¬ì§„ì— ë”°ë¥´ë©´ <code class="language-plaintext highlighter-rouge">width</code>(ì€ë‹‰ì¸µ í¬ê¸°)ëŠ” ì¶•ì†Œë¥¼ ì ìš©í•´ë„ ì—°ì‚° íš¨ìœ¨ì´ ì¦ê°€í•˜ì§€ ì•ŠëŠ”ë‹¤ê³  í•œë‹¤. ì •ë¦¬í•˜ë©´ <code class="language-plaintext highlighter-rouge">Teacher</code> ëª¨ë¸ì˜ <code class="language-plaintext highlighter-rouge">ë ˆì´ì–´ ê°œìˆ˜*0.6</code>ì˜ ê°œìˆ˜ë§Œí¼ ì¸ì½”ë”ë¥¼ ìŒ“ìœ¼ë©´ ëœë‹¤ëŠ” ê²ƒì´ë‹¤.</p>

<p>ê·¸ë¦¬ê³  ìµœëŒ€í•œ <code class="language-plaintext highlighter-rouge">Teacher</code>ì˜ ì§€ì‹ì„ ì „ìˆ˜í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—, ë°ì´í„°ëŠ” <code class="language-plaintext highlighter-rouge">Teacher</code> ë¥¼ ìˆ˜ë ´ì‹œí‚¨ ê²ƒê³¼ ë™ì¼í•œ ì„¸íŠ¸ë¥¼ ì´ìš©í•´ì•¼ í•œë‹¤. ì´ ë•Œ, Teacher ëª¨ë¸ì€ ì´ë¯¸ MLE ë°©ì‹ìœ¼ë¡œ í›ˆë ¨ì´ ëœ ìƒíƒœë¼ì„œ ë¡œì§“ì´ ë‹¨ì¼ í† í° í•˜ë‚˜ ìª½ìœ¼ë¡œ ì ë ¤ ìˆì„ ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ë‹¤. ì´ëŠ” <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì— ì•…ì˜í–¥ì„ ë¯¸ì¹  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ë”°ë¼ì„œ Temperature ë³€ìˆ˜ $T$ ë„ì…í•´ ì†Œí”„íŠ¸ ë§¥ìŠ¤(ë¡œì§“)ì˜ ë¶„í¬ë¥¼ í‰íƒ„í™” í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´, <code class="language-plaintext highlighter-rouge">argmax()</code> ê°€ ì•„ë‹Œ ë‹¤ë¥¸ í† í° í‘œí˜„ì— ëŒ€í•´ì„œë„ <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì´ ì§€ì‹ì„ ìŠµë“í•  ìˆ˜ ìˆì–´ì„œ í’ë¶€í•œ ë¬¸ë§¥ì„ í•™ìŠµí•˜ê³  ì¼ë°˜í™” ëŠ¥ë ¥ì„ ë†’ì´ëŠ”ë° ë„ì›€ì´ ëœë‹¤. ì´ë¥¼ <code class="language-plaintext highlighter-rouge">ì•”í‘ ì§€ì‹(Dark Knowledge)</code> ì„ í™œìš©í•œë‹¤ê³  í‘œí˜„í•œë‹¤. Temperature ë³€ìˆ˜ $T$ ë„ì…í•œ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ë‹¤.</p>

\[\text{softmax}(x_i) = \frac{e^{\frac{x_i}{\tau}}}{\sum_{j} e^{\frac{x_j}{\tau}}}\]

<p>ìˆ˜ì‹ìƒ ë³€ìˆ˜ $T$ì˜ ê°’ì„ 1ì´ìƒìœ¼ë¡œ ì„¸íŒ…í•´ì•¼ í‰íƒ„í™”ë¥¼ í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì—°êµ¬ì§„ì€ $T =2$ ë¡œ ë‘ê³  ì‚¬ì „ í•™ìŠµì„ ì§„í–‰í–ˆë‹¤(ë…¼ë¬¸ì— ê³µê°œì•ˆë¨, GitHubì— ìˆìŒ). ì´ë²ˆ íŒŒíŠ¸ ë§¨ ì²˜ìŒì— ë“±ì¥í•œ ìˆ˜ì‹ì„ ë‹¤ì‹œ ë³´ì. ê²°êµ­ <code class="language-plaintext highlighter-rouge">DisilBERT</code>ì˜ ëª©ì í•¨ìˆ˜ëŠ” 3ê°€ì§€ ì†ì‹¤ì˜ ê°€ì¤‘í•©ìœ¼ë¡œ êµ¬ì„±ëœë‹¤. ì´ì œë¶€í„°ëŠ” ê°œë³„ ì†ì‹¤ì— ëŒ€í•´ì„œ ìì„¸íˆ ì‚´í´ë³´ì.</p>

<h4 id="distillation-loss-kl-divergence-loss"><code class="language-plaintext highlighter-rouge">ğŸª¢Â Distillation Loss: KL-Divergence Loss</code></h4>

\[\text{KL-Divergence}(P || Q) = \sum_{i} P(i) \log \frac{P(i)}{Q(i)}\]

<p>ì¦ë¥˜ ì†ì‹¤ë¡œ ì‚¬ìš©ë˜ëŠ” <code class="language-plaintext highlighter-rouge">KL-Divergence Loss</code>ëŠ” ë‘ í™•ë¥  ë¶„í¬ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œ ì¤‘ í•˜ë‚˜ë‹¤. ì£¼ë¡œ í™•ë¥  ë¶„í¬ Pì™€ Q ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ë°, ê°œë³„ ìš”ì†Œì˜ í™•ë¥ ê°’ ì°¨ì´ê°€ í´ìˆ˜ë¡ í•©ì‚°ê°’ì€ ì»¤ì ¸ ì†ì‹¤ì´ ì»¤ì§€ê²Œ ëœë‹¤. ë°˜ëŒ€ë¡œ ë‘ ë¶„í¬ì˜ ê°œë³„ ìš”ì†Œ í™•ë¥ ê°’ ì°¨ì´ê°€ ì‘ë‹¤ë©´ ë‹¹ì—°íˆ, ë‘ ë¶„í¬ê°€ ìœ ì‚¬í•˜ë‹¤ëŠ” ì˜ë¯¸ì´ë¯€ë¡œ ì†ì‹¤ ì—­ì‹œ ì‘ì•„ì§€ê²Œ ëœë‹¤. ì¼ë°˜ì ìœ¼ë¡œ <code class="language-plaintext highlighter-rouge">KL-Divergence Loss</code> ì—ì„œ í™•ë¥ ë¶„í¬ $P$ ê°€ ì´ìƒì ì¸ í™•ë¥  ë¶„í¬ë¥¼, $Q$ ê°€ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í™•ë¥ ë¶„í¬ë¥¼ ì˜ë¯¸í•œë‹¤. ë”°ë¼ì„œ <code class="language-plaintext highlighter-rouge">DistilBERT</code>ì˜ ê²½ìš° í™•ë¥ ë¶„í¬ $P$ ìë¦¬ì—ëŠ” <code class="language-plaintext highlighter-rouge">Teacher</code> ëª¨ë¸ì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¶„í¬ê°€, $Q$ ì—ëŠ” <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¶„í¬ê°€ ëŒ€ì…ë˜ë©´ ëœë‹¤. ì´ ë•Œ ë‘ í™•ë¥ ë¶„í¬ ëª¨ë‘, ì•”í‘ ì§€ì‹ íšë“ì„ ìœ„í•´ ì†Œí”„íŠ¸ë§¥ìŠ¤ í‰íƒ„í™”ë¥¼ ì ìš©í•œ ê²°ê³¼ë¥¼ ì‚¬ìš©í•œë‹¤. ë…¼ë¬¸ì—ì„œ, ì„ ìƒ ëª¨ë¸ ì˜ˆì¸¡ì— í‰íƒ„í™”ë¥¼ ì ìš©í•œ ê²ƒì„ <code class="language-plaintext highlighter-rouge">ì†Œí”„íŠ¸ ë¼ë²¨</code>, í•™ìƒ ëª¨ë¸ì˜ ê²ƒì— ì ìš©í•œ ê²°ê³¼ëŠ” <code class="language-plaintext highlighter-rouge">ì†Œí”„íŠ¸ ì˜ˆì¸¡</code>ì´ë¼ê³  ë¶€ë¥¸ë‹¤.</p>

<h4 id="student-loss-mlm-loss"><code class="language-plaintext highlighter-rouge">ğŸ§‘â€ğŸ“Â Student Loss: MLM Loss</code></h4>

\[\mathcal{L}_{\text{MLM}} = - \sum_{i=1}^{N} \sum_{j=1}^{L} \mathbb{1}_{m_{ij}} \log \text{softmax}(x_{ij})\]

<p>í•™ìƒ ì†ì‹¤ì€ ë§ê·¸ëŒ€ë¡œ ê¸°ë³¸ì ì¸ MLM ì†ì‹¤ì„ ë§í•œë‹¤. ì •í™•í•œ ì†ì‹¤ê°’ ê³„ì‚°ì„ ìœ„í•´ì„œ í•™ìƒì˜ ì†Œí”„íŠ¸ë§¥ìŠ¤ ë¶„í¬ì— í‰íƒ„í™”ë¥¼ ì ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ë¥¼ ë…¼ë¬¸ì—ì„œëŠ” <code class="language-plaintext highlighter-rouge">í•˜ë“œ ì˜ˆì¸¡</code>ì´ë¼ê³  ë¶€ë¥¸ë‹¤. ë¼ë²¨ ì—­ì‹œ <code class="language-plaintext highlighter-rouge">Teacher</code>ë¡œë¶€í„° ë‚˜ì˜¨ ê²ƒì´ ì•„ë‹Œ ì›ë˜ MLM ìˆ˜í–‰ì— ì‚¬ìš©ë˜ëŠ” ë§ˆìŠ¤í‚¹ ë¼ë²¨ì„ ì‚¬ìš©í•œë‹¤.</p>

<h4 id="cosine-embedding-loss-contrastive-loss-by-cosine-similarity"><code class="language-plaintext highlighter-rouge">ğŸŒ†Â Cosine Embedding Loss: Contrastive Loss by cosine similarity</code></h4>

\[\mathcal{L}_{\text{COS}}(x,y) = \begin{cases} 1 - \cos(x_1, x_2), &amp; \text{if } y = 1 \\ \max(0, \cos(x_1, x_2) - \text{margin}), &amp; \text{if } y = -1 \end{cases}\]

<p><code class="language-plaintext highlighter-rouge">Teacher</code> ëª¨ë¸ê³¼ <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì¸ì½”ë” ëª¨ë¸ì´ ì¶œë ¥í•˜ëŠ” ì€ë‹‰ê°’ì— ëŒ€í•œ <code class="language-plaintext highlighter-rouge">Contrastive Loss</code>ë¥¼ ì˜ë¯¸í•œë‹¤. ì´ ë•Œ <code class="language-plaintext highlighter-rouge">Distance Metric</code>ì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•œë‹¤. ê·¸ë˜ì„œ ì½”ì‚¬ì¸ ì„ë² ë”© ì†ì‹¤ì´ë¼ê³  ë…¼ë¬¸ì—ì„œ ì •ì˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •ëœë‹¤. ìœ„ ìˆ˜ì‹ì„ ìµœì í™”í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•œë‹¤. ì´ ë•Œ ë¼ë²¨ì€ <code class="language-plaintext highlighter-rouge">[BS, Seq_len]</code>ì˜ í¬ê¸°ë¥¼ ê°–ë˜, ëª¨ë“  ì›ì†ŒëŠ” 1ì´ ë˜ë„ë¡ ë§Œë“ ë‹¤. ì´ìœ ëŠ” ê°„ë‹¨í•˜ë‹¤. <code class="language-plaintext highlighter-rouge">Student</code> ëª¨ë¸ì˜ ì€ë‹‰ê°’ì´ <code class="language-plaintext highlighter-rouge">Teacher</code> ëª¨ë¸ì˜ ê²ƒê³¼ ìµœëŒ€í•œ ë¹„ìŠ·í•´ì§€ë„ë¡ ë§Œë“œëŠ”ê²Œ ìš°ë¦¬ ëª©ì ì´ê¸° ë•Œë¬¸ì´ë‹¤.</p>

<h3 id="implementation-by-pytorch"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ’»Â Implementation by Pytorch</code></h3>
<p>ë…¼ë¬¸ì˜ ë‚´ìš©ê³¼ ì˜¤í”¼ì…œë¡œ ê³µê°œëœ ì½”ë“œë¥¼ ì¢…í•©í•˜ì—¬ íŒŒì´í† ì¹˜ë¡œ <code class="language-plaintext highlighter-rouge">DistilBERT</code>ë¥¼ êµ¬í˜„í•´ë´¤ë‹¤. ë…¼ë¬¸ì— í¬í•¨ëœ ì•„ì´ë””ì–´ë¥¼ ì´í•´í•˜ëŠ”ë°ëŠ” ì—­ì‹œ ì–´ë µì§€ ì•Šì•˜ì§€ë§Œ, í˜ì´í¼ì— hyper-param í…Œì´ë¸”ì´ ë”°ë¡œ ì œì‹œë˜ì–´ ìˆì§€ ì•Šì•„ ê³µê°œëœ ì½”ë“œë¥¼ ì•ˆ ë³¼ìˆ˜ê°€ ì—†ì—ˆë‹¤.</p>

<p>ì „ì²´ ëª¨ë¸ êµ¬ì¡° ëŒ€í•œ ì½”ë“œëŠ” <strong><a href="https://github.com/qcqced123/model_study">ì—¬ê¸° ë§í¬</a></strong>ë¥¼ í†µí•´ ì°¸ê³ ë°”ë€ë‹¤.</p>

<h4 id="knowledge-distillation-pipeline"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ’»Â Knowledge Distillation Pipeline</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train_val_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loader_train</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">criterion</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">],</span> <span class="n">optimizer</span><span class="p">,</span><span class="n">scheduler</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
    <span class="s">""" Function for train loop with validation for each batch*N Steps
    DistillBERT has three loss:

        1) distillation loss, calculated by soft targets &amp; soft predictions
            (nn.KLDIVLoss(reduction='batchmean'))

        2) student loss, calculated by hard targets &amp; hard predictions
            (nn.CrossEntropyLoss(reduction='mean')), same as pure MLM Loss

        3) cosine similarity loss, calculated by student &amp; teacher logit similarity
            (nn.CosineEmbeddingLoss(reduction='mean')), similar as contrastive loss

    Those 3 losses are summed jointly and then backward to student model
    """</span>
    <span class="n">scaler</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="n">GradScaler</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">amp_scaler</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">step</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">loader_train</span><span class="p">)):</span>
        <span class="n">optimizer</span><span class="p">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'input_ids'</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'labels'</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">padding_mask</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s">'padding_mask'</span><span class="p">].</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="n">padding_mask</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">dim_model</span><span class="p">)</span>  <span class="c1"># for hidden states dim
</span>        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">t_hidden_state</span><span class="p">,</span> <span class="n">soft_target</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">teacher_fw</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">padding_mask</span><span class="o">=</span><span class="n">padding_mask</span><span class="p">,</span>
                <span class="n">mask</span><span class="o">=</span><span class="n">mask</span>
            <span class="p">)</span>  <span class="c1"># teacher model's pred =&gt; hard logit
</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">amp</span><span class="p">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">enabled</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">amp_scaler</span><span class="p">):</span>
            <span class="n">s_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span><span class="p">,</span> <span class="n">soft_pred</span><span class="p">,</span> <span class="n">c_labels</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">student_fw</span><span class="p">(</span>
                <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">padding_mask</span><span class="o">=</span><span class="n">padding_mask</span><span class="p">,</span>
                <span class="n">mask</span><span class="o">=</span><span class="n">mask</span>
            <span class="p">)</span>
            <span class="n">d_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">[</span><span class="s">"KLDivLoss"</span><span class="p">](</span><span class="n">soft_pred</span><span class="p">.</span><span class="n">log</span><span class="p">(),</span> <span class="n">soft_target</span><span class="p">)</span>  <span class="c1"># nn.KLDIVLoss
</span>            <span class="n">s_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">[</span><span class="s">"CrossEntropyLoss"</span><span class="p">](</span><span class="n">s_logit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">labels</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># nn.CrossEntropyLoss
</span>            <span class="n">c_loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">[</span><span class="s">"CosineEmbeddingLoss"</span><span class="p">](</span><span class="n">s_hidden_state</span><span class="p">,</span> <span class="n">t_hidden_state</span><span class="p">,</span> <span class="n">c_labels</span><span class="p">)</span>  <span class="c1"># nn.CosineEmbeddingLoss
</span>            <span class="n">loss</span> <span class="o">=</span> <span class="n">d_loss</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">alpha_distillation</span> <span class="o">+</span> <span class="n">s_loss</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">alpha_student</span> <span class="o">+</span> <span class="n">c_loss</span><span class="o">*</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">alpha_cosine</span>  <span class="c1"># linear combination loss
</span>
        <span class="n">scaler</span><span class="p">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">).</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">scaler</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
        <span class="n">scaler</span><span class="p">.</span><span class="n">update</span><span class="p">()</span>
        <span class="n">scheduler</span><span class="p">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div></div>

<h4 id="knowledge-distillation-model"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ’»Â Knowledge Distillation Model</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DistillationKnowledge</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">AbstractTask</span><span class="p">):</span>
    <span class="s">""" Custom Task Module for Knowledge Distillation by DistilBERT Style Architecture
    DistilBERT Style Architecture is Teacher-Student Framework for Knowledge Distillation,

    And then they have 3 objective functions:
        1) distillation loss, calculated by soft targets &amp; soft predictions
            (nn.KLDIVLoss(reduction='batchmean'))
        2) student loss, calculated by hard targets &amp; hard predictions
            (nn.CrossEntropyLoss(reduction='mean')), same as pure MLM Loss
        3) cosine similarity loss, calculated by student &amp; teacher logit similarity
            (nn.CosineEmbeddingLoss(reduction='mean')), similar as contrastive loss

    References:
        https://arxiv.org/pdf/1910.01108.pdf
        https://github.com/huggingface/transformers/blob/main/examples/research_projects/distillation/distiller.py
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CFG</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistillationKnowledge</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">CFG</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">DistilBERT</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">,</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">select_model</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">_init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">teacher_load_pretrained</span><span class="p">:</span>  <span class="c1"># for teacher model
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">checkpoint_dir</span> <span class="o">+</span> <span class="n">cfg</span><span class="p">.</span><span class="n">teacher_state_dict</span><span class="p">),</span>
                <span class="n">strict</span><span class="o">=</span><span class="bp">False</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">student_load_pretrained</span><span class="p">:</span>  <span class="c1"># for student model
</span>            <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">student</span><span class="p">.</span><span class="n">load_state_dict</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">checkpoint_dir</span> <span class="o">+</span> <span class="n">cfg</span><span class="p">.</span><span class="n">student_state_dict</span><span class="p">),</span>
                <span class="n">strict</span><span class="o">=</span><span class="bp">True</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">freeze</span><span class="p">:</span>
            <span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher</span><span class="p">)</span>
            <span class="n">freeze</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">mlm_head</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">gradient_checkpoint</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">gradient_checkpointing_enable</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">teacher_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">is_valid</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" teacher forward pass to make soft target, last_hidden_state for distillation loss """</span>
        <span class="c1"># 1) make soft target
</span>        <span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">is_valid</span> <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">t_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher_fw</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="o">~</span><span class="n">mask</span><span class="p">)</span>  <span class="c1"># for inverse select
</span>        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">dim_model</span><span class="p">)</span>  <span class="c1"># flatten last_hidden_state
</span>        <span class="n">soft_target</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">t_logit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># flatten softmax distribution
</span>            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>  <span class="c1"># [bs* seq, vocab_size]
</span>        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">soft_target</span>

    <span class="k">def</span> <span class="nf">student_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
        <span class="n">is_valid</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" student forward pass to make soft prediction, hard prediction for student loss """</span>
        <span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="k">if</span> <span class="n">is_valid</span> <span class="k">else</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">temperature</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">teacher_fw</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">masked_select</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">,</span> <span class="o">~</span><span class="n">mask</span><span class="p">)</span>  <span class="c1"># for inverse select
</span>        <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">dim_model</span><span class="p">)</span>  <span class="c1"># flatten last_hidden_state
</span>        <span class="n">c_labels</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">.</span><span class="n">new</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)).</span><span class="n">fill_</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">soft_pred</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">s_logit</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="o">/</span> <span class="n">temperature</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>  <span class="c1"># flatten softmax distribution
</span>            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span><span class="p">,</span> <span class="n">soft_pred</span><span class="p">,</span> <span class="n">c_labels</span>
</code></pre></div></div>

<h4 id="distilbert-model"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ’»Â DistilBERT Model</code></h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">DistilBERT</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">AbstractModel</span><span class="p">):</span>
    <span class="s">""" Main class for DistilBERT Style Model, Teacher-Student Framework
    for Knowledge Distillation aim to lighter Large Scale LLM model. This model have 3 objective functions:

        1) distillation loss, calculated by soft targets &amp; soft predictions
            (nn.KLDIVLoss(reduction='batchmean'))

        2) student loss, calculated by hard targets &amp; hard predictions
            (nn.CrossEntropyLoss(reduction='mean')), same as pure MLM Loss

        3) cosine similarity loss, calculated by student &amp; teacher logit similarity
            (nn.CosineEmbeddingLoss(reduction='mean')), similar as contrastive loss

    soft targets &amp; soft predictions are meaning that logit are passed through softmax function applied with temperature T
    temperature T aim to flatten softmax layer distribution for making "Dark Knowledge" from teacher model

    hard targets &amp; hard predictions are meaning that logit are passed through softmax function without temperature T
    hard targets are same as just simple labels from MLM Collator returns for calculating cross entropy loss

    cosine similarity loss is calculated by cosine similarity between student &amp; teacher
    in official repo, they mask padding tokens for calculating cosine similarity, target for this task is 1
    cosine similarity is calculated by nn.CosineSimilarity() function, values are range to [-1, 1]

    you can select any other backbone model architecture for Teacher &amp; Student Model for knowledge distillation
    but, in original paper, BERT is used for Teacher Model &amp; Student
    and you must select pretrained model for Teacher Model, because Teacher Model is used for knowledge distillation,
    which is containing pretrained mlm head

    Do not pass gradient backward to teacher model!!
    (teacher model must be frozen or register_buffer to model or use no_grad() context manager)

    Args:
        cfg: configuration.CFG
        model_func: make model instance in runtime from config.json

    References:
        https://arxiv.org/pdf/1910.01108.pdf
        https://github.com/huggingface/transformers/blob/main/examples/research_projects/distillation/distiller.py
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CFG</span><span class="p">,</span> <span class="n">model_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DistilBERT</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">teacher</span> <span class="o">=</span> <span class="n">model_func</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">teacher_num_layers</span><span class="p">)</span>  <span class="c1"># must be loading pretrained model containing mlm head
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span> <span class="o">=</span> <span class="n">MLMHead</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">)</span>  <span class="c1"># must be loading pretrained model's mlm head
</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">student</span> <span class="o">=</span> <span class="n">model_func</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">student_num_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">s_mlm_head</span> <span class="o">=</span> <span class="n">MLMHead</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">teacher_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" forward pass for teacher model
        """</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">teacher</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">t_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">)</span>  <span class="c1"># hard logit =&gt; to make soft logit
</span>        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">t_logit</span>

    <span class="k">def</span> <span class="nf">student_fw</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="s">""" forward pass for student model
        """</span>
        <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">student</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">s_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">s_mlm_head</span><span class="p">(</span><span class="n">last_hidden_state</span><span class="p">)</span>  <span class="c1"># hard logit =&gt; to make soft logit
</span>        <span class="k">return</span> <span class="n">last_hidden_state</span><span class="p">,</span> <span class="n">s_logit</span>
</code></pre></div></div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#bert" class="page__taxonomy-item p-category" rel="tag">BERT</a><span class="sep">, </span>
    
      <a href="/tags/#distilbert" class="page__taxonomy-item p-category" rel="tag">DistilBERT</a><span class="sep">, </span>
    
      <a href="/tags/#natural-language-process" class="page__taxonomy-item p-category" rel="tag">Natural Language Process</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">Pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#self-attention" class="page__taxonomy-item p-category" rel="tag">Self-Attention</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#nlp" class="page__taxonomy-item p-category" rel="tag">NLP</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-03-11">March 11, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%F0%9F%A7%91%E2%80%8D%F0%9F%8F%AB+%5BDistilBERT%5D+DistilBERT%2C+a+distilled+version+of+BERT%3A+smaller%2C+faster%2C+cheaper+and+lighter%20http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdistilbert" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdistilbert" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdistilbert" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/nlp/deberta_v3" class="pagination--pager" title="ğŸª¢Â [DeBERTa-V3] DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing
">Previous</a>
    
    
      <a href="/nlp/electra" class="pagination--pager" title="ğŸ‘® [ELECTRA] Pre-training Text Encoders as Discriminators Rather Than Generators
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/linear_attention" rel="permalink">ğŸŒ† [Linear Attention] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 14 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Linear Attention Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/spanbert" rel="permalink">ğŸ—‚ï¸[SpanBERT] SpanBERT: Improving Pre-training by Representing and Predicting Spans
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 11 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">SpanBERT Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/roformer" rel="permalink">ğŸ¡ [Roformer] RoFormer: Enhanced Transformer with Rotary Position Embedding
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 11 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Roformer Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/electra" rel="permalink">ğŸ‘® [ELECTRA] Pre-training Text Encoders as Discriminators Rather Than Generators
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 11 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ELECTRA Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 qcqced. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'qcqced123/qcqced123.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
});
</script>

  </body>
</html>
