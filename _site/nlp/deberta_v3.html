<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>🪢 [DeBERTa-V3] DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing - AI/Business Study Log</title>
<meta name="description" content="DeBERTa-V3 Official Paper Review with Pytorch Implementation">


  <meta name="author" content="qcqced">
  
  <meta property="article:author" content="qcqced">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AI/Business Study Log">
<meta property="og:title" content="🪢 [DeBERTa-V3] DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing">
<meta property="og:url" content="http://localhost:4000/nlp/deberta_v3">


  <meta property="og:description" content="DeBERTa-V3 Official Paper Review with Pytorch Implementation">







  <meta property="article:published_time" content="2024-03-11T00:00:00+09:00">



  <meta property="article:modified_time" content="2024-03-12T02:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/nlp/deberta_v3">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "qcqced",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="AI/Business Study Log Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<!-- Latex -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
<link rel="manifest" href="/assets/site.webmanifest">
<link rel="mask-icon" href="/assets/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          AI/Business Study Log
          <span class="site-subtitle">NLP, Marketing</span>
        </a>
        
        
        <ul class="visible-links">
              
              
                  <li class="masthead__menu-item">
                      <a href="https://qcqced123.github.io/">Home</a>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CS/AI  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/nlp/">    Natural Language Process</a>
                          
                              <a class = "dropdown-item" href="/multi-modal/">    Multi Modal</a>
                          
                              <a class = "dropdown-item" href="/cv/">    Computer Vision</a>
                          
                              <a class = "dropdown-item" href="/ml/">    Machine Learning</a>
                          
                              <a class = "dropdown-item" href="/framework-library/">    Framework & Library</a>
                          
                              <a class = "dropdown-item" href="/python/">    Python</a>
                          
                              <a class = "dropdown-item" href="/algorithm/">    Data Structure & Algorithm</a>
                          
                              <a class = "dropdown-item" href="/ps/">    Problem Solving</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Math  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/linear-algebra/">    Linear Algebra</a>
                          
                              <a class = "dropdown-item" href="/optimization-theory/">    Optimization Theory/Calculus</a>
                          
                              <a class = "dropdown-item" href="/signal-system/">    Signal & System</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Business/Marketing  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/device/">    Device</a>
                          
                              <a class = "dropdown-item" href="/semi-conductor/">    Semi-Conductor</a>
                          
                              <a class = "dropdown-item" href="/ai/">    AI</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/categories/">Category</a>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/about/">About</a>
                  </li>
              
          
       </ul>
       
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/huggingface_emoji.png" alt="qcqced" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">qcqced</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in NLP, Marketing</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Seoul, South Korea</span>
        </li>
      

      
        
          
            <li><a href="https://qcqced123.github.io" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
          
            <li><a href="https://github.com/qcqced123" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.kaggle.com/qcqced" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-kaggle" aria-hidden="true"></i><span class="label">Kaggle</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:qcqced123@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="qcqced123@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="🪢 [DeBERTa-V3] DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing">
    <meta itemprop="description" content="DeBERTa-V3 Official Paper Review with Pytorch Implementation">
    <meta itemprop="datePublished" content="2024-03-11T00:00:00+09:00">
    <meta itemprop="dateModified" content="2024-03-12T02:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/nlp/deberta_v3" class="u-url" itemprop="url">🪢 [DeBERTa-V3] DeBERTaV3: Improving DeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangled Embedding Sharing
</a>
          </h1>
          <p class="page__date">
            <a href="https://hits.seeyoufarm.com/localhost:4000/nlp/deberta_v3"target="_blank">
              <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://localhost:4000/nlp/deberta_v3&count_bg=%23399DE2&title_bg=%236D6D6D&icon=pytorch.svg&icon_color=%23E7E7E7&title=Views&edge_flat=false"/>
            </a>
            <i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2024-03-11T00:00:00+09:00">March 11, 2024</time>
            <!-- <div style="text-align: left;"> -->
            <!-- </div> -->
          </p>
          
          
        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#overview">🔭 Overview</a></li><li><a href="#gdes-gradient-disentangled-embedding-sharing">🪢GDES: Gradient Disentangled Embedding Sharing</a></li><li><a href="#implementation-by-pytorch">👩‍💻 Implementation by Pytorch</a></li><li><a href="#-gdes-experiment">🤔 GDES Experiment</a></li></ul>

            </nav>
          </aside>
        
        <h3 id="overview"><code class="language-plaintext highlighter-rouge">🔭 Overview</code></h3>

<p>2021년 Microsoft에서 공개한 <code class="language-plaintext highlighter-rouge">DeBERTa-V3</code>은 기존 DeBERTa의 모델 구조는 그대로 유지하되, ELECTRA의 Generator-Discriminator 구조를 차용하여 전작 대비 성능을 향상 시킨 모델이다. ELECTRA에서 BackBone 모델로 BERT 대신 <code class="language-plaintext highlighter-rouge">DeBERTa을</code> 사용했다고 생각하면 된다. 거기에 더해 ELECTRA의 <code class="language-plaintext highlighter-rouge">Tug-of-War</code> 현상을 방지하기 위해 새로운 임베딩 공유 기법인 <code class="language-plaintext highlighter-rouge">GDES(Gradient Disentagnled Embedding Sharing)</code>방법을 제시했다.</p>

<p>이번 포스팅에서는 구현 코드와 함께 GDES에 대해서만 살펴보려 한다. ELECTRA, DeBERTa에 대해 궁금하다면 이전 포스팅을, 전체 구조에 대한 코드는 <strong><a href="https://github.com/qcqced123/model_study">여기 링크</a></strong>를 통해 확인 가능하다.</p>

<h3 id="gdes-gradient-disentangled-embedding-sharing"><code class="language-plaintext highlighter-rouge">🪢GDES: Gradient Disentangled Embedding Sharing</code></h3>

<p align="center">
<img src="/assets/images/deberta_v3/deberta_v3.png" alt="GDES" class="align-center image-caption" width="100%&quot;, height=&quot;100%" />
<strong><em><a href="https://arxiv.org/abs/2111.09543">GDES</a></em></strong>
</p>

<p>그림의 (a)가 기존 ELECTRA의 가중치 공유 방식, (c)가 GDES에 해당된다. 그림 속 모식도와 설명이 좀 복잡해 보이지만 아이디어는 매우 간단하다.</p>

<p>생성자와 판별자가 서로 포워드 패스 시점에는 단어, 위치 임베딩을 공유하되, 백워드 패스 시점에서는 공유되지 못하도록 하여, 판별자의 학습 결과에 의해 생성자의 단어 임베딩, 위치 임베딩이 업데이트 되지 못하도록 하지는 것이다. 오직 생성자의 MLM 학습에 의해서만 단어 및 위치 임베딩이 업데이트 되어야 한다.</p>

\[E_{D} = \text{sg}(E_{G}) + E_{\Delta}\]

<p>필자가 추정하기로는 <code class="language-plaintext highlighter-rouge">Skip-Connection</code>에서 영감을 받지 않았나 싶은 이 수식은, 생성자의 임베딩에 잔차값들을 더해 판별자의 임베딩 행렬이 RTD에 최적화 되도록 설계 되었다. 여기서 <code class="language-plaintext highlighter-rouge">sg()</code> 는 <code class="language-plaintext highlighter-rouge">stop gradient</code>를 의미한다. 다시 말해, 생성자의 임베딩 가중치를 판별자 학습에 사용하되, 해당 시점에서는 계산 그래프 작성을 중단시켜 판별자의 학습 결과(이진 분류 손실)가 생성자의 임베딩 가중치에 영향을 미치지 못하도록 한 것이다.</p>

<p>이러한 아이디어는 실제로 어떻게 코드로 구현해야할까, 아래 코드와 함께 살펴보자.</p>

<h3 id="implementation-by-pytorch"><code class="language-plaintext highlighter-rouge">👩‍💻 Implementation by Pytorch</code></h3>

<p>ELECTRA 모듈 <strong><code class="language-plaintext highlighter-rouge">__init__</code></strong>의 <strong><code class="language-plaintext highlighter-rouge">share_embed_method</code></strong>에 따라 브랜치가 발생하는 구간과, 아래 <strong><code class="language-plaintext highlighter-rouge">share_embedding()</code></strong> 메서드에 주목해보자.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">experiment.models.abstract_model</span> <span class="kn">import</span> <span class="n">AbstractModel</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Callable</span>
<span class="kn">from</span> <span class="nn">einops.layers.torch</span> <span class="kn">import</span> <span class="n">Rearrange</span>
<span class="kn">from</span> <span class="nn">experiment.tuner.mlm</span> <span class="kn">import</span> <span class="n">MLMHead</span>
<span class="kn">from</span> <span class="nn">experiment.tuner.sbo</span> <span class="kn">import</span> <span class="n">SBOHead</span>
<span class="kn">from</span> <span class="nn">experiment.tuner.rtd</span> <span class="kn">import</span> <span class="n">get_discriminator_input</span><span class="p">,</span> <span class="n">RTDHead</span>
<span class="kn">from</span> <span class="nn">configuration</span> <span class="kn">import</span> <span class="n">CFG</span>


<span class="k">class</span> <span class="nc">ELECTRA</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">AbstractModel</span><span class="p">):</span>
    <span class="s">""" If you want to use pure ELECTRA, you should set share_embedding = ES
    elif you want to use ELECTRA with GDES, you should set share_embedding = GDES
    GDES is new approach of embedding sharing method from DeBERTa-V3 paper

    Args:
        cfg: configuration.CFG
        model_func: make model instance in runtime from config.json

    Var:
        cfg: configuration.CFG
        generator: Generator, which is used for generating replaced tokens for RTD
                   should select backbone model ex) BERT, RoBERTa, DeBERTa, ...
        discriminator: Discriminator, which is used for detecting replaced tokens for RTD
                       should select backbone model ex) BERT, RoBERTa, DeBERTa, ...
        share_embedding: whether or not to share embedding layer (word &amp; pos) between Generator &amp; Discriminator
        self.word_bias: Delta_E in paper
        self.abs_pos_bias: Delta_E in paper
        self.rel_pos_bias: Delta_E in paper

    References:
        https://arxiv.org/pdf/2003.10555.pdf
        https://arxiv.org/pdf/2111.09543.pdf
        https://github.com/google-research/electra
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="n">CFG</span><span class="p">,</span> <span class="n">model_func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ELECTRA</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span> <span class="o">=</span> <span class="n">cfg</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">model_func</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">generator_num_layers</span><span class="p">)</span>  <span class="c1"># init generator
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span> <span class="o">=</span> <span class="n">MLMHead</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">rtd_masking</span> <span class="o">==</span> <span class="s">'SpanBoundaryObjective'</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span> <span class="o">=</span> <span class="n">SBOHead</span><span class="p">(</span>
                <span class="n">cfg</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">,</span>
                <span class="n">is_concatenate</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">is_concatenate</span><span class="p">,</span>
                <span class="n">max_span_length</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">max_span_length</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span> <span class="o">=</span> <span class="n">model_func</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">discriminator_num_layers</span><span class="p">)</span>  <span class="c1"># init generator
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">rtd_head</span> <span class="o">=</span> <span class="n">RTDHead</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">share_embed_method</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">share_embed_method</span>  <span class="c1"># instance, es, gdes
</span>        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">share_embed_method</span> <span class="o">==</span> <span class="s">'GDES'</span><span class="p">:</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">word_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">abs_pos_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span><span class="p">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s">'_weight'</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">word_bias</span><span class="p">)</span>

            <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">)</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span><span class="p">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s">'_weight'</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">abs_pos_bias</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s">'DeBERTa'</span><span class="p">:</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">rel_pos_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Parameter</span><span class="p">(</span>
                    <span class="n">torch</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span><span class="p">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="nb">delattr</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">)</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span><span class="p">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="s">'_weight'</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">rel_pos_emb</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">share_embedding</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">share_embedding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">def</span> <span class="nf">discriminator_hook</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">share_embed_method</span> <span class="o">==</span> <span class="s">'instance'</span><span class="p">:</span>  <span class="c1"># Instance Sharing
</span>                <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">share_embed_method</span> <span class="o">==</span> <span class="s">'ES'</span><span class="p">:</span>  <span class="c1"># ES (Embedding Sharing)
</span>                <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span><span class="p">.</span><span class="n">weight</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span><span class="p">.</span><span class="n">weight</span>
                <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s">'DeBERTa'</span><span class="p">:</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span><span class="p">.</span><span class="n">weight</span>

            <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">share_embed_method</span> <span class="o">==</span> <span class="s">'GDES'</span><span class="p">:</span>  <span class="c1"># GDES (Generator Discriminator Embedding Sharing)
</span>                <span class="n">g_w_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span>
                <span class="n">d_w_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">word_embedding</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">_set_param</span><span class="p">(</span><span class="n">d_w_emb</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="n">g_w_emb</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">+</span> <span class="n">d_w_emb</span><span class="p">.</span><span class="n">_weight</span><span class="p">)</span>
                <span class="n">g_p_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span>
                <span class="n">d_p_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">abs_pos_emb</span>
                <span class="bp">self</span><span class="p">.</span><span class="n">_set_param</span><span class="p">(</span><span class="n">d_p_emb</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="n">g_p_emb</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">+</span> <span class="n">d_p_emb</span><span class="p">.</span><span class="n">_weight</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">model_name</span> <span class="o">==</span> <span class="s">'DeBERTa'</span><span class="p">:</span>
                    <span class="n">g_rp_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span>
                    <span class="n">d_rp_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">rel_pos_emb</span>
                    <span class="bp">self</span><span class="p">.</span><span class="n">_set_param</span><span class="p">(</span><span class="n">d_rp_emb</span><span class="p">,</span> <span class="s">'weight'</span><span class="p">,</span> <span class="n">g_rp_emb</span><span class="p">.</span><span class="n">weight</span><span class="p">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">+</span> <span class="n">d_rp_emb</span><span class="p">.</span><span class="n">_weight</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">.</span><span class="n">register_forward_pre_hook</span><span class="p">(</span><span class="n">discriminator_hook</span><span class="p">)</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">_set_param</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="n">module</span><span class="p">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generator_fw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">mask_labels</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]:</span>
        <span class="n">g_last_hidden_states</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">generator</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">rtd_masking</span> <span class="o">==</span> <span class="s">'MaskedLanguageModel'</span><span class="p">:</span>
            <span class="n">g_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span><span class="p">(</span>
                <span class="n">g_last_hidden_states</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="p">.</span><span class="n">cfg</span><span class="p">.</span><span class="n">rtd_masking</span> <span class="o">==</span> <span class="s">'SpanBoundaryObjective'</span><span class="p">:</span>
            <span class="n">g_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mlm_head</span><span class="p">(</span>
                <span class="n">g_last_hidden_states</span><span class="p">,</span>
                <span class="n">mask_labels</span>
            <span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">g_logit</span><span class="p">.</span><span class="n">clone</span><span class="p">().</span><span class="n">detach</span><span class="p">()</span>
        <span class="n">d_inputs</span><span class="p">,</span> <span class="n">d_labels</span> <span class="o">=</span> <span class="n">get_discriminator_input</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">labels</span><span class="p">,</span>
            <span class="n">pred</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">g_logit</span><span class="p">,</span> <span class="n">d_inputs</span><span class="p">,</span> <span class="n">d_labels</span>

    <span class="k">def</span> <span class="nf">discriminator_fw</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span><span class="n">attention_mask</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">d_last_hidden_states</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">discriminator</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">padding_mask</span><span class="p">,</span>
            <span class="n">attention_mask</span>
        <span class="p">)</span>
        <span class="n">d_logit</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">rtd_head</span><span class="p">(</span>
            <span class="n">d_last_hidden_states</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">d_logit</span>
</code></pre></div></div>
<p>먼저 <strong><code class="language-plaintext highlighter-rouge">__init__</code></strong>의 브랜치 구간을 살펴보자. <strong><code class="language-plaintext highlighter-rouge">word_bias</code></strong>, <strong><code class="language-plaintext highlighter-rouge">pos_bias</code></strong>를 만들어 <code class="language-plaintext highlighter-rouge">register_parameter</code>화를 하고 있다. 새롭게 생성되어 <strong><code class="language-plaintext highlighter-rouge">_weight</code></strong>이란 이름으로 생성자의 파라미터가 된 두 가중치가 바로 $E_{\Delta}$ 가 된다.</p>

<p>다음 <strong><code class="language-plaintext highlighter-rouge">share_embedding()</code></strong> 메서드를 보자. $E_{G}$ 에 <code class="language-plaintext highlighter-rouge">torch.detach()</code>를 사용해 수식의 <code class="language-plaintext highlighter-rouge">stop gradient</code> 효과를 적용한다. 그리고 두 가중치를 더하고, <code class="language-plaintext highlighter-rouge">torch.register_buffer</code>를 호출해 포워드 패스에 활용은 되지만 백워드 패스에 그라디언트가 해당 가중치를 업데이트 하지 못하도록 설정한다. 그리고 마지막에 <code class="language-plaintext highlighter-rouge">torch.register_forward_pre_hook</code>을 호출하는데, 그 이유는 $E_{G}$ 에 <code class="language-plaintext highlighter-rouge">torch.detach()</code> 를 사용했기 때문에 현재 판별자의 버퍼에 있는 $E_{G}$ 는 이전 시점의 생성자 MLM 손실에 의해 새롭게 업데이트 $E_{G}$ 가 아니다. 따라서 매번 판별자의 포워드 패스가 호출(시작)되는 시점에 업데이트 된 $E_{G}$ 를 반영해 RTD를 수행할 수 있도록 하기 위해 <code class="language-plaintext highlighter-rouge">register_forward_pre_hook</code> 를 사용했다.</p>

<h3 id="-gdes-experiment"><strong><code class="language-plaintext highlighter-rouge">🤔 GDES Experiment</code></strong></h3>

<p>GDES가 제대로 구현되었는지, 논문 주장대로 판별자 학습 결과가 간섭을 발생시키지 않는지 확인하기 위해 한가지 실험을 진행했다. 실험 내용은 이렇다. 만약 GDES가 의도대로 구현된게 맞다면, 인코더 모델의 MLM 학습 결과 추이와 ELECTRA의 생성자 학습 결과 추이 양상이 유사해야 한다. 만약 최적화 추세가 다르다면, 필자가 잘못 구현했거나, 저자의 주장과 다르게 간섭이 발생하는 것이라 볼 수 있을 것이다. Backbone을 DeBERTa로 두고 각각 학습을 진행했다. 모든 하이퍼 파라미터를 고정한 뒤, 학습 초반 120스탭에 대한 결과 추이를 비교해봤다.</p>

<p align="center">
<img src="/assets/images/deberta_v3/deberta_test.png" alt="DeBERTa MLM Result" class="align-center image-caption" width="100%&quot;, height=&quot;100%" />
<strong><em><a href="https://arxiv.org/abs/2111.09543">DeBERTa MLM Result</a></em></strong>
</p>

<p align="center">
<img src="/assets/images/deberta_v3/gdes_test.png" alt="GDES Result" class="align-center image-caption" width="100%&quot;, height=&quot;100%" />
<strong><em><a href="https://arxiv.org/abs/2111.09543">GDES Result</a></em></strong>
</p>

<p>미처 까먹고 <code class="language-plaintext highlighter-rouge">torch.backends.cudnn.deterministic = False</code>로 두고 실험을 진행하여, 생성자의 수렴이 좀 더 빨리 진행되는 양상을 보이고 있다. 아마도 생성자 학습을 할 때 <code class="language-plaintext highlighter-rouge">cudnn</code> 이 열심히 일을 한 것 같댜. 수렴 속도에는 차이가 조금 나지만, 최적화 되는 추세 자체는 동일한 것을 알 수 있다.</p>

<p>따라서 GDES를 사용하면 간섭이 발생하지 않아 <code class="language-plaintext highlighter-rouge">Tug-of-War</code> 현상을 방지할 수 있다. 다만, 실험이 다소 엄밀하지 못한 측면이 있다. 추후에 좀 더 엄밀한 증명을 할 수 있는 실험 방법을 생각해봐야겠다.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#deberta" class="page__taxonomy-item p-category" rel="tag">DeBERTa</a><span class="sep">, </span>
    
      <a href="/tags/#deberta-v3" class="page__taxonomy-item p-category" rel="tag">DeBERTa-V3</a><span class="sep">, </span>
    
      <a href="/tags/#electra" class="page__taxonomy-item p-category" rel="tag">ELECTRA</a><span class="sep">, </span>
    
      <a href="/tags/#gdes" class="page__taxonomy-item p-category" rel="tag">GDES</a><span class="sep">, </span>
    
      <a href="/tags/#natural-language-process" class="page__taxonomy-item p-category" rel="tag">Natural Language Process</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">Pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#weight-sharing" class="page__taxonomy-item p-category" rel="tag">Weight Sharing</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#nlp" class="page__taxonomy-item p-category" rel="tag">NLP</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-03-11">March 11, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%F0%9F%AA%A2%C2%A0%5BDeBERTa-V3%5D+DeBERTaV3%3A+Improving+DeBERTa+using+ELECTRA-Style+Pre-Training+with+Gradient-Disentangled+Embedding+Sharing%20http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdeberta_v3" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdeberta_v3" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fnlp%2Fdeberta_v3" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/ps/baekjoon-1987" class="pagination--pager" title="👩‍💻🎄 [baekjoon] 1987번: 알파벳
">Previous</a>
    
    
      <a href="/nlp/distilbert" class="pagination--pager" title="🧑‍🏫 [DistilBERT] DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/lora" rel="permalink">🔪 [LoRA] Low-Rank Adaptation of Large Language Models
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          12 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 28 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">LoRA Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/time_complexity2" rel="permalink">👨⏰🐍 [Python] 시간복잡도 2
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 26 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">시간 복잡도 줄이기
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/time_complexity1" rel="permalink">👨⏰🐍 [Python] 시간복잡도 1
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 26 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">시간 복잡도에 대한 이해
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/linear_attention" rel="permalink">🌆 [Linear Attention] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 14 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Linear Attention Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 qcqced. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'qcqced123/qcqced123.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
});
</script>

  </body>
</html>
