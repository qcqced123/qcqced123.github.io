<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>üî•¬†Pytorch Tensor Indexing ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî Î©îÏÑúÎìú Î™®ÏùåÏßë - AI/Business Study Log</title>
<meta name="description" content="ÌååÏù¥ÌÜ†ÏπòÏóêÏÑú ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî ÌÖêÏÑú Ïù∏Îç±Ïã± Í¥ÄÎ†® Î©îÏÑúÎìú Î™®Ïùå">


  <meta name="author" content="qcqced">
  
  <meta property="article:author" content="qcqced">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AI/Business Study Log">
<meta property="og:title" content="üî•¬†Pytorch Tensor Indexing ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî Î©îÏÑúÎìú Î™®ÏùåÏßë">
<meta property="og:url" content="http://localhost:4000/framework-library/torch-indexing-function">


  <meta property="og:description" content="ÌååÏù¥ÌÜ†ÏπòÏóêÏÑú ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî ÌÖêÏÑú Ïù∏Îç±Ïã± Í¥ÄÎ†® Î©îÏÑúÎìú Î™®Ïùå">







  <meta property="article:published_time" content="2024-01-09T00:00:00+09:00">



  <meta property="article:modified_time" content="2024-01-10T02:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/framework-library/torch-indexing-function">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "qcqced",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="AI/Business Study Log Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<!-- Latex -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
<link rel="manifest" href="/assets/site.webmanifest">
<link rel="mask-icon" href="/assets/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          AI/Business Study Log
          <span class="site-subtitle">NLP, Marketing</span>
        </a>
        
        
        <ul class="visible-links">
              
              
                  <li class="masthead__menu-item">
                      <a href="https://qcqced123.github.io/">Home</a>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CS/AI  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/nlp/">    Natural Language Process</a>
                          
                              <a class = "dropdown-item" href="/multi-modal/">    Multi Modal</a>
                          
                              <a class = "dropdown-item" href="/cv/">    Computer Vision</a>
                          
                              <a class = "dropdown-item" href="/ml/">    Machine Learning</a>
                          
                              <a class = "dropdown-item" href="/framework-library/">    Framework & Library</a>
                          
                              <a class = "dropdown-item" href="/python/">    Python</a>
                          
                              <a class = "dropdown-item" href="/algorithm/">    Data Structure & Algorithm</a>
                          
                              <a class = "dropdown-item" href="/ps/">    Problem Solving</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Math  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/linear-algebra/">    Linear Algebra</a>
                          
                              <a class = "dropdown-item" href="/optimization-theory/">    Optimization Theory/Calculus</a>
                          
                              <a class = "dropdown-item" href="/signal-system/">    Signal & System</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Business/Marketing  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/device/">    Device</a>
                          
                              <a class = "dropdown-item" href="/semi-conductor/">    Semi-Conductor</a>
                          
                              <a class = "dropdown-item" href="/ai/">    AI</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/categories/">Category</a>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/about/">About</a>
                  </li>
              
          
       </ul>
       
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/huggingface_emoji.png" alt="qcqced" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">qcqced</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in NLP, Marketing</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Seoul, South Korea</span>
        </li>
      

      
        
          
            <li><a href="https://qcqced123.github.io" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
          
            <li><a href="https://github.com/qcqced123" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.kaggle.com/qcqced" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-kaggle" aria-hidden="true"></i><span class="label">Kaggle</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:qcqced123@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="qcqced123@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="üî•¬†Pytorch Tensor Indexing ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî Î©îÏÑúÎìú Î™®ÏùåÏßë">
    <meta itemprop="description" content="ÌååÏù¥ÌÜ†ÏπòÏóêÏÑú ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî ÌÖêÏÑú Ïù∏Îç±Ïã± Í¥ÄÎ†® Î©îÏÑúÎìú Î™®Ïùå">
    <meta itemprop="datePublished" content="2024-01-09T00:00:00+09:00">
    <meta itemprop="dateModified" content="2024-01-10T02:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/framework-library/torch-indexing-function" class="u-url" itemprop="url">üî•¬†Pytorch Tensor Indexing ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî Î©îÏÑúÎìú Î™®ÏùåÏßë
</a>
          </h1>
          <p class="page__date">
            <a href="https://hits.seeyoufarm.com/localhost:4000/framework-library/torch-indexing-function"target="_blank">
              <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://localhost:4000/framework-library/torch-indexing-function&count_bg=%23399DE2&title_bg=%236D6D6D&icon=pytorch.svg&icon_color=%23E7E7E7&title=Views&edge_flat=false"/>
            </a>
            <i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2024-01-09T00:00:00+09:00">January 09, 2024</time>
            <!-- <div style="text-align: left;"> -->
            <!-- </div> -->
          </p>
          
          
        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#torchargmax">üîé¬†torch.argmax</a></li><li><a href="#torchstack">üìö¬†torch.stack</a></li><li><a href="#torcharange">üî¢¬†torch.arange</a></li><li><a href="#torchrepeat">üîÅ¬†torch.repeat</a></li><li><a href="#torchclamp">üî¨¬†torch.clamp</a></li><li><a href="#torchgather">üë©‚Äçüë©‚Äçüëß‚Äçüë¶¬†torch.gather</a></li><li><a href="#torchtriu-torchtril">üë©‚Äçüë©‚Äçüëß‚Äçüë¶¬†torch.triu, torch.tril</a></li><li><a href="#torchtensormasked_fill">üë©‚Äçüë©‚Äçüëß‚Äçüë¶¬†torch.Tensor.masked_fill</a></li><li><a href="#Ô∏ètorchclone">üóÇÔ∏è¬†torch.clone</a></li></ul>

            </nav>
          </aside>
        
        <p>ÌååÏù¥ÌÜ†ÏπòÏóêÏÑú ÌïÑÏûêÍ∞Ä ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî ÌÖêÏÑú Ïù∏Îç±Ïã± Í¥ÄÎ†® Î©îÏÑúÎìúÏùò ÏÇ¨Ïö©Î≤ï Î∞è ÏÇ¨Ïö© ÏòàÏãúÎ•º ÌïúÎ∞©Ïóê Ï†ïÎ¶¨Ìïú Ìè¨Ïä§Ìä∏Îã§. Î©îÏÑúÎìú ÌïòÎÇòÎãπ ÌïòÎÇòÏùò Ìè¨Ïä§Ìä∏Î°ú ÎßåÎì§Í∏∞ÏóêÎäî ÎÑàÎ¨¥ Í∏∏Ïù¥Í∞Ä ÏßßÎã§ ÏÉùÍ∞ÅÌï¥ Ìïú ÌéòÏù¥ÏßÄÏóê Î™®Îëê ÎÑ£Í≤å ÎêòÏóàÎã§. ÏßÄÏÜçÏ†ÅÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏ Îê† ÏòàÏ†ïÏù¥Îã§. ÎòêÌïú ÌÖêÏÑú Ïù∏Îç±Ïã± ÎßêÍ≥†ÎèÑ Îã§Î•∏ Ï£ºÏ†úÎ°úÎèÑ Í¥ÄÎ†® Î©îÏÑúÎìúÎ•º Ï†ïÎ¶¨Ìï¥ Ïò¨Î¶¥ ÏòàÏ†ïÏù¥Îãà ÎßéÏùÄ Í¥ÄÏã¨ Î∂ÄÌÉÅÎìúÎ¶∞Îã§.</p>

<h3 id="torchargmax"><code class="language-plaintext highlighter-rouge">üîé¬†torch.argmax</code></h3>

<p>ÏûÖÎ†• ÌÖêÏÑúÏóêÏÑú Í∞ÄÏû• ÌÅ∞ Í∞íÏùÑ Í∞ñÍ≥† ÏûàÎäî ÏõêÏÜåÏùò Ïù∏Îç±Ïä§Î•º Î∞òÌôòÌïúÎã§. ÏµúÎåÄÍ∞íÏùÑ Ï∞æÏùÑ Ï∞®ÏõêÏùÑ ÏßÄÏ†ïÌï¥Ï§Ñ Ïàò ÏûàÎã§. ÏïÑÎûò ÏòàÏãú ÏΩîÎìúÎ•º ÌôïÏù∏Ìï¥Î≥¥Ïûê.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.argmax params
</span><span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># torch.argmax example 1
</span><span class="n">test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">45</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="o">&lt;</span><span class="n">Result</span><span class="o">&gt;</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># torch.argmax example 2
</span><span class="n">test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                     <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">Result</span><span class="o">&gt;</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># torch.argmax example 3
</span><span class="n">test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                     <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">dim</code> Îß§Í∞úÎ≥ÄÏàòÏóê ÏõêÌïòÎäî Ï∞®ÏõêÏùÑ ÏûÖÎ†•ÌïòÎ©¥ Ìï¥Îãπ Ï∞®Ïõê Î∑∞ÏóêÏÑú Í∞ÄÏû• ÌÅ∞ ÏõêÏÜåÎ•º Ï∞æÏïÑ Ïù∏Îç±Ïä§ Í∞íÏùÑ Î∞òÌôòÌï¥Ï§Ñ Í≤ÉÏù¥Îã§. Ïù¥ Îïå <code class="language-plaintext highlighter-rouge">keepdim=True</code> Î°ú ÏÑ§Ï†ïÌïúÎã§Î©¥ ÏûÖÎ†• Ï∞®ÏõêÏóêÏÑú Í∞ÄÏû• ÌÅ∞ ÏõêÏÜåÏùò Ïù∏Îç±Ïä§Î•º Î∞òÌôòÌïòÎêò ÏõêÎ≥∏ ÌÖêÏÑúÏùò Ï∞®ÏõêÍ≥º ÎèôÏùºÌïú ÌòïÌÉúÎ°ú Ï∂úÎ†•Ìï¥Ï§ÄÎã§. <code class="language-plaintext highlighter-rouge">example 2</code> Ïùò Í≤ΩÏö∞ <code class="language-plaintext highlighter-rouge">dim=0</code> ÎùºÏÑú ÌñâÏù¥ ÎàÑÏ†ÅÎêú Î∞©Ìñ•ÏúºÎ°ú ÌÖêÏÑúÎ•º Î∞îÎùºÎ¥êÏïº ÌïúÎã§. ÌñâÏù¥ ÎàÑÏ†ÅÎêú Î∞©Ìñ•ÏúºÎ°ú ÌÖêÏÑúÎ•º Î≥¥Í≤å ÎêòÎ©¥ <code class="language-plaintext highlighter-rouge">tensor([[0, 1, 1]])</code>Ïù¥ ÎêúÎã§.</p>

<h3 id="torchstack"><code class="language-plaintext highlighter-rouge">üìö¬†torch.stack</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
torch.stack
Args:
	tensors(sequence of Tensors): ÌÖêÏÑúÍ∞Ä Îã¥Í∏¥ ÌååÏù¥Ïç¨ ÏãúÌÄÄÏä§ Í∞ùÏ≤¥
	dim(int): Ï∂îÍ∞ÄÌï† Ï∞®Ïõê Î∞©Ìñ•ÏùÑ ÏÑ∏ÌåÖ, Í∏∞Î≥∏Í∞íÏùÄ 0
"""</span>
<span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>Îß§Í∞úÎ≥ÄÏàòÎ°ú Ï£ºÏñ¥ÏßÑ ÌååÏù¥Ïç¨ ÏãúÌÄÄÏä§ Í∞ùÏ≤¥(Î¶¨Ïä§Ìä∏, ÌäúÌîå)Î•º ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú ÏÉàÎ°úÏö¥ Ï∞®ÏõêÏóê ÏåìÎäî Í∏∞Îä•ÏùÑ ÌïúÎã§. Îß§Í∞úÎ≥ÄÏàò <code class="language-plaintext highlighter-rouge">tensors</code> Îäî ÌÖêÏÑúÍ∞Ä Îã¥Í∏¥ ÌååÏù¥Ïç¨Ïùò ÏãúÌÄÄÏä§ Í∞ùÏ≤¥Î•º ÏûÖÎ†•ÏúºÎ°ú Î∞õÎäîÎã§. <code class="language-plaintext highlighter-rouge">dim</code> ÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä ÌÖêÏÑú Ï†ÅÏû¨Î•º ÌïòÍ≥† Ïã∂ÏùÄ ÏÉàÎ°úÏö¥ Ï∞®ÏõêÏùÑ ÏßÄÏ†ïÌï¥Ï£ºÎ©¥ ÎêúÎã§. Í∏∞Î≥∏Í∞íÏùÄ 0Ï∞®ÏõêÏúºÎ°ú ÏßÄÏ†ï ÎêòÏñ¥ÏûàÏúºÎ©∞, ÌÖêÏÑúÏùò Îß® ÏïûÏ∞®ÏõêÏù¥ ÏÉàÎ°≠Í≤å ÏÉùÍ∏∞Í≤å ÎêúÎã§. <code class="language-plaintext highlighter-rouge">torch.stack</code> ÏùÄ Í∏∞Í≥ÑÌïôÏäµ, ÌäπÌûà Îî•Îü¨ÎãùÏóêÏÑú Ï†ïÎßê ÏûêÏ£º ÏÇ¨Ïö©ÎêòÍ∏∞ ÎïåÎ¨∏Ïóê ÏÇ¨Ïö©Î≤ï Î∞è ÏÇ¨Ïö©ÏÉÅÌô©ÏùÑ ÏùµÌòÄÎëêÎ©¥ ÎèÑÏõÄÏù¥ ÎêúÎã§. ÏòàÏãúÎ•º ÌÜµÌï¥ Ìï¥Îãπ Î©îÏÑúÎìúÎ•º Ïñ¥Îñ§ ÏÉÅÌô©ÏóêÏÑú Ïñ¥ÎñªÍ≤å ÏÇ¨Ïö©ÌïòÎäîÏßÄ ÏïåÏïÑÎ≥¥Ïûê.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">""" torch.stack example """</span>

<span class="k">class</span> <span class="nc">Projector</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Making projection matrix(Q, K, V) for each attention head
    When you call this class, it returns projection matrix of each attention head
    For example, if you call this class with 8 heads, it returns 8 set of projection matrices (Q, K, V)
    Args:
        num_heads: number of heads in MHA, default 8
        dim_head: dimension of each attention head, default 64
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">dim_head</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Projector</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">dim_head</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span> <span class="o">=</span> <span class="n">dim_head</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fc_q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span><span class="p">)</span>
        <span class="n">fc_k</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span><span class="p">)</span>
        <span class="n">fc_v</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fc_q</span><span class="p">,</span> <span class="n">fc_k</span><span class="p">,</span> <span class="n">fc_v</span>

<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">dim_head</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">projector</span> <span class="o">=</span> <span class="n">Projector</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">dim_head</span><span class="p">)</span>  <span class="c1"># init instance
</span><span class="n">projector_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">projector</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">)]</span>  <span class="c1"># call instance
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span> <span class="c1"># x.shape: [Batch_Size, Sequence_Length, Dim_model]
</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">):</span>
    <span class="n">Q</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">projector_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">))</span> <span class="c1"># [10, 512, 64]
</span>    <span class="n">K</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">projector_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span> <span class="c1"># [10, 512, 64]
</span>	  <span class="n">V</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">projector_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">))</span> <span class="c1"># [10, 512, 64]
</span> 
<span class="n">Q</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Q.shape: [10, 8, 512, 64]
</span><span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># K.shape: [10, 8, 512, 64]
</span><span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># V.shape: [10, 8, 512, 64]
</span></code></pre></div></div>

<p>ÏúÑ ÏΩîÎìúÎäî <code class="language-plaintext highlighter-rouge">Transformer</code> Ïùò <code class="language-plaintext highlighter-rouge">Multi-Head Attention</code> Íµ¨ÌòÑÏ≤¥ ÏùºÎ∂ÄÎ•º Î∞úÏ∑åÌï¥Ïò® Í≤ÉÏù¥Îã§. <code class="language-plaintext highlighter-rouge">Multi-Head Attention</code> ÏùÄ Í∞úÎ≥Ñ Ïñ¥ÌÖêÏÖò Ìï¥ÎìúÎ≥ÑÎ°ú ÌñâÎ†¨ $Q, K, V$Î•º Í∞ÄÏ†∏Ïïº ÌïúÎã§. Îî∞ÎùºÏÑú ÏûÖÎ†• ÏûÑÎ≤†Îî©ÏùÑ Í∞úÎ≥Ñ Ïñ¥ÌÖêÏÖò Ìó§ÎìúÏóê <code class="language-plaintext highlighter-rouge">Linear Combination</code> Ìï¥Ï§òÏïº ÌïòÎäîÎç∞ Ìó§Îìú Í∞úÏàòÍ∞Ä 8Í∞úÎÇò ÎêòÍ∏∞ ÎïåÎ¨∏Ïóê Í∞úÎ≥ÑÏ†ÅÏúºÎ°ú <code class="language-plaintext highlighter-rouge">Projection Matrix</code> Î•º ÏÑ†Ïñ∏Ìï¥Ï£ºÎäî Í≤ÉÏùÄ Îß§Ïö∞ ÎπÑÌö®Ïú®Ï†ÅÏù¥Îã§. Îî∞ÎùºÏÑú Í∞ùÏ≤¥  <code class="language-plaintext highlighter-rouge">Projector</code> Ïóê ÌñâÎ†¨ $Q, K, V$Ïóê ÎåÄÌïú <code class="language-plaintext highlighter-rouge">Projection Matrix</code> Î•º Ï†ïÏùòÌï¥Ï§¨Îã§. Ïù¥ÌõÑ Ìó§Îìú Í∞úÏàòÎßåÌÅº Í∞ùÏ≤¥  <code class="language-plaintext highlighter-rouge">Projector</code> Î•º Ìò∏Ï∂úÌï¥ Î¶¨Ïä§Ìä∏Ïóê Ìï¥ÎìúÎ≥Ñ <code class="language-plaintext highlighter-rouge">Projection Matrix</code> Î•º Îã¥ÏïÑÏ§ÄÎã§. Í∑∏ Îã§Ïùå <code class="language-plaintext highlighter-rouge">torch.stack</code>ÏùÑ ÏÇ¨Ïö©Ìï¥ <code class="language-plaintext highlighter-rouge">Attention Head</code> Î∞©Ìñ•Ïùò Ï∞®ÏõêÏúºÎ°ú Î¶¨Ïä§Ìä∏ ÎÇ¥Î∂Ä ÌÖêÏÑúÎì§ÏùÑ ÏåìÏïÑÏ£ºÎ©¥ ÎêúÎã§.</p>

<h3 id="torcharange"><code class="language-plaintext highlighter-rouge">üî¢¬†torch.arange</code></h3>

<p>ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú ÏãúÏûëÏ†êÎ∂ÄÌÑ∞ ÎÅùÏ†êÍπåÏßÄ ÏùºÏ†ïÌïú Í∞ÑÍ≤©ÏúºÎ°ú ÌÖêÏÑúÎ•º ÎÇòÏó¥ÌïúÎã§. PythonÏùò ÎÇ¥Ïû• Î©îÏÑúÎìú <code class="language-plaintext highlighter-rouge">range</code>ÏôÄ ÎèôÏùºÌïú Ïó≠Ìï†ÏùÑ ÌïòÎäîÎç∞, ÎåÄÏã† ÌÖêÏÑú Í∑∏ Í≤∞Í≥ºÎ•º ÌÖêÏÑú Íµ¨Ï°∞Ï≤¥Î°ú Î∞òÌôòÌïúÎã§Í≥† ÏÉùÍ∞ÅÌïòÎ©¥ ÎêòÍ≤†Îã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.arange usage
</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.5000</span><span class="p">,</span>  <span class="mf">2.0000</span><span class="p">])</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">step</code> Îß§Í∞úÎ≥ÄÏàòÎ°ú ÏõêÏÜåÍ∞Ñ Í∞ÑÍ≤© Ï°∞Ï†ïÏùÑ Ìï† Ïàò ÏûàÎäîÎç∞, Í∏∞Î≥∏ÏùÄ 1Î°ú ÏßÄÏ†ï ÎêòÏñ¥ ÏûàÏúºÎãà Ï∞∏Í≥†ÌïòÏûê. ÌïÑÏûêÏùò Í≤ΩÏö∞ÏóêÎäî <code class="language-plaintext highlighter-rouge">nn.Embedding</code>Ïùò ÏûÖÎ†• ÌÖêÏÑúÎ•º ÎßåÎì§ Îïå Í∞ÄÏû• ÎßéÏù¥ ÏÇ¨Ïö©ÌñàÎã§. <code class="language-plaintext highlighter-rouge">nn.Embedding</code> Ïùò Í≤ΩÏö∞ InputÏúºÎ°ú <code class="language-plaintext highlighter-rouge">IntTensor</code>, <code class="language-plaintext highlighter-rouge">LongTensor</code>Î•º Î∞õÍ≤å ÎêòÏñ¥ ÏûàÏúºÎãà ÏïåÏïÑÎëêÏûê.</p>

<h3 id="torchrepeat"><code class="language-plaintext highlighter-rouge">üîÅ¬†torch.repeat</code></h3>

<p>ÏûÖÎ†•Í∞íÏúºÎ°ú Ï£ºÏñ¥ÏßÑ ÌÖêÏÑúÎ•º ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú Î∞òÎ≥µ ÌöüÏàòÎßåÌÅº ÌäπÏ†ï Ï∞®Ïõê Î∞©Ìñ•ÏúºÎ°ú ÎäòÎ¶∞Îã§. ÏòàÎ•º Îì§Î©¥ <code class="language-plaintext highlighter-rouge">[1,2,3] * 3</code>Ïùò Í≤∞Í≥ºÎäî <code class="language-plaintext highlighter-rouge">[1, 2, 3, 1, 2, 3, 1, 2, 3]</code> Ïù∏Îç∞, Ïù¥Í≤ÉÏùÑ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú Î∞òÎ≥µ ÌöüÏàòÎßåÌÅº ÌäπÏ†ï Ï∞®ÏõêÏúºÎ°ú ÏàòÌñâÌïòÍ≤†Îã§Îäî Í≤ÉÏù¥Îã§. ÏïÑÎûò ÏÇ¨Ïö© ÏòàÏ†úÎ•º ÌôïÏù∏Ìï¥Î≥¥Ïûê.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.repeat example
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">size</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]])</span>
</code></pre></div></div>

<p>$t$Î•º Ïñ¥Îñ§ ÌÖêÏÑú Íµ¨Ï°∞Ï≤¥ $x$Ïùò ÏµúÎåÄ Ï∞®ÏõêÏù¥ÎùºÍ≥† ÌñàÏùÑ , $x_t$Î•º Í∞ÄÏû• ÏôºÏ™ΩÏóê ÎÑ£Í≥† Í∞ÄÏû• ÎÇÆÏùÄ Ï∞®ÏõêÏù∏ 0Ï∞®ÏõêÏóê ÎåÄÌïú Î∞òÎ≥µ ÌöüÏàòÎ•º Ïò§Î•∏Ï™Ω ÎÅùÏóê ÎåÄÏûÖÌï¥ÏÑú ÏÇ¨Ïö©ÌïòÎ©¥ ÎêúÎã§. (<code class="language-plaintext highlighter-rouge">torch.repeat(</code>$x_t, x_{t-1}, ‚Ä¶ x_2, x_1, x_0$<code class="language-plaintext highlighter-rouge">))</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.arange &amp; torch.repeate usage example
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pos_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pos_x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1025</span><span class="p">])</span>
</code></pre></div></div>

<p>ÌïÑÏûêÏùò Í≤ΩÏö∞, <code class="language-plaintext highlighter-rouge">position embedding</code>Ïùò ÏûÖÎ†•ÏùÑ ÎßåÎì§Í≥† Ïã∂ÏùÑ Îïå <code class="language-plaintext highlighter-rouge">torch.arange</code> ÏôÄ Ïó∞Í≥ÑÌï¥ ÏûêÏ£º ÏÇ¨Ïö© ÌñàÎçò Í≤É Í∞ôÎã§. ÏúÑ ÏΩîÎìúÎ•º Ï∞∏Í≥†ÌïòÏûê.</p>

<h3 id="torchclamp"><code class="language-plaintext highlighter-rouge">üî¨¬†torch.clamp</code></h3>

<p>ÏûÖÎ†• ÌÖêÏÑúÏùò ÏõêÏÜåÍ∞íÏùÑ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú ÏµúÎåÄ‚Ä¢ÏµúÏÜåÍ∞í Î≤îÏúÑ Ïù¥ÎÇ¥Î°ú Ï†úÌïúÌïòÎäî Î©îÏÑúÎìúÎã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.clamp params
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="err">‚Üí</span> <span class="n">Tensor</span>

<span class="c1"># torch.clamp usage example
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.7120</span><span class="p">,</span>  <span class="mf">0.1734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0478</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0922</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5000</span><span class="p">,</span>  <span class="mf">0.1734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0478</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0922</span><span class="p">])</span>
</code></pre></div></div>

<p>ÏûÖÎ†•Îêú ÌÖêÏÑúÏùò ÏõêÏÜåÎ•º ÏßÄÏ†ï ÏµúÎåÄ‚Ä¢ÏµúÏÜå ÏÑ§Ï†ïÍ∞íÍ≥º ÌïòÎÇò ÌïòÎÇò ÎåÄÏ°∞Ìï¥ÏÑú ÌÖêÏÑú ÎÇ¥Î∂ÄÏùò Î™®Îì† ÏõêÏÜåÍ∞Ä ÏßÄÏ†ï Î≤îÏúÑ ÏïàÏóê Îì§ÎèÑÎ°ù ÎßåÎì§Ïñ¥Ï§ÄÎã§. <code class="language-plaintext highlighter-rouge">torch.clamp</code> Ïó≠Ïãú Îã§ÏñëÌïú ÏÉÅÌô©ÏóêÏÑú ÏÇ¨Ïö©ÎêòÎäîÎç∞, ÌïÑÏûêÏùò Í≤ΩÏö∞ Î™®Îç∏ Î†àÏù¥Ïñ¥ Ï§ëÍ∞ÑÏóê Ï†úÍ≥±Í∑ºÏù¥ÎÇò ÏßÄÏàò, Î∂ÑÏàò ÌòπÏùÄ Í∞ÅÎèÑ Í¥ÄÎ†® Ïó∞ÏÇ∞Ïù¥ Îì§Ïñ¥Í∞Ä <code class="language-plaintext highlighter-rouge">Backward Pass</code>ÏóêÏÑú <code class="language-plaintext highlighter-rouge">NaN</code>Ïù¥ Î∞úÏÉùÌï† Ïàò ÏûàÎäî Í≤ΩÏö∞Ïóê ÏïàÏ†ÑÏû•ÏπòÎ°ú ÎßéÏù¥ ÏÇ¨Ïö©ÌïòÍ≥† ÏûàÎã§. (<a href="https://qcqced123.github.io/framework-library/backward-nan/">ÏûêÏÑ∏Ìûà ÏïåÍ≥† Ïã∂Îã§Î©¥ ÌÅ¥Î¶≠</a>)</p>

<h3 id="torchgather"><code class="language-plaintext highlighter-rouge">üë©‚Äçüë©‚Äçüëß‚Äçüë¶¬†torch.gather</code></h3>

<p>ÌÖêÏÑú Í∞ùÏ≤¥ ÎÇ¥Î∂ÄÏóêÏÑú ÏõêÌïòÎäî Ïù∏Îç±Ïä§Ïóê ÏúÑÏπòÌïú ÏõêÏÜåÎßå Ï∂îÏ∂úÌïòÍ≥† Ïã∂ÏùÑ Îïå ÏÇ¨Ïö©ÌïòÎ©¥ Îß§Ïö∞ Ïú†Ïö©Ìïú Î©îÏÑúÎìúÎã§. ÌÖêÏÑú Ïó≠Ïãú <code class="language-plaintext highlighter-rouge">iterable</code> Í∞ùÏ≤¥ÎùºÏÑú <code class="language-plaintext highlighter-rouge">loop</code> Î•º ÏÇ¨Ïö©Ìï¥ Ï†ëÍ∑ºÌïòÎäî Í≤ÉÏù¥ ÏßÅÍ¥ÄÏ†ÅÏúºÎ°ú Î≥¥Ïùº Ïàò ÏûàÏúºÎÇò, ÌÜµÏÉÅÏ†ÅÏúºÎ°ú ÌÖêÏÑúÎ•º ÏÇ¨Ïö©ÌïòÎäî ÏÉÅÌô©Ïù¥ÎùºÎ©¥ Í∞ùÏ≤¥Ïùò Ï∞®ÏõêÏù¥ Ïñ¥ÎßàÎ¨¥Ïãú ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê Î£®ÌîÑÎ°ú Ï†ëÍ∑ºÌï¥ Í¥ÄÎ¶¨ÌïòÎäî Í≤ÉÏùÄ Îß§Ïö∞ ÎπÑÌö®Ïú®Ï†ÅÏù¥Îã§. Î£®ÌîÑÎ•º ÌÜµÌï¥ Ï†ëÍ∑ºÌïòÎ©¥ ÌååÏù¥Ïç¨Ïùò ÎÇ¥Ïû• Î¶¨Ïä§Ìä∏Î•º ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÍ≥º Î≥ÑÎ∞ò Îã§Î•ºÍ≤å ÏóÜÏñ¥ÏßÄÍ∏∞ ÎïåÎ¨∏Ïóê, ÌÖêÏÑúÎ•º ÏÇ¨Ïö©ÌïòÎäî Î©îÎ¶¨Ìä∏Í∞Ä ÏÇ¨ÎùºÏßÑÎã§. ÎπÑÍµêÏ†Å ÌÅ¨ÏßÄ ÏïäÏùÄ 2~3Ï∞®ÏõêÏùò ÌÖêÏÑú Ï†ïÎèÑÎùºÎ©¥ ÏÇ¨Ïö©Ìï¥ÎèÑ ÌÅ¨Í≤å Î¨∏Ï†úÎäî ÏóÜÏùÑÍ±∞Îùº ÏÉùÍ∞ÅÌïòÏßÄÎßå Í∑∏ÎûòÎèÑ ÏΩîÎìúÏùò ÏùºÍ¥ÄÏÑ±ÏùÑ ÏúÑÌï¥ <code class="language-plaintext highlighter-rouge">torch.gather</code> ÏÇ¨Ïö©ÏùÑ Í∂åÏû•ÌïúÎã§. Ïù¥Ï†ú <code class="language-plaintext highlighter-rouge">torch.gather</code>Ïùò ÏÇ¨Ïö©Î≤ïÏóê ÎåÄÌï¥ ÏïåÏïÑÎ≥¥Ïûê.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.gather params
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">dim</code>Í≥º <code class="language-plaintext highlighter-rouge">index</code>Ïóê Ï£ºÎ™©Ìï¥Î≥¥Ïûê. Î®ºÏ†Ä <code class="language-plaintext highlighter-rouge">dim</code>ÏùÄ ÏÇ¨Ïö©ÏûêÍ∞Ä Ïù∏Îç±Ïã±ÏùÑ Ï†ÅÏö©ÌïòÍ≥† Ïã∂ÏùÄ Ï∞®ÏõêÏùÑ ÏßÄÏ†ïÌï¥Ï£ºÎäî Ïó≠Ìï†ÏùÑ ÌïúÎã§. <code class="language-plaintext highlighter-rouge">index</code> Îß§Í∞úÎ≥ÄÏàòÎ°ú Ï†ÑÎã¨ÌïòÎäî ÌÖêÏÑú ÏïàÏóêÎäî ÏõêÏÜåÏùò <code class="language-plaintext highlighter-rouge">‚ÄòÏù∏Îç±Ïä§‚Äô</code>Î•º ÏùòÎØ∏ÌïòÎäî Ïà´ÏûêÎì§Ïù¥ ÎßàÍµ¨Ïû°Ïù¥Î°ú Îã¥Í≤®ÏûàÎäîÎç∞, Ìï¥Îãπ Ïù∏Îç±Ïä§Í∞Ä ÎåÄÏÉÅ ÌÖêÏÑúÏùò Ïñ¥Îäê Ï∞®ÏõêÏùÑ Í∞ÄÎ¶¨ÌÇ¨ Í≤ÉÏù∏ÏßÄÎ•º Ïª¥Ìì®ÌÑ∞ÏóêÍ≤å ÏïåÎ†§Ï§ÄÎã§Í≥† ÏÉùÍ∞ÅÌïòÎ©¥ ÎêúÎã§. <code class="language-plaintext highlighter-rouge">index</code> Îäî ÏïûÏóêÏÑú ÏÑ§Î™ÖÌñàÎìØÏù¥ ÏõêÏÜåÏùò <code class="language-plaintext highlighter-rouge">‚ÄòÏù∏Îç±Ïä§‚Äô</code>Î•º ÏùòÎØ∏ÌïòÎäî Ïà´ÏûêÎì§Ïù¥ Îã¥Í∏¥ ÌÖêÏÑúÎ•º ÏûÖÎ†•ÏúºÎ°ú ÌïòÎäî Îß§Í∞úÎ≥ÄÏàòÎã§. Ïù¥ Îïå Ï£ºÏùòÌï† Ï†êÏùÄ ÎåÄÏÉÅ ÌÖêÏÑú(<code class="language-plaintext highlighter-rouge">input</code>)ÏôÄ Ïù∏Îç±Ïä§ ÌÖêÏÑúÏùò Ï∞®Ïõê ÌòïÌÉúÍ∞Ä Î∞òÎìúÏãú ÎèôÏùºÌï¥Ïïº ÌïúÎã§Îäî Í≤ÉÏù¥Îã§. Ïó≠Ïãú ÎßêÎ°úÎßå Îì§ÏúºÎ©¥ Ïù¥Ìï¥ÌïòÍ∏∞ ÌûòÎìúÎãà ÏÇ¨Ïö© ÏòàÏãúÎ•º Ìï®Íºê ÏÇ¥Ìé¥Î≥¥Ïûê.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.gather usage example
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">q</span><span class="p">,</span> <span class="n">kr</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span> <span class="c1"># [batch, sequence, dim_head], [batch, 2*sequence, dim_head]
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_c2p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">kr</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_c2p</span><span class="p">,</span> <span class="n">tmp_c2p</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">2.6477</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.7478</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.3250</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">1.6062</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9717</span><span class="p">,</span>  <span class="mf">3.8004</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.0662</span><span class="p">,</span>  <span class="mf">1.5240</span><span class="p">,</span>  <span class="mf">0.1182</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.1653</span><span class="p">,</span>  <span class="mf">2.8476</span><span class="p">,</span>  <span class="mf">1.6337</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.5010</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.2267</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1179</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">1.1447</span><span class="p">,</span>  <span class="mf">1.7845</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1493</span><span class="p">],</span>
         <span class="p">...,</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">2.1073</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2149</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.8630</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.8238</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5833</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2066</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.1747</span><span class="p">,</span>  <span class="mf">3.2924</span><span class="p">,</span>  <span class="mf">6.5808</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.2926</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2511</span><span class="p">,</span>  <span class="mf">2.6996</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">2.8362</span><span class="p">,</span>  <span class="mf">2.8700</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9729</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">4.9913</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3616</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">]],</span>
        <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">MmBackward0</span><span class="o">&gt;</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">max_seq</span><span class="p">,</span> <span class="n">max_relative_position</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">q_index</span><span class="p">,</span> <span class="n">k_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_seq</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">max_relative_position</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">q_index</span><span class="p">,</span> <span class="n">k_index</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span>   <span class="mi">0</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">2</span><span class="p">,</span>  <span class="p">...,</span> <span class="mi">1021</span><span class="p">,</span> <span class="mi">1022</span><span class="p">,</span> <span class="mi">1023</span><span class="p">]),</span>
 <span class="n">tensor</span><span class="p">([</span>   <span class="mi">0</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">2</span><span class="p">,</span>  <span class="p">...,</span> <span class="mi">1021</span><span class="p">,</span> <span class="mi">1022</span><span class="p">,</span> <span class="mi">1023</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_pos</span> <span class="o">=</span> <span class="n">q_index</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">k_index</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span> <span class="o">=</span> <span class="n">tmp_pos</span> <span class="o">+</span> <span class="n">max_relative_position</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mi">509</span><span class="p">,</span> <span class="o">-</span><span class="mi">510</span><span class="p">,</span> <span class="o">-</span><span class="mi">511</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mi">508</span><span class="p">,</span> <span class="o">-</span><span class="mi">509</span><span class="p">,</span> <span class="o">-</span><span class="mi">510</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mi">507</span><span class="p">,</span> <span class="o">-</span><span class="mi">508</span><span class="p">,</span> <span class="o">-</span><span class="mi">509</span><span class="p">],</span>
        <span class="p">...,</span>
        <span class="p">[</span><span class="mi">1533</span><span class="p">,</span> <span class="mi">1532</span><span class="p">,</span> <span class="mi">1531</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1534</span><span class="p">,</span> <span class="mi">1533</span><span class="p">,</span> <span class="mi">1532</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1535</span><span class="p">,</span> <span class="mi">1534</span><span class="p">,</span> <span class="mi">1533</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">rel_pos_matrix</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">max_relative_position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_c2p</span> <span class="o">=</span> <span class="n">tmp_c2p</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span><span class="p">,</span> <span class="n">rel_pos_matrix</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tmp_c2p</span><span class="p">.</span><span class="n">shape</span> 
<span class="p">(</span><span class="n">tensor</span><span class="p">([[[</span> <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">...,</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">]],</span>
 
         <span class="p">[[</span> <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">...,</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">]],</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]),</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">tmp_c2p</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rel_pos_matrix</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.8579</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2178</span><span class="p">,</span>  <span class="mf">1.6323</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">2.6477</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6477</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6477</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">1.1601</span><span class="p">,</span>  <span class="mf">2.1752</span><span class="p">,</span>  <span class="mf">0.7187</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0662</span><span class="p">,</span>  <span class="mf">0.0662</span><span class="p">,</span>  <span class="mf">0.0662</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">3.4379</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2573</span><span class="p">,</span>  <span class="mf">0.1375</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.5010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5010</span><span class="p">],</span>
         <span class="p">...,</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">1.2066</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2066</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2066</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.5943</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5169</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0820</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.6996</span><span class="p">,</span>  <span class="mf">2.6996</span><span class="p">,</span>  <span class="mf">2.6996</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.2014</span><span class="p">,</span>  <span class="mf">1.1458</span><span class="p">,</span>  <span class="mf">3.2626</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">1.9955</span><span class="p">,</span>  <span class="mf">4.1549</span><span class="p">,</span>  <span class="mf">2.6356</span><span class="p">]],</span>
</code></pre></div></div>

<p>ÏúÑ ÏΩîÎìúÎäî <code class="language-plaintext highlighter-rouge">DeBERTa</code> Ïùò <code class="language-plaintext highlighter-rouge">Disentangled Self-Attention</code>ÏùÑ Íµ¨ÌòÑÌïú ÏΩîÎìúÏùò ÏùºÎ∂ÄÎ∂ÑÏù¥Îã§. ÏûêÏÑ∏Ìïú ÏõêÎ¶¨Îäî <code class="language-plaintext highlighter-rouge">DeBERTa</code> ÎÖºÎ¨∏ Î¶¨Î∑∞ Ìè¨Ïä§ÌåÖÏóêÏÑú ÌôïÏù∏ÌïòÎ©¥ ÎêòÍ≥†, Ïö∞Î¶¨Í∞Ä ÏßÄÍ∏à Ï£ºÎ™©Ìï† Î∂ÄÎ∂ÑÏùÄ Î∞îÎ°ú <code class="language-plaintext highlighter-rouge">tmp_c2p</code>, <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> Í∑∏Î¶¨Í≥† ÎßàÏßÄÎßâ Ï§ÑÏóê ÏúÑÏπòÌïú <code class="language-plaintext highlighter-rouge">torch.gather</code> Îã§. <code class="language-plaintext highlighter-rouge">[10, 1024, 1024]</code> Î™®ÏñëÏùÑ Í∞ÄÏßÑ ÎåÄÏÉÅ ÌÖêÏÑú <code class="language-plaintext highlighter-rouge">tmp_c2p</code> ÏóêÏÑú ÎÇ¥Í∞Ä ÏõêÌïòÎäî ÏõêÏÜåÎßå Ï∂îÏ∂úÌïòÎ†§Îäî ÏÉÅÌô©Ïù∏Îç∞, Ï∂îÏ∂úÌï¥ÏïºÌï† ÏõêÏÜåÏùò Ïù∏Îç±Ïä§ Í∞íÏù¥ Îã¥Í∏¥ ÌÖêÏÑúÎ•º <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> Î°ú Ï†ïÏùòÌñàÎã§. <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> Ïùò Ï∞®ÏõêÏùÄ <code class="language-plaintext highlighter-rouge">[10, 1024, 1024]</code>Î°ú <code class="language-plaintext highlighter-rouge">tmp_c2p</code>ÏôÄ ÎèôÏùºÌïòÎã§. Ï∞∏Í≥†Î°ú Ï∂îÏ∂úÌï¥Ïïº ÌïòÎäî Ï∞®Ïõê Î∞©Ìñ•ÏùÄ Í∞ÄÎ°ú Î∞©Ìñ•(Îëê Î≤àÏß∏ 1024)Ïù¥Îã§.</p>

<p>Ïù¥Ï†ú <code class="language-plaintext highlighter-rouge">torch.gather</code>Ïùò ÎèôÏûëÏùÑ ÏÇ¥Ìé¥Î≥¥Ïûê. Ïö∞Î¶¨Í∞Ä ÌòÑÏû¨ Ï∂îÏ∂úÌïòÍ≥† Ïã∂ÏùÄ ÎåÄÏÉÅÏùÄ 3Ï∞®Ïõê ÌÖêÏÑúÏùò Í∞ÄÎ°ú Î∞©Ìñ•(Îëê Î≤àÏß∏ 1024, ÌÖêÏÑúÏùò Ìñâ Î≤°ÌÑ∞), Ï¶â <code class="language-plaintext highlighter-rouge">2 * max_sequence_length</code> Î•º ÏùòÎØ∏ÌïòÎäî Ï∞®Ïõê Î∞©Ìñ•Ïùò ÏõêÏÜåÎã§. Îî∞ÎùºÏÑú <code class="language-plaintext highlighter-rouge">dim=-1</code>ÏúºÎ°ú ÏÑ§Ï†ïÌï¥Ï§ÄÎã§. Ïù¥Ï†ú Î©îÏÑúÎìúÍ∞Ä ÏùòÎèÑÎåÄÎ°ú Ï†ÅÏö©ÎêòÏóàÎäîÏßÄ ÌôïÏù∏Ìï¥Î≥¥Ïûê. <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> Ïùò 0Î≤à Î∞∞Ïπò, 0Î≤àÏß∏ ÏãúÌÄÄÏä§Ïùò Í∞ÄÏû• ÎßàÏßÄÎßâ Ï∞®ÏõêÏùò Í∞íÏùÄ <code class="language-plaintext highlighter-rouge">0</code>ÏúºÎ°ú Ï¥àÍ∏∞Ìôî ÎêòÏñ¥ ÏûàÎã§. Îã§Ïãú ÎßêÌï¥, ÎåÄÏÉÅ ÌÖêÏÑúÏùò ÎåÄÏÉÅ Ï∞®ÏõêÏóêÏÑú 0Î≤àÏß∏ Ïù∏Îç±Ïä§Ïóê Ìï¥ÎãπÌïòÎäî Í∞íÏùÑ Í∞ÄÏ†∏Ïò§ÎùºÎäî ÏùòÎØ∏Î•º Îã¥Í≥† ÏûàÎã§. Í∑∏Î†áÎã§Î©¥ <code class="language-plaintext highlighter-rouge">torch.gather</code> Ïã§Ìñâ Í≤∞Í≥ºÍ∞Ä <code class="language-plaintext highlighter-rouge">tmp_c2p</code>Ïùò 0Î≤à Î∞∞Ïπò, 0Î≤àÏß∏ ÏãúÌÄÄÏä§Ïùò 0Î≤àÏß∏ Ï∞®Ïõê Í∞íÍ≥º ÏùºÏπòÌïòÎäîÏßÄ ÌôïÏù∏Ìï¥Î≥¥Ïûê. Îëò Îã§ <code class="language-plaintext highlighter-rouge">-2.6477</code>, <code class="language-plaintext highlighter-rouge">-2.6477</code> ÏúºÎ°ú Í∞ôÏùÄ Í∞íÏùÑ ÎÇòÌÉÄÎÇ¥Í≥† ÏûàÎã§. Îî∞ÎùºÏÑú Ïö∞Î¶¨ ÏùòÎèÑÎåÄÎ°ú Ïûò Ïã§ÌñâÎêòÏóàÎã§Îäî ÏÇ¨Ïã§ÏùÑ Ïïå Ïàò ÏûàÎã§.</p>

<h3 id="torchtriu-torchtril"><code class="language-plaintext highlighter-rouge">üë©‚Äçüë©‚Äçüëß‚Äçüë¶¬†torch.triu, torch.tril</code></h3>

<p>Í∞ÅÍ∞Å ÏûÖÎ†• ÌÖêÏÑúÎ•º <code class="language-plaintext highlighter-rouge">ÏÉÅÏÇºÍ∞ÅÌñâÎ†¨</code>, <code class="language-plaintext highlighter-rouge">ÌïòÏÇºÍ∞ÅÌñâÎ†¨</code>Î°ú ÎßåÎì†Îã§. <code class="language-plaintext highlighter-rouge">triu</code>ÎÇò <code class="language-plaintext highlighter-rouge">tril</code>ÏùÄ ÏÇ¨Ïã§ Îí§ÏßëÏúºÎ©¥ Í∞ôÏùÄ Í≤∞Í≥ºÎ•º Î∞òÌôòÌïòÍ∏∞ ÎïåÎ¨∏Ïóê <code class="language-plaintext highlighter-rouge">tril</code>ÏùÑ Í∏∞Ï§ÄÏúºÎ°ú ÏÑ§Î™ÖÏùÑ ÌïòÍ≤†Îã§. Î©îÏÑúÎìúÏùò Îß§Í∞úÎ≥ÄÏàòÎäî Îã§ÏùåÍ≥º Í∞ôÎã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.triu, tril params
</span><span class="n">upper_tri_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">triu</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">lower_tri_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">diagonal</code> Ïóê Ï£ºÎ™©Ìï¥Î≥¥Ïûê. ÏñëÏàòÎ•º Ï†ÑÎã¨ÌïòÎ©¥ Ï£ºÎåÄÍ∞ÅÏÑ±Î∂ÑÏóêÏÑú Ìï¥ÎãπÌïòÎäî Í∞íÎßåÌÅº Îñ®Ïñ¥ÏßÑ Í≥≥Ïùò ÎåÄÍ∞ÅÏÑ±Î∂ÑÍπåÏßÄ Í∑∏ Í∞íÏùÑ ÏÇ¥Î†§ÎëîÎã§. ÌïúÌé∏ ÏùåÏàòÎ•º Ï†ÑÎã¨ÌïòÎ©¥ Ï£ºÎåÄÍ∞ÅÏÑ±Î∂ÑÏùÑ Ìè¨Ìï®Ìï¥ Ï£ºÏñ¥ÏßÑ Í∞íÎßåÌÅº Îñ®Ïñ¥ÏßÑ Í≥≥ÍπåÏßÄÏùò ÎåÄÍ∞ÅÏÑ±Î∂ÑÏùÑ Î™®Îëê 0ÏúºÎ°ú ÎßåÎì§Ïñ¥Î≤ÑÎ¶∞Îã§. Í∏∞Î≥∏ÏùÄ 0ÏúºÎ°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏúºÎ©∞, Ïù¥Îäî Ï£ºÎåÄÍ∞ÅÏÑ±Î∂ÑÎ∂ÄÌÑ∞ ÏôºÏ™Ω ÌïòÎã®Ïùò ÏõêÏÜåÎ•º Î™®Îëê ÏÇ¥Î†§ÎëêÍ≤†Îã§Îäî ÏùòÎØ∏Í∞Ä ÎêúÎã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.tril usage example
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span>
</code></pre></div></div>

<p>Îëê Î©îÏÑúÎìúÎäî ÏÑ†ÌòïÎåÄÏàòÌïôÏù¥ ÌïÑÏöîÌïú Îã§ÏñëÌïú Î∂ÑÏïºÏóêÏÑú ÏÇ¨Ïö©ÎêòÎäîÎç∞, ÌïÑÏûêÏùò Í≤ΩÏö∞, <code class="language-plaintext highlighter-rouge">GPT</code>Ï≤òÎüº <code class="language-plaintext highlighter-rouge">Transformer</code>Ïùò <code class="language-plaintext highlighter-rouge">Decoder</code> Î•º ÏÇ¨Ïö©ÌïòÎäî Î™®Îç∏ÏùÑ ÎπåÎìúÌï† Îïå Í∞ÄÏû• ÎßéÏù¥ ÏÇ¨Ïö©ÌñàÎçò Í≤É Í∞ôÎã§. <code class="language-plaintext highlighter-rouge">Decoder</code>Î•º ÏÇ¨Ïö©ÌïòÎäî Î™®Îç∏ÏùÄ ÎåÄÎ∂ÄÎ∂Ñ Íµ¨Ï°∞ÏÉÅ <code class="language-plaintext highlighter-rouge">Language Modeling</code>ÏùÑ ÏúÑÌï¥ÏÑú <code class="language-plaintext highlighter-rouge">Masked Multi-Head Self-Attention Block</code>ÏùÑ ÏÇ¨Ïö©ÌïòÎäîÎç∞ Ïù¥ Îïå ÎØ∏Îûò ÏãúÏ†êÏùò ÌÜ†ÌÅ∞ ÏûÑÎ≤†Îî© Í∞íÏóê ÎßàÏä§ÌÇπÏùÑ Ìï¥Ï£ºÍ∏∞ ÏúÑÌï¥ <code class="language-plaintext highlighter-rouge">torch.tril</code> ÏùÑ ÏÇ¨Ïö©ÌïòÍ≤å ÎêòÎãà Ï∞∏Í≥†ÌïòÏûê.</p>

<h3 id="torchtensormasked_fill"><code class="language-plaintext highlighter-rouge">üë©‚Äçüë©‚Äçüëß‚Äçüë¶¬†torch.Tensor.masked_fill</code></h3>

<p>ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú Í∞íÏóê Ìï¥ÎãπÎêòÎäî ÏõêÏÜåÎ•º Î™®Îëê ÎßàÏä§ÌÇπ Ï≤òÎ¶¨Ìï¥Ï£ºÎäî Î©îÏÑúÎìúÎã§. Î®ºÏ†Ä Îß§Í∞úÎ≥ÄÏàòÎ•º ÌôïÏù∏Ìï¥Î≥¥Ïûê.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.Tensor.masked_fill params
</span><span class="n">input_tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">input_tensors</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">:</span> <span class="n">BoolTensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">masked_fill</code> ÏùÄ ÌÖêÏÑú Í∞ùÏ≤¥Ïùò ÎÇ¥Î∂Ä <code class="language-plaintext highlighter-rouge">attribute</code> Î°ú Ï†ïÏùòÎêòÍ∏∞ ÎïåÎ¨∏Ïóê Ìï¥Îãπ Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©ÌïòÍ≥† Ïã∂Îã§Î©¥ Î®ºÏ†Ä ÎßàÏä§ÌÇπ ÎåÄÏÉÅ ÌÖêÏÑúÎ•º ÎßåÎì§Ïñ¥Ïïº ÌïúÎã§. ÌÖêÏÑúÎ•º Ï†ïÏùòÌñàÎã§Î©¥ ÌÖêÏÑú Í∞ùÏ≤¥Ïùò <code class="language-plaintext highlighter-rouge">attributes</code> Ï†ëÍ∑ºÏùÑ ÌÜµÌï¥ <code class="language-plaintext highlighter-rouge">masked_fill()</code> ÏùÑ Ìò∏Ï∂úÌïú Îí§, ÌïÑÏöîÌïú Îß§Í∞úÎ≥ÄÏàòÎ•º Ï†ÑÎã¨Ìï¥Ï£ºÎäî Î∞©ÏãùÏúºÎ°ú ÏÇ¨Ïö©ÌïòÎ©¥ ÎêúÎã§.</p>

<p><code class="language-plaintext highlighter-rouge">mask</code> Îß§Í∞úÎ≥ÄÏàòÏóêÎäî ÎßàÏä§ÌÇπ ÌÖêÏÑúÎ•º Ï†ÑÎã¨Ìï¥Ïïº ÌïòÎäîÎç∞, Ïù¥ Îïå ÎÇ¥Î∂Ä ÏõêÏÜåÎäî Î™®Îëê <code class="language-plaintext highlighter-rouge">boolean</code>Ïù¥Ïñ¥Ïïº ÌïòÍ≥† ÌÖêÏÑúÏùò ÌòïÌÉúÎäî ÎåÄÏÉÅ ÌÖêÏÑúÏôÄ ÎèôÏùºÌï¥Ïïº ÌïúÎã§(ÏôÑÏ†ÑÌûà Í∞ôÏùÑ ÌïÑÏöîÎäî ÏóÜÍ≥†, Î∏åÎ°úÎìú Ï∫êÏä§ÌåÖÎßå Í∞ÄÎä•ÌïòÎ©¥ ÏÉÅÍ¥Ä ÏóÜÏùå).</p>

<p><code class="language-plaintext highlighter-rouge">value</code> Îß§Í∞úÎ≥ÄÏàòÏóêÎäî ÎßàÏä§ÌÇπ ÎåÄÏÉÅ ÏõêÏÜåÎì§Ïóê ÏùºÍ¥ÑÏ†ÅÏúºÎ°ú Ï†ÅÏö©Ìï¥Ï£ºÍ≥† Ïã∂ÏùÄ Í∞íÏùÑ Ï†ÑÎã¨ÌïúÎã§. Ïù¥Í≤å ÎßêÎ°úÎßå Îì§ÏúºÎ©¥ Ïù¥Ìï¥ÌïòÍ∏∞ ÏâΩÏßÄ ÏïäÎã§. ÏïÑÎûò ÏÇ¨Ïö© ÏòàÏãúÎ•º Ìï®Íªò Ï≤®Î∂ÄÌñàÏúºÎãà Ï∞∏Í≥† Î∞îÎûÄÎã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.masked_fill usage
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">dot_scale</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">1.2</span> <span class="mf">1.1</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="mf">9.9</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="mf">9.9</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="mf">9.9</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">attention_matrix</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">lm_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span>
<span class="mf">1.22</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="o">-</span><span class="n">inf</span>
</code></pre></div></div>

<h3 id="Ô∏ètorchclone"><code class="language-plaintext highlighter-rouge">üóÇÔ∏è¬†torch.clone</code></h3>

<p><code class="language-plaintext highlighter-rouge">inputs</code> Ïù∏ÏûêÎ°ú Ï†ÑÎã¨Ìïú ÌÖêÏÑúÎ•º Î≥µÏÇ¨ÌïòÎäî ÌååÏù¥ÌÜ†Ïπò ÎÇ¥Ïû• Î©îÏÑúÎìúÎã§.  ÏÇ¨Ïö©Î≤ïÏùÄ ÏïÑÎûòÏôÄ Í∞ôÎã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">""" torch.clone """</span>
<span class="n">torch</span><span class="p">.</span><span class="n">clone</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span><span class="err">¬†</span>
    <span class="o">*</span><span class="p">,</span>
   <span class="err">¬†</span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">preserve_format</span>
<span class="p">)</span><span class="err">¬†‚Üí¬†</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
</code></pre></div></div>

<p>Îî•Îü¨Îãù ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ ÎßåÎì§Îã§ Î≥¥Î©¥ ÎßéÏù¥ ÏÇ¨Ïö©ÌïòÍ≤å ÎêòÎäî Í∏∞Î≥∏Ï†ÅÏù∏ Î©îÏÑúÎìúÏù∏Îç∞, Ïù¥Î†áÍ≤å Îî∞Î°ú Ï†ïÎ¶¨ÌïòÍ≤å Îêú Ïù¥Ïú†Í∞Ä ÏûàÎã§. ÏûÖÎ†•Îêú ÌÖêÏÑúÎ•º Í∑∏ÎåÄÎ°ú Î≥µÏÇ¨ÌïúÎã§Îäî ÌäπÏÑ± ÎïåÎ¨∏Ïóê ÏÇ¨Ïö©Ïãú Ï£ºÏùòÌï¥Ïïº Ìï† Ï†êÏù¥ ÏûàÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§. Ìï¥Îãπ Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©ÌïòÍ∏∞ Ï†ÑÏóê Î∞òÎìúÏãú ÏûÖÎ†•Ìï† ÌÖêÏÑúÍ∞Ä ÌòÑÏû¨ Ïñ¥Îäê ÎîîÎ∞îÏù¥Ïä§(CPU, GPU) ÏúÑÏóê ÏûàÎäîÏßÄ, Í∑∏Î¶¨Í≥† Ìï¥Îãπ ÌÖêÏÑúÍ∞Ä Í≥ÑÏÇ∞ Í∑∏ÎûòÌîÑÎ•º Í∞ÄÏßÄÍ≥† ÏûàÎäîÏßÄÎ•º <strong>Î∞òÎìúÏãú</strong> ÌååÏïÖÌï¥Ïïº ÌïúÎã§.</p>

<p>ÌïÑÏûêÎäî ELECTRA Î™®Îç∏ÏùÑ ÏßÅÏ†ë Íµ¨ÌòÑÌïòÎäî Í≥ºÏ†ïÏóêÏÑú <code class="language-plaintext highlighter-rouge">clone()</code> Î©îÏÑúÎìúÎ•º ÏÇ¨Ïö©ÌñàÎäîÎç∞, Generator Î™®Îç∏Ïùò Í≤∞Í≥º Î°úÏßìÏùÑ DiscriminatorÏùò ÏûÖÎ†•ÏúºÎ°ú Î≥ÄÌôòÌï¥Ï£ºÍ∏∞ ÏúÑÌï®Ïù¥ÏóàÎã§. Í∑∏ Í≥ºÏ†ïÏóêÏÑú GeneratorÍ∞Ä Î∞òÌôòÌïú Î°úÏßìÏùÑ Í∑∏ÎåÄÎ°ú <code class="language-plaintext highlighter-rouge">clone</code>Ìïú Îí§, ÏûÖÎ†•ÏùÑ ÎßåÎì§Ïñ¥ Ï£ºÏóàÍ≥† Í∑∏ Í≤∞Í≥º ÏïÑÎûòÏôÄ Í∞ôÏùÄ ÏóêÎü¨Î•º ÎßàÏ£ºÌñàÎã§.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">RuntimeError</span><span class="p">:</span> <span class="n">one</span> <span class="n">of</span> <span class="n">the</span> <span class="n">variables</span> <span class="n">needed</span> <span class="k">for</span> <span class="n">gradient</span> <span class="n">computation</span> <span class="n">has</span> <span class="n">been</span> <span class="n">modified</span> <span class="n">by</span> <span class="n">an</span> <span class="n">inplace</span> <span class="n">operation</span><span class="p">:</span> <span class="p">[</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">LongTensor</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">511</span><span class="p">]]</span> <span class="ow">is</span> <span class="n">at</span> <span class="n">version</span> <span class="mi">1</span><span class="p">;</span> <span class="n">expected</span> <span class="n">version</span> <span class="mi">0</span> 
<span class="n">instead</span><span class="p">.</span> <span class="n">Hint</span><span class="p">:</span> <span class="n">the</span> <span class="n">backtrace</span> <span class="n">further</span> <span class="n">above</span> <span class="n">shows</span> <span class="n">the</span> <span class="n">operation</span> <span class="n">that</span> <span class="n">failed</span> <span class="n">to</span> <span class="n">compute</span> <span class="n">its</span> <span class="n">gradient</span><span class="p">.</span> 
<span class="n">The</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">question</span> <span class="n">was</span> <span class="n">changed</span> <span class="ow">in</span> <span class="n">there</span> <span class="ow">or</span> <span class="n">anywhere</span> <span class="n">later</span><span class="p">.</span> <span class="n">Good</span> <span class="n">luck</span><span class="err">!</span>
</code></pre></div></div>

<p>ÏóêÎü¨ Î°úÍ∑∏Î•º ÏûêÏÑ∏Ìûà ÏùΩÏñ¥Î≥¥Î©¥ ÌÖêÏÑú Î≤ÑÏ†ÑÏùò Î≥ÄÍ≤ΩÏúºÎ°ú Ïù∏Ìï¥ Í∑∏ÎùºÎîîÏñ∏Ìä∏ Í≥ÑÏÇ∞Ïù¥ Î∂àÍ∞ÄÌïòÎã§Îäî ÎÇ¥Ïö©Ïù¥ Îã¥Í≤®ÏûàÎã§. Íµ¨Í∏ÄÎßÅÌï¥Î¥êÎèÑ Ïûò ÏïàÎÇòÏôÄÏÑú Ìè¨Í∏∞ÌïòÎ†§Îçò Ï∞∞ÎùºÏóê Ïö∞Ïó∞Ìûà <code class="language-plaintext highlighter-rouge">torch.clone()</code> Î©îÏÑúÎìúÏùò Ï†ïÌôïÌïú ÏÇ¨Ïö©Î≤ïÏù¥ Í∂ÅÍ∏àÌï¥ Í≥µÏãù DocsÎ•º ÏùΩÍ≤å ÎêòÏóàÍ≥†, Í±∞Í∏∞ÏÑú ÏóÑÏ≤≠ÎÇú ÏÇ¨Ïã§ÏùÑ Î∞úÍ≤¨ÌñàÎã§. <code class="language-plaintext highlighter-rouge">clone()</code> Î©îÏÑúÎìúÍ∞Ä ÏûÖÎ†•Îêú ÌÖêÏÑúÏùò ÌòÑÏû¨ ÎîîÎ∞îÏù¥Ïä§ ÏúÑÏπòÏóê ÎòëÍ∞ôÏù¥ Î≥µÏÇ¨Îê† Í≤ÉÏù¥ÎûÄ ÏòàÏÉÅÏùÄ ÌñàÏßÄÎßå, ÏûÖÎ†• ÌÖêÏÑúÏùò Í≥ÑÏÇ∞Í∑∏ÎûòÌîÑÍπåÏßÄ Î≥µÏÇ¨Îê† Í≤ÉÏù¥ÎûÄ ÏÉùÍ∞ÅÏùÄ Ï†ÑÌòÄ ÌïòÏßÄ Î™ªÌñàÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§. Í∑∏ÎûòÏÑú ÏúÑÏôÄ Í∞ôÏùÄ ÏóêÎü¨Î•º ÎßàÏ£ºÌïòÏßÄ ÏïäÏúºÎ†§Î©¥, <code class="language-plaintext highlighter-rouge">clone()</code>ÏùÑ Ìò∏Ï∂úÌï† Îïå Îí§Ïóê Î∞òÎìúÏãú <code class="language-plaintext highlighter-rouge">detach()</code>Î•º Ìï®Íªò Ìò∏Ï∂úÌï¥Ï§òÏïº ÌïúÎã§.</p>

<p><code class="language-plaintext highlighter-rouge">clone()</code> Î©îÏÑúÎìúÎäî ÏûÖÎ†•Îêú ÌÖêÏÑúÏùò Î™®Îì† Í≤ÉÏùÑ Î≥µÏÇ¨ÌïúÎã§Îäî Ï†êÏùÑ Î∞òÎìúÏãú Í∏∞ÏñµÌïòÏûê.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#linear-algebra" class="page__taxonomy-item p-category" rel="tag">Linear Algebra</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">Pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#tensor" class="page__taxonomy-item p-category" rel="tag">Tensor</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#framework-library" class="page__taxonomy-item p-category" rel="tag">Framework & Library</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-01-09">January 9, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%F0%9F%94%A5%C2%A0Pytorch+Tensor+Indexing+%EC%9E%90%EC%A3%BC+%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94+%EB%A9%94%EC%84%9C%EB%93%9C+%EB%AA%A8%EC%9D%8C%EC%A7%91%20http%3A%2F%2Flocalhost%3A4000%2Fframework-library%2Ftorch-indexing-function" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fframework-library%2Ftorch-indexing-function" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fframework-library%2Ftorch-indexing-function" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/optimization-theory/product_quotient_rule" class="pagination--pager" title="üî¢¬†Product &amp; Quotient Rule: Í≥±Ïùò ÎØ∏Î∂Ñ, Î™´Ïùò ÎØ∏Î∂Ñ
">Previous</a>
    
    
      <a href="/ps/baekjoon-1987" class="pagination--pager" title="üë©‚ÄçüíªüéÑ [baekjoon] 1987Î≤à: ÏïåÌååÎ≤≥
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/lora" rel="permalink">üî™ [LoRA] Low-Rank Adaptation of Large Language Models
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          12 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 28 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">LoRA Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/time_complexity2" rel="permalink">üë®‚è∞üêç¬†[Python] ÏãúÍ∞ÑÎ≥µÏû°ÎèÑ 2
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 26 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ÏãúÍ∞Ñ Î≥µÏû°ÎèÑ Ï§ÑÏù¥Í∏∞
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/time_complexity1" rel="permalink">üë®‚è∞üêç¬†[Python] ÏãúÍ∞ÑÎ≥µÏû°ÎèÑ 1
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 26 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ÏãúÍ∞Ñ Î≥µÏû°ÎèÑÏóê ÎåÄÌïú Ïù¥Ìï¥
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/linear_attention" rel="permalink">üåÜ [Linear Attention] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 14 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Linear Attention Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 qcqced. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'qcqced123/qcqced123.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
});
</script>

  </body>
</html>
