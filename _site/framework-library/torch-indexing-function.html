<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>ğŸ”¥Â Pytorch Tensor Indexing ìì£¼ ì‚¬ìš©í•˜ëŠ” ë©”ì„œë“œ ëª¨ìŒì§‘ - AI/Business Study Log</title>
<meta name="description" content="íŒŒì´í† ì¹˜ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” í…ì„œ ì¸ë±ì‹± ê´€ë ¨ ë©”ì„œë“œ ëª¨ìŒ">


  <meta name="author" content="qcqced">
  
  <meta property="article:author" content="qcqced">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="AI/Business Study Log">
<meta property="og:title" content="ğŸ”¥Â Pytorch Tensor Indexing ìì£¼ ì‚¬ìš©í•˜ëŠ” ë©”ì„œë“œ ëª¨ìŒì§‘">
<meta property="og:url" content="http://localhost:4000/framework-library/torch-indexing-function">


  <meta property="og:description" content="íŒŒì´í† ì¹˜ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” í…ì„œ ì¸ë±ì‹± ê´€ë ¨ ë©”ì„œë“œ ëª¨ìŒ">







  <meta property="article:published_time" content="2024-01-09T00:00:00+09:00">



  <meta property="article:modified_time" content="2024-01-10T02:00:00+09:00">



  

  


<link rel="canonical" href="http://localhost:4000/framework-library/torch-indexing-function">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "qcqced",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="AI/Business Study Log Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



<!-- Latex -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon-16x16.png">
<link rel="manifest" href="/assets/site.webmanifest">
<link rel="mask-icon" href="/assets/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<!-- end custom head snippets -->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      TeX: {
        equationNumbers: {
          autoNumber: "AMS"
        }
      },
      tex2jax: {
      inlineMath: [ ['$', '$'] ],
      displayMath: [ ['$$', '$$'] ],
      processEscapes: true
    }
  });
  MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
      alert("Math Processing Error: "+message[1]);
    });
  </script>
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          AI/Business Study Log
          <span class="site-subtitle">NLP, Marketing</span>
        </a>
        
        
        <ul class="visible-links">
              
              
                  <li class="masthead__menu-item">
                      <a href="https://qcqced123.github.io/">Home</a>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">CS/AI  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/nlp/">    Natural Language Process</a>
                          
                              <a class = "dropdown-item" href="/multi-modal/">    Multi Modal</a>
                          
                              <a class = "dropdown-item" href="/cv/">    Computer Vision</a>
                          
                              <a class = "dropdown-item" href="/ml/">    Machine Learning</a>
                          
                              <a class = "dropdown-item" href="/framework-library/">    Framework & Library</a>
                          
                              <a class = "dropdown-item" href="/python/">    Python</a>
                          
                              <a class = "dropdown-item" href="/algorithm/">    Data Structure & Algorithm</a>
                          
                              <a class = "dropdown-item" href="/ps/">    Problem Solving</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Math  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/linear-algebra/">    Linear Algebra</a>
                          
                              <a class = "dropdown-item" href="/optimization-theory/">    Optimization Theory/Calculus</a>
                          
                              <a class = "dropdown-item" href="/signal-system/">    Signal & System</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="dropdown ">
                      <a class="dropdown-toggle" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Business/Marketing  <i class="fa fa-caret-down fa-sm" aria-hidden="true"></i><span class="caret"></span></a>
       
                      <ul class="dropdown-content" >
                          
                              <a class = "dropdown-item" href="/device/">    Device</a>
                          
                              <a class = "dropdown-item" href="/semi-conductor/">    Semi-Conductor</a>
                          
                              <a class = "dropdown-item" href="/ai/">    AI</a>
                          
                      </ul>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/categories/">Category</a>
                  </li>
              
          
              
              
                  <li class="masthead__menu-item">
                      <a href="/about/">About</a>
                  </li>
              
          
       </ul>
       
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/huggingface_emoji.png" alt="qcqced" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">qcqced</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Interested in NLP, Marketing</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Seoul, South Korea</span>
        </li>
      

      
        
          
            <li><a href="https://qcqced123.github.io" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-link" aria-hidden="true"></i><span class="label">Website</span></a></li>
          
        
          
            <li><a href="https://github.com/qcqced123" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
            <li><a href="https://www.kaggle.com/qcqced" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-kaggle" aria-hidden="true"></i><span class="label">Kaggle</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:qcqced123@gmail.com" rel="me" class="u-email">
            <meta itemprop="email" content="qcqced123@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="ğŸ”¥Â Pytorch Tensor Indexing ìì£¼ ì‚¬ìš©í•˜ëŠ” ë©”ì„œë“œ ëª¨ìŒì§‘">
    <meta itemprop="description" content="íŒŒì´í† ì¹˜ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” í…ì„œ ì¸ë±ì‹± ê´€ë ¨ ë©”ì„œë“œ ëª¨ìŒ">
    <meta itemprop="datePublished" content="2024-01-09T00:00:00+09:00">
    <meta itemprop="dateModified" content="2024-01-10T02:00:00+09:00">

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/framework-library/torch-indexing-function" class="u-url" itemprop="url">ğŸ”¥Â Pytorch Tensor Indexing ìì£¼ ì‚¬ìš©í•˜ëŠ” ë©”ì„œë“œ ëª¨ìŒì§‘
</a>
          </h1>
          <p class="page__date">
            <a href="https://hits.seeyoufarm.com/localhost:4000/framework-library/torch-indexing-function"target="_blank">
              <img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https://localhost:4000/framework-library/torch-indexing-function&count_bg=%23399DE2&title_bg=%236D6D6D&icon=pytorch.svg&icon_color=%23E7E7E7&title=Views&edge_flat=false"/>
            </a>
            <i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated: <time datetime="2024-01-09T00:00:00+09:00">January 09, 2024</time>
            <!-- <div style="text-align: left;"> -->
            <!-- </div> -->
          </p>
          
          
        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#torchargmax">ğŸ”Â torch.argmax</a></li><li><a href="#torchstack">ğŸ“šÂ torch.stack</a></li><li><a href="#torcharange">ğŸ”¢Â torch.arange</a></li><li><a href="#torchrepeat">ğŸ”Â torch.repeat</a></li><li><a href="#torchclamp">ğŸ”¬Â torch.clamp</a></li><li><a href="#torchgather">ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦Â torch.gather</a></li><li><a href="#torchtriu-torchtril">ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦Â torch.triu, torch.tril</a></li><li><a href="#torchtensormasked_fill">ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦Â torch.Tensor.masked_fill</a></li><li><a href="#ï¸torchclone">ğŸ—‚ï¸Â torch.clone</a></li></ul>

            </nav>
          </aside>
        
        <p>íŒŒì´í† ì¹˜ì—ì„œ í•„ìê°€ ìì£¼ ì‚¬ìš©í•˜ëŠ” í…ì„œ ì¸ë±ì‹± ê´€ë ¨ ë©”ì„œë“œì˜ ì‚¬ìš©ë²• ë° ì‚¬ìš© ì˜ˆì‹œë¥¼ í•œë°©ì— ì •ë¦¬í•œ í¬ìŠ¤íŠ¸ë‹¤. ë©”ì„œë“œ í•˜ë‚˜ë‹¹ í•˜ë‚˜ì˜ í¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°ì—ëŠ” ë„ˆë¬´ ê¸¸ì´ê°€ ì§§ë‹¤ ìƒê°í•´ í•œ í˜ì´ì§€ì— ëª¨ë‘ ë„£ê²Œ ë˜ì—ˆë‹¤. ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ë  ì˜ˆì •ì´ë‹¤. ë˜í•œ í…ì„œ ì¸ë±ì‹± ë§ê³ ë„ ë‹¤ë¥¸ ì£¼ì œë¡œë„ ê´€ë ¨ ë©”ì„œë“œë¥¼ ì •ë¦¬í•´ ì˜¬ë¦´ ì˜ˆì •ì´ë‹ˆ ë§ì€ ê´€ì‹¬ ë¶€íƒë“œë¦°ë‹¤.</p>

<h3 id="torchargmax"><code class="language-plaintext highlighter-rouge">ğŸ”Â torch.argmax</code></h3>

<p>ì…ë ¥ í…ì„œì—ì„œ ê°€ì¥ í° ê°’ì„ ê°–ê³  ìˆëŠ” ì›ì†Œì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•œë‹¤. ìµœëŒ€ê°’ì„ ì°¾ì„ ì°¨ì›ì„ ì§€ì •í•´ì¤„ ìˆ˜ ìˆë‹¤. ì•„ë˜ ì˜ˆì‹œ ì½”ë“œë¥¼ í™•ì¸í•´ë³´ì.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.argmax params
</span><span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># torch.argmax example 1
</span><span class="n">test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">29</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">45</span><span class="p">,</span><span class="mi">22</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test2</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="o">&lt;</span><span class="n">Result</span><span class="o">&gt;</span>
<span class="n">tensor</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># torch.argmax example 2
</span><span class="n">test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                     <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="o">&lt;</span><span class="n">Result</span><span class="o">&gt;</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="c1"># torch.argmax example 3
</span><span class="n">test</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
                     <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>

<span class="n">torch</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">]])</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">dim</code> ë§¤ê°œë³€ìˆ˜ì— ì›í•˜ëŠ” ì°¨ì›ì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ì°¨ì› ë·°ì—ì„œ ê°€ì¥ í° ì›ì†Œë¥¼ ì°¾ì•„ ì¸ë±ìŠ¤ ê°’ì„ ë°˜í™˜í•´ì¤„ ê²ƒì´ë‹¤. ì´ ë•Œ <code class="language-plaintext highlighter-rouge">keepdim=True</code> ë¡œ ì„¤ì •í•œë‹¤ë©´ ì…ë ¥ ì°¨ì›ì—ì„œ ê°€ì¥ í° ì›ì†Œì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜í•˜ë˜ ì›ë³¸ í…ì„œì˜ ì°¨ì›ê³¼ ë™ì¼í•œ í˜•íƒœë¡œ ì¶œë ¥í•´ì¤€ë‹¤. <code class="language-plaintext highlighter-rouge">example 2</code> ì˜ ê²½ìš° <code class="language-plaintext highlighter-rouge">dim=0</code> ë¼ì„œ í–‰ì´ ëˆ„ì ëœ ë°©í–¥ìœ¼ë¡œ í…ì„œë¥¼ ë°”ë¼ë´ì•¼ í•œë‹¤. í–‰ì´ ëˆ„ì ëœ ë°©í–¥ìœ¼ë¡œ í…ì„œë¥¼ ë³´ê²Œ ë˜ë©´ <code class="language-plaintext highlighter-rouge">tensor([[0, 1, 1]])</code>ì´ ëœë‹¤.</p>

<h3 id="torchstack"><code class="language-plaintext highlighter-rouge">ğŸ“šÂ torch.stack</code></h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
torch.stack
Args:
	tensors(sequence of Tensors): í…ì„œê°€ ë‹´ê¸´ íŒŒì´ì¬ ì‹œí€€ìŠ¤ ê°ì²´
	dim(int): ì¶”ê°€í•  ì°¨ì› ë°©í–¥ì„ ì„¸íŒ…, ê¸°ë³¸ê°’ì€ 0
"""</span>
<span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">tensors</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p>ë§¤ê°œë³€ìˆ˜ë¡œ ì£¼ì–´ì§„ íŒŒì´ì¬ ì‹œí€€ìŠ¤ ê°ì²´(ë¦¬ìŠ¤íŠ¸, íŠœí”Œ)ë¥¼ ì‚¬ìš©ìê°€ ì§€ì •í•œ ìƒˆë¡œìš´ ì°¨ì›ì— ìŒ“ëŠ” ê¸°ëŠ¥ì„ í•œë‹¤. ë§¤ê°œë³€ìˆ˜ <code class="language-plaintext highlighter-rouge">tensors</code> ëŠ” í…ì„œê°€ ë‹´ê¸´ íŒŒì´ì¬ì˜ ì‹œí€€ìŠ¤ ê°ì²´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ”ë‹¤. <code class="language-plaintext highlighter-rouge">dim</code> ì€ ì‚¬ìš©ìê°€ í…ì„œ ì ì¬ë¥¼ í•˜ê³  ì‹¶ì€ ìƒˆë¡œìš´ ì°¨ì›ì„ ì§€ì •í•´ì£¼ë©´ ëœë‹¤. ê¸°ë³¸ê°’ì€ 0ì°¨ì›ìœ¼ë¡œ ì§€ì • ë˜ì–´ìˆìœ¼ë©°, í…ì„œì˜ ë§¨ ì•ì°¨ì›ì´ ìƒˆë¡­ê²Œ ìƒê¸°ê²Œ ëœë‹¤. <code class="language-plaintext highlighter-rouge">torch.stack</code> ì€ ê¸°ê³„í•™ìŠµ, íŠ¹íˆ ë”¥ëŸ¬ë‹ì—ì„œ ì •ë§ ìì£¼ ì‚¬ìš©ë˜ê¸° ë•Œë¬¸ì— ì‚¬ìš©ë²• ë° ì‚¬ìš©ìƒí™©ì„ ìµí˜€ë‘ë©´ ë„ì›€ì´ ëœë‹¤. ì˜ˆì‹œë¥¼ í†µí•´ í•´ë‹¹ ë©”ì„œë“œë¥¼ ì–´ë–¤ ìƒí™©ì—ì„œ ì–´ë–»ê²Œ ì‚¬ìš©í•˜ëŠ”ì§€ ì•Œì•„ë³´ì.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">""" torch.stack example """</span>

<span class="k">class</span> <span class="nc">Projector</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Making projection matrix(Q, K, V) for each attention head
    When you call this class, it returns projection matrix of each attention head
    For example, if you call this class with 8 heads, it returns 8 set of projection matrices (Q, K, V)
    Args:
        num_heads: number of heads in MHA, default 8
        dim_head: dimension of each attention head, default 64
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">dim_head</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Projector</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span> <span class="o">=</span> <span class="n">num_heads</span> <span class="o">*</span> <span class="n">dim_head</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span> <span class="o">=</span> <span class="n">dim_head</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">fc_q</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span><span class="p">)</span>
        <span class="n">fc_k</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span><span class="p">)</span>
        <span class="n">fc_v</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">dim_model</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">dim_head</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fc_q</span><span class="p">,</span> <span class="n">fc_k</span><span class="p">,</span> <span class="n">fc_v</span>

<span class="n">num_heads</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">dim_head</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">projector</span> <span class="o">=</span> <span class="n">Projector</span><span class="p">(</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">dim_head</span><span class="p">)</span>  <span class="c1"># init instance
</span><span class="n">projector_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">projector</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">)]</span>  <span class="c1"># call instance
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span> <span class="c1"># x.shape: [Batch_Size, Sequence_Length, Dim_model]
</span><span class="n">Q</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_heads</span><span class="p">):</span>
    <span class="n">Q</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">projector_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">](</span><span class="n">x</span><span class="p">))</span> <span class="c1"># [10, 512, 64]
</span>    <span class="n">K</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">projector_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">](</span><span class="n">x</span><span class="p">))</span> <span class="c1"># [10, 512, 64]
</span>	  <span class="n">V</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">projector_list</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">))</span> <span class="c1"># [10, 512, 64]
</span> 
<span class="n">Q</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Q.shape: [10, 8, 512, 64]
</span><span class="n">K</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># K.shape: [10, 8, 512, 64]
</span><span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># V.shape: [10, 8, 512, 64]
</span></code></pre></div></div>

<p>ìœ„ ì½”ë“œëŠ” <code class="language-plaintext highlighter-rouge">Transformer</code> ì˜ <code class="language-plaintext highlighter-rouge">Multi-Head Attention</code> êµ¬í˜„ì²´ ì¼ë¶€ë¥¼ ë°œì·Œí•´ì˜¨ ê²ƒì´ë‹¤. <code class="language-plaintext highlighter-rouge">Multi-Head Attention</code> ì€ ê°œë³„ ì–´í…ì…˜ í•´ë“œë³„ë¡œ í–‰ë ¬ $Q, K, V$ë¥¼ ê°€ì ¸ì•¼ í•œë‹¤. ë”°ë¼ì„œ ì…ë ¥ ì„ë² ë”©ì„ ê°œë³„ ì–´í…ì…˜ í—¤ë“œì— <code class="language-plaintext highlighter-rouge">Linear Combination</code> í•´ì¤˜ì•¼ í•˜ëŠ”ë° í—¤ë“œ ê°œìˆ˜ê°€ 8ê°œë‚˜ ë˜ê¸° ë•Œë¬¸ì— ê°œë³„ì ìœ¼ë¡œ <code class="language-plaintext highlighter-rouge">Projection Matrix</code> ë¥¼ ì„ ì–¸í•´ì£¼ëŠ” ê²ƒì€ ë§¤ìš° ë¹„íš¨ìœ¨ì ì´ë‹¤. ë”°ë¼ì„œ ê°ì²´  <code class="language-plaintext highlighter-rouge">Projector</code> ì— í–‰ë ¬ $Q, K, V$ì— ëŒ€í•œ <code class="language-plaintext highlighter-rouge">Projection Matrix</code> ë¥¼ ì •ì˜í•´ì¤¬ë‹¤. ì´í›„ í—¤ë“œ ê°œìˆ˜ë§Œí¼ ê°ì²´  <code class="language-plaintext highlighter-rouge">Projector</code> ë¥¼ í˜¸ì¶œí•´ ë¦¬ìŠ¤íŠ¸ì— í•´ë“œë³„ <code class="language-plaintext highlighter-rouge">Projection Matrix</code> ë¥¼ ë‹´ì•„ì¤€ë‹¤. ê·¸ ë‹¤ìŒ <code class="language-plaintext highlighter-rouge">torch.stack</code>ì„ ì‚¬ìš©í•´ <code class="language-plaintext highlighter-rouge">Attention Head</code> ë°©í–¥ì˜ ì°¨ì›ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ë‚´ë¶€ í…ì„œë“¤ì„ ìŒ“ì•„ì£¼ë©´ ëœë‹¤.</p>

<h3 id="torcharange"><code class="language-plaintext highlighter-rouge">ğŸ”¢Â torch.arange</code></h3>

<p>ì‚¬ìš©ìê°€ ì§€ì •í•œ ì‹œì‘ì ë¶€í„° ëì ê¹Œì§€ ì¼ì •í•œ ê°„ê²©ìœ¼ë¡œ í…ì„œë¥¼ ë‚˜ì—´í•œë‹¤. Pythonì˜ ë‚´ì¥ ë©”ì„œë“œ <code class="language-plaintext highlighter-rouge">range</code>ì™€ ë™ì¼í•œ ì—­í• ì„ í•˜ëŠ”ë°, ëŒ€ì‹  í…ì„œ ê·¸ ê²°ê³¼ë¥¼ í…ì„œ êµ¬ì¡°ì²´ë¡œ ë°˜í™˜í•œë‹¤ê³  ìƒê°í•˜ë©´ ë˜ê² ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.arange usage
</span><span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">0</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span> <span class="mf">1.0000</span><span class="p">,</span>  <span class="mf">1.5000</span><span class="p">,</span>  <span class="mf">2.0000</span><span class="p">])</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">step</code> ë§¤ê°œë³€ìˆ˜ë¡œ ì›ì†Œê°„ ê°„ê²© ì¡°ì •ì„ í•  ìˆ˜ ìˆëŠ”ë°, ê¸°ë³¸ì€ 1ë¡œ ì§€ì • ë˜ì–´ ìˆìœ¼ë‹ˆ ì°¸ê³ í•˜ì. í•„ìì˜ ê²½ìš°ì—ëŠ” <code class="language-plaintext highlighter-rouge">nn.Embedding</code>ì˜ ì…ë ¥ í…ì„œë¥¼ ë§Œë“¤ ë•Œ ê°€ì¥ ë§ì´ ì‚¬ìš©í–ˆë‹¤. <code class="language-plaintext highlighter-rouge">nn.Embedding</code> ì˜ ê²½ìš° Inputìœ¼ë¡œ <code class="language-plaintext highlighter-rouge">IntTensor</code>, <code class="language-plaintext highlighter-rouge">LongTensor</code>ë¥¼ ë°›ê²Œ ë˜ì–´ ìˆìœ¼ë‹ˆ ì•Œì•„ë‘ì.</p>

<h3 id="torchrepeat"><code class="language-plaintext highlighter-rouge">ğŸ”Â torch.repeat</code></h3>

<p>ì…ë ¥ê°’ìœ¼ë¡œ ì£¼ì–´ì§„ í…ì„œë¥¼ ì‚¬ìš©ìê°€ ì§€ì •í•œ ë°˜ë³µ íšŸìˆ˜ë§Œí¼ íŠ¹ì • ì°¨ì› ë°©í–¥ìœ¼ë¡œ ëŠ˜ë¦°ë‹¤. ì˜ˆë¥¼ ë“¤ë©´ <code class="language-plaintext highlighter-rouge">[1,2,3] * 3</code>ì˜ ê²°ê³¼ëŠ” <code class="language-plaintext highlighter-rouge">[1, 2, 3, 1, 2, 3, 1, 2, 3]</code> ì¸ë°, ì´ê²ƒì„ ì‚¬ìš©ìê°€ ì§€ì •í•œ ë°˜ë³µ íšŸìˆ˜ë§Œí¼ íŠ¹ì • ì°¨ì›ìœ¼ë¡œ ìˆ˜í–‰í•˜ê² ë‹¤ëŠ” ê²ƒì´ë‹¤. ì•„ë˜ ì‚¬ìš© ì˜ˆì œë¥¼ í™•ì¸í•´ë³´ì.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.repeat example
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="n">size</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span>

        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
         <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]])</span>
</code></pre></div></div>

<p>$t$ë¥¼ ì–´ë–¤ í…ì„œ êµ¬ì¡°ì²´ $x$ì˜ ìµœëŒ€ ì°¨ì›ì´ë¼ê³  í–ˆì„ , $x_t$ë¥¼ ê°€ì¥ ì™¼ìª½ì— ë„£ê³  ê°€ì¥ ë‚®ì€ ì°¨ì›ì¸ 0ì°¨ì›ì— ëŒ€í•œ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì˜¤ë¥¸ìª½ ëì— ëŒ€ì…í•´ì„œ ì‚¬ìš©í•˜ë©´ ëœë‹¤. (<code class="language-plaintext highlighter-rouge">torch.repeat(</code>$x_t, x_{t-1}, â€¦ x_2, x_1, x_0$<code class="language-plaintext highlighter-rouge">))</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.arange &amp; torch.repeate usage example
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pos_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">num_patches</span> <span class="o">+</span> <span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]).</span><span class="n">to</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">pos_x</span><span class="p">.</span><span class="n">shape</span>
<span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1025</span><span class="p">])</span>
</code></pre></div></div>

<p>í•„ìì˜ ê²½ìš°, <code class="language-plaintext highlighter-rouge">position embedding</code>ì˜ ì…ë ¥ì„ ë§Œë“¤ê³  ì‹¶ì„ ë•Œ <code class="language-plaintext highlighter-rouge">torch.arange</code> ì™€ ì—°ê³„í•´ ìì£¼ ì‚¬ìš© í–ˆë˜ ê²ƒ ê°™ë‹¤. ìœ„ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì.</p>

<h3 id="torchclamp"><code class="language-plaintext highlighter-rouge">ğŸ”¬Â torch.clamp</code></h3>

<p>ì…ë ¥ í…ì„œì˜ ì›ì†Œê°’ì„ ì‚¬ìš©ìê°€ ì§€ì •í•œ ìµœëŒ€â€¢ìµœì†Œê°’ ë²”ìœ„ ì´ë‚´ë¡œ ì œí•œí•˜ëŠ” ë©”ì„œë“œë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.clamp params
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span> <span class="err">â†’</span> <span class="n">Tensor</span>

<span class="c1"># torch.clamp usage example
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">a</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">1.7120</span><span class="p">,</span>  <span class="mf">0.1734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0478</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0922</span><span class="p">])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">0.5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5000</span><span class="p">,</span>  <span class="mf">0.1734</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0478</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0922</span><span class="p">])</span>
</code></pre></div></div>

<p>ì…ë ¥ëœ í…ì„œì˜ ì›ì†Œë¥¼ ì§€ì • ìµœëŒ€â€¢ìµœì†Œ ì„¤ì •ê°’ê³¼ í•˜ë‚˜ í•˜ë‚˜ ëŒ€ì¡°í•´ì„œ í…ì„œ ë‚´ë¶€ì˜ ëª¨ë“  ì›ì†Œê°€ ì§€ì • ë²”ìœ„ ì•ˆì— ë“¤ë„ë¡ ë§Œë“¤ì–´ì¤€ë‹¤. <code class="language-plaintext highlighter-rouge">torch.clamp</code> ì—­ì‹œ ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©ë˜ëŠ”ë°, í•„ìì˜ ê²½ìš° ëª¨ë¸ ë ˆì´ì–´ ì¤‘ê°„ì— ì œê³±ê·¼ì´ë‚˜ ì§€ìˆ˜, ë¶„ìˆ˜ í˜¹ì€ ê°ë„ ê´€ë ¨ ì—°ì‚°ì´ ë“¤ì–´ê°€ <code class="language-plaintext highlighter-rouge">Backward Pass</code>ì—ì„œ <code class="language-plaintext highlighter-rouge">NaN</code>ì´ ë°œìƒí•  ìˆ˜ ìˆëŠ” ê²½ìš°ì— ì•ˆì „ì¥ì¹˜ë¡œ ë§ì´ ì‚¬ìš©í•˜ê³  ìˆë‹¤. (<a href="https://qcqced123.github.io/framework-library/backward-nan/">ìì„¸íˆ ì•Œê³  ì‹¶ë‹¤ë©´ í´ë¦­</a>)</p>

<h3 id="torchgather"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦Â torch.gather</code></h3>

<p>í…ì„œ ê°ì²´ ë‚´ë¶€ì—ì„œ ì›í•˜ëŠ” ì¸ë±ìŠ¤ì— ìœ„ì¹˜í•œ ì›ì†Œë§Œ ì¶”ì¶œí•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ë©´ ë§¤ìš° ìœ ìš©í•œ ë©”ì„œë“œë‹¤. í…ì„œ ì—­ì‹œ <code class="language-plaintext highlighter-rouge">iterable</code> ê°ì²´ë¼ì„œ <code class="language-plaintext highlighter-rouge">loop</code> ë¥¼ ì‚¬ìš©í•´ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ ì§ê´€ì ìœ¼ë¡œ ë³´ì¼ ìˆ˜ ìˆìœ¼ë‚˜, í†µìƒì ìœ¼ë¡œ í…ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ìƒí™©ì´ë¼ë©´ ê°ì²´ì˜ ì°¨ì›ì´ ì–´ë§ˆë¬´ì‹œ í•˜ê¸° ë•Œë¬¸ì— ë£¨í”„ë¡œ ì ‘ê·¼í•´ ê´€ë¦¬í•˜ëŠ” ê²ƒì€ ë§¤ìš° ë¹„íš¨ìœ¨ì ì´ë‹¤. ë£¨í”„ë¥¼ í†µí•´ ì ‘ê·¼í•˜ë©´ íŒŒì´ì¬ì˜ ë‚´ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒê³¼ ë³„ë°˜ ë‹¤ë¥¼ê²Œ ì—†ì–´ì§€ê¸° ë•Œë¬¸ì—, í…ì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ë©”ë¦¬íŠ¸ê°€ ì‚¬ë¼ì§„ë‹¤. ë¹„êµì  í¬ì§€ ì•Šì€ 2~3ì°¨ì›ì˜ í…ì„œ ì •ë„ë¼ë©´ ì‚¬ìš©í•´ë„ í¬ê²Œ ë¬¸ì œëŠ” ì—†ì„ê±°ë¼ ìƒê°í•˜ì§€ë§Œ ê·¸ë˜ë„ ì½”ë“œì˜ ì¼ê´€ì„±ì„ ìœ„í•´ <code class="language-plaintext highlighter-rouge">torch.gather</code> ì‚¬ìš©ì„ ê¶Œì¥í•œë‹¤. ì´ì œ <code class="language-plaintext highlighter-rouge">torch.gather</code>ì˜ ì‚¬ìš©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ì.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.gather params
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">sparse_grad</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">dim</code>ê³¼ <code class="language-plaintext highlighter-rouge">index</code>ì— ì£¼ëª©í•´ë³´ì. ë¨¼ì € <code class="language-plaintext highlighter-rouge">dim</code>ì€ ì‚¬ìš©ìê°€ ì¸ë±ì‹±ì„ ì ìš©í•˜ê³  ì‹¶ì€ ì°¨ì›ì„ ì§€ì •í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. <code class="language-plaintext highlighter-rouge">index</code> ë§¤ê°œë³€ìˆ˜ë¡œ ì „ë‹¬í•˜ëŠ” í…ì„œ ì•ˆì—ëŠ” ì›ì†Œì˜ <code class="language-plaintext highlighter-rouge">â€˜ì¸ë±ìŠ¤â€™</code>ë¥¼ ì˜ë¯¸í•˜ëŠ” ìˆ«ìë“¤ì´ ë§ˆêµ¬ì¡ì´ë¡œ ë‹´ê²¨ìˆëŠ”ë°, í•´ë‹¹ ì¸ë±ìŠ¤ê°€ ëŒ€ìƒ í…ì„œì˜ ì–´ëŠ ì°¨ì›ì„ ê°€ë¦¬í‚¬ ê²ƒì¸ì§€ë¥¼ ì»´í“¨í„°ì—ê²Œ ì•Œë ¤ì¤€ë‹¤ê³  ìƒê°í•˜ë©´ ëœë‹¤. <code class="language-plaintext highlighter-rouge">index</code> ëŠ” ì•ì—ì„œ ì„¤ëª…í–ˆë“¯ì´ ì›ì†Œì˜ <code class="language-plaintext highlighter-rouge">â€˜ì¸ë±ìŠ¤â€™</code>ë¥¼ ì˜ë¯¸í•˜ëŠ” ìˆ«ìë“¤ì´ ë‹´ê¸´ í…ì„œë¥¼ ì…ë ¥ìœ¼ë¡œ í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ë‹¤. ì´ ë•Œ ì£¼ì˜í•  ì ì€ ëŒ€ìƒ í…ì„œ(<code class="language-plaintext highlighter-rouge">input</code>)ì™€ ì¸ë±ìŠ¤ í…ì„œì˜ ì°¨ì› í˜•íƒœê°€ ë°˜ë“œì‹œ ë™ì¼í•´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ì—­ì‹œ ë§ë¡œë§Œ ë“¤ìœ¼ë©´ ì´í•´í•˜ê¸° í˜ë“œë‹ˆ ì‚¬ìš© ì˜ˆì‹œë¥¼ í•¨ê¼ ì‚´í´ë³´ì.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.gather usage example
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">q</span><span class="p">,</span> <span class="n">kr</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span> <span class="c1"># [batch, sequence, dim_head], [batch, 2*sequence, dim_head]
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_c2p</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">kr</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_c2p</span><span class="p">,</span> <span class="n">tmp_c2p</span><span class="p">.</span><span class="n">shape</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">2.6477</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.7478</span><span class="p">,</span> <span class="o">-</span><span class="mf">5.3250</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">1.6062</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.9717</span><span class="p">,</span>  <span class="mf">3.8004</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">0.0662</span><span class="p">,</span>  <span class="mf">1.5240</span><span class="p">,</span>  <span class="mf">0.1182</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.1653</span><span class="p">,</span>  <span class="mf">2.8476</span><span class="p">,</span>  <span class="mf">1.6337</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.5010</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.2267</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1179</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">1.1447</span><span class="p">,</span>  <span class="mf">1.7845</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1493</span><span class="p">],</span>
         <span class="p">...,</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">2.1073</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2149</span><span class="p">,</span> <span class="o">-</span><span class="mf">4.8630</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.8238</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5833</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2066</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.1747</span><span class="p">,</span>  <span class="mf">3.2924</span><span class="p">,</span>  <span class="mf">6.5808</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.2926</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2511</span><span class="p">,</span>  <span class="mf">2.6996</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">2.8362</span><span class="p">,</span>  <span class="mf">2.8700</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9729</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">4.9913</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3616</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">]],</span>
        <span class="n">grad_fn</span><span class="o">=&lt;</span><span class="n">MmBackward0</span><span class="o">&gt;</span><span class="p">)</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">max_seq</span><span class="p">,</span> <span class="n">max_relative_position</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">q_index</span><span class="p">,</span> <span class="n">k_index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_seq</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">max_relative_position</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">q_index</span><span class="p">,</span> <span class="n">k_index</span>
<span class="p">(</span><span class="n">tensor</span><span class="p">([</span>   <span class="mi">0</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">2</span><span class="p">,</span>  <span class="p">...,</span> <span class="mi">1021</span><span class="p">,</span> <span class="mi">1022</span><span class="p">,</span> <span class="mi">1023</span><span class="p">]),</span>
 <span class="n">tensor</span><span class="p">([</span>   <span class="mi">0</span><span class="p">,</span>    <span class="mi">1</span><span class="p">,</span>    <span class="mi">2</span><span class="p">,</span>  <span class="p">...,</span> <span class="mi">1021</span><span class="p">,</span> <span class="mi">1022</span><span class="p">,</span> <span class="mi">1023</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_pos</span> <span class="o">=</span> <span class="n">q_index</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">k_index</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span> <span class="o">=</span> <span class="n">tmp_pos</span> <span class="o">+</span> <span class="n">max_relative_position</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span>
<span class="n">tensor</span><span class="p">([[</span> <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mi">509</span><span class="p">,</span> <span class="o">-</span><span class="mi">510</span><span class="p">,</span> <span class="o">-</span><span class="mi">511</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mi">508</span><span class="p">,</span> <span class="o">-</span><span class="mi">509</span><span class="p">,</span> <span class="o">-</span><span class="mi">510</span><span class="p">],</span>
        <span class="p">[</span> <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mi">507</span><span class="p">,</span> <span class="o">-</span><span class="mi">508</span><span class="p">,</span> <span class="o">-</span><span class="mi">509</span><span class="p">],</span>
        <span class="p">...,</span>
        <span class="p">[</span><span class="mi">1533</span><span class="p">,</span> <span class="mi">1532</span><span class="p">,</span> <span class="mi">1531</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1534</span><span class="p">,</span> <span class="mi">1533</span><span class="p">,</span> <span class="mi">1532</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1535</span><span class="p">,</span> <span class="mi">1534</span><span class="p">,</span> <span class="mi">1533</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">]])</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">rel_pos_matrix</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">max_relative_position</span> <span class="o">-</span> <span class="mi">1</span><span class="p">).</span><span class="n">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">tmp_c2p</span> <span class="o">=</span> <span class="n">tmp_c2p</span><span class="p">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">rel_pos_matrix</span><span class="p">,</span> <span class="n">rel_pos_matrix</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tmp_c2p</span><span class="p">.</span><span class="n">shape</span> 
<span class="p">(</span><span class="n">tensor</span><span class="p">([[[</span> <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">...,</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">]],</span>
 
         <span class="p">[[</span> <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">[</span> <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="p">...,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">,</span>    <span class="mi">0</span><span class="p">],</span>
          <span class="p">...,</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">,</span>  <span class="mi">510</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">,</span>  <span class="mi">511</span><span class="p">],</span>
          <span class="p">[</span><span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span> <span class="mi">1023</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mi">514</span><span class="p">,</span>  <span class="mi">513</span><span class="p">,</span>  <span class="mi">512</span><span class="p">]],</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]),</span>
<span class="n">torch</span><span class="p">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">]))</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">torch</span><span class="p">.</span><span class="n">gather</span><span class="p">(</span><span class="n">tmp_c2p</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rel_pos_matrix</span><span class="p">)</span>
<span class="n">tensor</span><span class="p">([[[</span><span class="o">-</span><span class="mf">0.8579</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2178</span><span class="p">,</span>  <span class="mf">1.6323</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">2.6477</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6477</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.6477</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">1.1601</span><span class="p">,</span>  <span class="mf">2.1752</span><span class="p">,</span>  <span class="mf">0.7187</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.0662</span><span class="p">,</span>  <span class="mf">0.0662</span><span class="p">,</span>  <span class="mf">0.0662</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">3.4379</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2573</span><span class="p">,</span>  <span class="mf">0.1375</span><span class="p">,</span>  <span class="p">...,</span> <span class="o">-</span><span class="mf">0.5010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5010</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5010</span><span class="p">],</span>
         <span class="p">...,</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">1.2066</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2066</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.2066</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.5943</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5169</span><span class="p">,</span> <span class="o">-</span><span class="mf">3.0820</span><span class="p">],</span>
         <span class="p">[</span> <span class="mf">2.6996</span><span class="p">,</span>  <span class="mf">2.6996</span><span class="p">,</span>  <span class="mf">2.6996</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">0.2014</span><span class="p">,</span>  <span class="mf">1.1458</span><span class="p">,</span>  <span class="mf">3.2626</span><span class="p">],</span>
         <span class="p">[</span><span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1708</span><span class="p">,</span>  <span class="p">...,</span>  <span class="mf">1.9955</span><span class="p">,</span>  <span class="mf">4.1549</span><span class="p">,</span>  <span class="mf">2.6356</span><span class="p">]],</span>
</code></pre></div></div>

<p>ìœ„ ì½”ë“œëŠ” <code class="language-plaintext highlighter-rouge">DeBERTa</code> ì˜ <code class="language-plaintext highlighter-rouge">Disentangled Self-Attention</code>ì„ êµ¬í˜„í•œ ì½”ë“œì˜ ì¼ë¶€ë¶„ì´ë‹¤. ìì„¸í•œ ì›ë¦¬ëŠ” <code class="language-plaintext highlighter-rouge">DeBERTa</code> ë…¼ë¬¸ ë¦¬ë·° í¬ìŠ¤íŒ…ì—ì„œ í™•ì¸í•˜ë©´ ë˜ê³ , ìš°ë¦¬ê°€ ì§€ê¸ˆ ì£¼ëª©í•  ë¶€ë¶„ì€ ë°”ë¡œ <code class="language-plaintext highlighter-rouge">tmp_c2p</code>, <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> ê·¸ë¦¬ê³  ë§ˆì§€ë§‰ ì¤„ì— ìœ„ì¹˜í•œ <code class="language-plaintext highlighter-rouge">torch.gather</code> ë‹¤. <code class="language-plaintext highlighter-rouge">[10, 1024, 1024]</code> ëª¨ì–‘ì„ ê°€ì§„ ëŒ€ìƒ í…ì„œ <code class="language-plaintext highlighter-rouge">tmp_c2p</code> ì—ì„œ ë‚´ê°€ ì›í•˜ëŠ” ì›ì†Œë§Œ ì¶”ì¶œí•˜ë ¤ëŠ” ìƒí™©ì¸ë°, ì¶”ì¶œí•´ì•¼í•  ì›ì†Œì˜ ì¸ë±ìŠ¤ ê°’ì´ ë‹´ê¸´ í…ì„œë¥¼ <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> ë¡œ ì •ì˜í–ˆë‹¤. <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> ì˜ ì°¨ì›ì€ <code class="language-plaintext highlighter-rouge">[10, 1024, 1024]</code>ë¡œ <code class="language-plaintext highlighter-rouge">tmp_c2p</code>ì™€ ë™ì¼í•˜ë‹¤. ì°¸ê³ ë¡œ ì¶”ì¶œí•´ì•¼ í•˜ëŠ” ì°¨ì› ë°©í–¥ì€ ê°€ë¡œ ë°©í–¥(ë‘ ë²ˆì§¸ 1024)ì´ë‹¤.</p>

<p>ì´ì œ <code class="language-plaintext highlighter-rouge">torch.gather</code>ì˜ ë™ì‘ì„ ì‚´í´ë³´ì. ìš°ë¦¬ê°€ í˜„ì¬ ì¶”ì¶œí•˜ê³  ì‹¶ì€ ëŒ€ìƒì€ 3ì°¨ì› í…ì„œì˜ ê°€ë¡œ ë°©í–¥(ë‘ ë²ˆì§¸ 1024, í…ì„œì˜ í–‰ ë²¡í„°), ì¦‰ <code class="language-plaintext highlighter-rouge">2 * max_sequence_length</code> ë¥¼ ì˜ë¯¸í•˜ëŠ” ì°¨ì› ë°©í–¥ì˜ ì›ì†Œë‹¤. ë”°ë¼ì„œ <code class="language-plaintext highlighter-rouge">dim=-1</code>ìœ¼ë¡œ ì„¤ì •í•´ì¤€ë‹¤. ì´ì œ ë©”ì„œë“œê°€ ì˜ë„ëŒ€ë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ì. <code class="language-plaintext highlighter-rouge">rel_pos_matrix</code> ì˜ 0ë²ˆ ë°°ì¹˜, 0ë²ˆì§¸ ì‹œí€€ìŠ¤ì˜ ê°€ì¥ ë§ˆì§€ë§‰ ì°¨ì›ì˜ ê°’ì€ <code class="language-plaintext highlighter-rouge">0</code>ìœ¼ë¡œ ì´ˆê¸°í™” ë˜ì–´ ìˆë‹¤. ë‹¤ì‹œ ë§í•´, ëŒ€ìƒ í…ì„œì˜ ëŒ€ìƒ ì°¨ì›ì—ì„œ 0ë²ˆì§¸ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ê°€ì ¸ì˜¤ë¼ëŠ” ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆë‹¤. ê·¸ë ‡ë‹¤ë©´ <code class="language-plaintext highlighter-rouge">torch.gather</code> ì‹¤í–‰ ê²°ê³¼ê°€ <code class="language-plaintext highlighter-rouge">tmp_c2p</code>ì˜ 0ë²ˆ ë°°ì¹˜, 0ë²ˆì§¸ ì‹œí€€ìŠ¤ì˜ 0ë²ˆì§¸ ì°¨ì› ê°’ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ì. ë‘˜ ë‹¤ <code class="language-plaintext highlighter-rouge">-2.6477</code>, <code class="language-plaintext highlighter-rouge">-2.6477</code> ìœ¼ë¡œ ê°™ì€ ê°’ì„ ë‚˜íƒ€ë‚´ê³  ìˆë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ ì˜ë„ëŒ€ë¡œ ì˜ ì‹¤í–‰ë˜ì—ˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>

<h3 id="torchtriu-torchtril"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦Â torch.triu, torch.tril</code></h3>

<p>ê°ê° ì…ë ¥ í…ì„œë¥¼ <code class="language-plaintext highlighter-rouge">ìƒì‚¼ê°í–‰ë ¬</code>, <code class="language-plaintext highlighter-rouge">í•˜ì‚¼ê°í–‰ë ¬</code>ë¡œ ë§Œë“ ë‹¤. <code class="language-plaintext highlighter-rouge">triu</code>ë‚˜ <code class="language-plaintext highlighter-rouge">tril</code>ì€ ì‚¬ì‹¤ ë’¤ì§‘ìœ¼ë©´ ê°™ì€ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì— <code class="language-plaintext highlighter-rouge">tril</code>ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…ì„ í•˜ê² ë‹¤. ë©”ì„œë“œì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.triu, tril params
</span><span class="n">upper_tri_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">triu</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">lower_tri_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">,</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">diagonal</code> ì— ì£¼ëª©í•´ë³´ì. ì–‘ìˆ˜ë¥¼ ì „ë‹¬í•˜ë©´ ì£¼ëŒ€ê°ì„±ë¶„ì—ì„œ í•´ë‹¹í•˜ëŠ” ê°’ë§Œí¼ ë–¨ì–´ì§„ ê³³ì˜ ëŒ€ê°ì„±ë¶„ê¹Œì§€ ê·¸ ê°’ì„ ì‚´ë ¤ë‘”ë‹¤. í•œí¸ ìŒìˆ˜ë¥¼ ì „ë‹¬í•˜ë©´ ì£¼ëŒ€ê°ì„±ë¶„ì„ í¬í•¨í•´ ì£¼ì–´ì§„ ê°’ë§Œí¼ ë–¨ì–´ì§„ ê³³ê¹Œì§€ì˜ ëŒ€ê°ì„±ë¶„ì„ ëª¨ë‘ 0ìœ¼ë¡œ ë§Œë“¤ì–´ë²„ë¦°ë‹¤. ê¸°ë³¸ì€ 0ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” ì£¼ëŒ€ê°ì„±ë¶„ë¶€í„° ì™¼ìª½ í•˜ë‹¨ì˜ ì›ì†Œë¥¼ ëª¨ë‘ ì‚´ë ¤ë‘ê² ë‹¤ëŠ” ì˜ë¯¸ê°€ ëœë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.tril usage example
</span><span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span>
</code></pre></div></div>

<p>ë‘ ë©”ì„œë“œëŠ” ì„ í˜•ëŒ€ìˆ˜í•™ì´ í•„ìš”í•œ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ”ë°, í•„ìì˜ ê²½ìš°, <code class="language-plaintext highlighter-rouge">GPT</code>ì²˜ëŸ¼ <code class="language-plaintext highlighter-rouge">Transformer</code>ì˜ <code class="language-plaintext highlighter-rouge">Decoder</code> ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì„ ë¹Œë“œí•  ë•Œ ê°€ì¥ ë§ì´ ì‚¬ìš©í–ˆë˜ ê²ƒ ê°™ë‹¤. <code class="language-plaintext highlighter-rouge">Decoder</code>ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì€ ëŒ€ë¶€ë¶„ êµ¬ì¡°ìƒ <code class="language-plaintext highlighter-rouge">Language Modeling</code>ì„ ìœ„í•´ì„œ <code class="language-plaintext highlighter-rouge">Masked Multi-Head Self-Attention Block</code>ì„ ì‚¬ìš©í•˜ëŠ”ë° ì´ ë•Œ ë¯¸ë˜ ì‹œì ì˜ í† í° ì„ë² ë”© ê°’ì— ë§ˆìŠ¤í‚¹ì„ í•´ì£¼ê¸° ìœ„í•´ <code class="language-plaintext highlighter-rouge">torch.tril</code> ì„ ì‚¬ìš©í•˜ê²Œ ë˜ë‹ˆ ì°¸ê³ í•˜ì.</p>

<h3 id="torchtensormasked_fill"><code class="language-plaintext highlighter-rouge">ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦Â torch.Tensor.masked_fill</code></h3>

<p>ì‚¬ìš©ìê°€ ì§€ì •í•œ ê°’ì— í•´ë‹¹ë˜ëŠ” ì›ì†Œë¥¼ ëª¨ë‘ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬í•´ì£¼ëŠ” ë©”ì„œë“œë‹¤. ë¨¼ì € ë§¤ê°œë³€ìˆ˜ë¥¼ í™•ì¸í•´ë³´ì.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.Tensor.masked_fill params
</span><span class="n">input_tensors</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
<span class="n">input_tensors</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span><span class="p">:</span> <span class="n">BoolTensor</span><span class="p">,</span> <span class="n">value</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span>
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">masked_fill</code> ì€ í…ì„œ ê°ì²´ì˜ ë‚´ë¶€ <code class="language-plaintext highlighter-rouge">attribute</code> ë¡œ ì •ì˜ë˜ê¸° ë•Œë¬¸ì— í•´ë‹¹ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ë‹¤ë©´ ë¨¼ì € ë§ˆìŠ¤í‚¹ ëŒ€ìƒ í…ì„œë¥¼ ë§Œë“¤ì–´ì•¼ í•œë‹¤. í…ì„œë¥¼ ì •ì˜í–ˆë‹¤ë©´ í…ì„œ ê°ì²´ì˜ <code class="language-plaintext highlighter-rouge">attributes</code> ì ‘ê·¼ì„ í†µí•´ <code class="language-plaintext highlighter-rouge">masked_fill()</code> ì„ í˜¸ì¶œí•œ ë’¤, í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì „ë‹¬í•´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ë©´ ëœë‹¤.</p>

<p><code class="language-plaintext highlighter-rouge">mask</code> ë§¤ê°œë³€ìˆ˜ì—ëŠ” ë§ˆìŠ¤í‚¹ í…ì„œë¥¼ ì „ë‹¬í•´ì•¼ í•˜ëŠ”ë°, ì´ ë•Œ ë‚´ë¶€ ì›ì†ŒëŠ” ëª¨ë‘ <code class="language-plaintext highlighter-rouge">boolean</code>ì´ì–´ì•¼ í•˜ê³  í…ì„œì˜ í˜•íƒœëŠ” ëŒ€ìƒ í…ì„œì™€ ë™ì¼í•´ì•¼ í•œë‹¤(ì™„ì „íˆ ê°™ì„ í•„ìš”ëŠ” ì—†ê³ , ë¸Œë¡œë“œ ìºìŠ¤íŒ…ë§Œ ê°€ëŠ¥í•˜ë©´ ìƒê´€ ì—†ìŒ).</p>

<p><code class="language-plaintext highlighter-rouge">value</code> ë§¤ê°œë³€ìˆ˜ì—ëŠ” ë§ˆìŠ¤í‚¹ ëŒ€ìƒ ì›ì†Œë“¤ì— ì¼ê´„ì ìœ¼ë¡œ ì ìš©í•´ì£¼ê³  ì‹¶ì€ ê°’ì„ ì „ë‹¬í•œë‹¤. ì´ê²Œ ë§ë¡œë§Œ ë“¤ìœ¼ë©´ ì´í•´í•˜ê¸° ì‰½ì§€ ì•Šë‹¤. ì•„ë˜ ì‚¬ìš© ì˜ˆì‹œë¥¼ í•¨ê»˜ ì²¨ë¶€í–ˆìœ¼ë‹ˆ ì°¸ê³  ë°”ë€ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># torch.masked_fill usage
</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">lm_mask</span>
<span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span> <span class="mi">0</span>
<span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="mi">0</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">k</span><span class="p">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">dot_scale</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">1.2</span> <span class="mf">1.1</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="mf">9.9</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="mf">9.9</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="mf">9.9</span>

<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span> <span class="o">=</span> <span class="n">attention_matrix</span><span class="p">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">lm_mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s">'-inf'</span><span class="p">))</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">attention_matrix</span>
<span class="mf">1.22</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span>
<span class="mf">1.22</span> <span class="mf">2.1</span> <span class="mf">3.4</span> <span class="mf">9.9</span> <span class="o">-</span><span class="n">inf</span>
</code></pre></div></div>

<h3 id="ï¸torchclone"><code class="language-plaintext highlighter-rouge">ğŸ—‚ï¸Â torch.clone</code></h3>

<p><code class="language-plaintext highlighter-rouge">inputs</code> ì¸ìë¡œ ì „ë‹¬í•œ í…ì„œë¥¼ ë³µì‚¬í•˜ëŠ” íŒŒì´í† ì¹˜ ë‚´ì¥ ë©”ì„œë“œë‹¤.  ì‚¬ìš©ë²•ì€ ì•„ë˜ì™€ ê°™ë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">""" torch.clone """</span>
<span class="n">torch</span><span class="p">.</span><span class="n">clone</span><span class="p">(</span>
    <span class="nb">input</span><span class="p">,</span><span class="err">Â </span>
    <span class="o">*</span><span class="p">,</span>
   <span class="err">Â </span><span class="n">memory_format</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">preserve_format</span>
<span class="p">)</span><span class="err">Â â†’Â </span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>
</code></pre></div></div>

<p>ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì„ ë§Œë“¤ë‹¤ ë³´ë©´ ë§ì´ ì‚¬ìš©í•˜ê²Œ ë˜ëŠ” ê¸°ë³¸ì ì¸ ë©”ì„œë“œì¸ë°, ì´ë ‡ê²Œ ë”°ë¡œ ì •ë¦¬í•˜ê²Œ ëœ ì´ìœ ê°€ ìˆë‹¤. ì…ë ¥ëœ í…ì„œë¥¼ ê·¸ëŒ€ë¡œ ë³µì‚¬í•œë‹¤ëŠ” íŠ¹ì„± ë•Œë¬¸ì— ì‚¬ìš©ì‹œ ì£¼ì˜í•´ì•¼ í•  ì ì´ ìˆê¸° ë•Œë¬¸ì´ë‹¤. í•´ë‹¹ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì…ë ¥í•  í…ì„œê°€ í˜„ì¬ ì–´ëŠ ë””ë°”ì´ìŠ¤(CPU, GPU) ìœ„ì— ìˆëŠ”ì§€, ê·¸ë¦¬ê³  í•´ë‹¹ í…ì„œê°€ ê³„ì‚° ê·¸ë˜í”„ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ë¥¼ <strong>ë°˜ë“œì‹œ</strong> íŒŒì•…í•´ì•¼ í•œë‹¤.</p>

<p>í•„ìëŠ” ELECTRA ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ëŠ” ê³¼ì •ì—ì„œ <code class="language-plaintext highlighter-rouge">clone()</code> ë©”ì„œë“œë¥¼ ì‚¬ìš©í–ˆëŠ”ë°, Generator ëª¨ë¸ì˜ ê²°ê³¼ ë¡œì§“ì„ Discriminatorì˜ ì…ë ¥ìœ¼ë¡œ ë³€í™˜í•´ì£¼ê¸° ìœ„í•¨ì´ì—ˆë‹¤. ê·¸ ê³¼ì •ì—ì„œ Generatorê°€ ë°˜í™˜í•œ ë¡œì§“ì„ ê·¸ëŒ€ë¡œ <code class="language-plaintext highlighter-rouge">clone</code>í•œ ë’¤, ì…ë ¥ì„ ë§Œë“¤ì–´ ì£¼ì—ˆê³  ê·¸ ê²°ê³¼ ì•„ë˜ì™€ ê°™ì€ ì—ëŸ¬ë¥¼ ë§ˆì£¼í–ˆë‹¤.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">RuntimeError</span><span class="p">:</span> <span class="n">one</span> <span class="n">of</span> <span class="n">the</span> <span class="n">variables</span> <span class="n">needed</span> <span class="k">for</span> <span class="n">gradient</span> <span class="n">computation</span> <span class="n">has</span> <span class="n">been</span> <span class="n">modified</span> <span class="n">by</span> <span class="n">an</span> <span class="n">inplace</span> <span class="n">operation</span><span class="p">:</span> <span class="p">[</span>
<span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="n">LongTensor</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">511</span><span class="p">]]</span> <span class="ow">is</span> <span class="n">at</span> <span class="n">version</span> <span class="mi">1</span><span class="p">;</span> <span class="n">expected</span> <span class="n">version</span> <span class="mi">0</span> 
<span class="n">instead</span><span class="p">.</span> <span class="n">Hint</span><span class="p">:</span> <span class="n">the</span> <span class="n">backtrace</span> <span class="n">further</span> <span class="n">above</span> <span class="n">shows</span> <span class="n">the</span> <span class="n">operation</span> <span class="n">that</span> <span class="n">failed</span> <span class="n">to</span> <span class="n">compute</span> <span class="n">its</span> <span class="n">gradient</span><span class="p">.</span> 
<span class="n">The</span> <span class="n">variable</span> <span class="ow">in</span> <span class="n">question</span> <span class="n">was</span> <span class="n">changed</span> <span class="ow">in</span> <span class="n">there</span> <span class="ow">or</span> <span class="n">anywhere</span> <span class="n">later</span><span class="p">.</span> <span class="n">Good</span> <span class="n">luck</span><span class="err">!</span>
</code></pre></div></div>

<p>ì—ëŸ¬ ë¡œê·¸ë¥¼ ìì„¸íˆ ì½ì–´ë³´ë©´ í…ì„œ ë²„ì „ì˜ ë³€ê²½ìœ¼ë¡œ ì¸í•´ ê·¸ë¼ë””ì–¸íŠ¸ ê³„ì‚°ì´ ë¶ˆê°€í•˜ë‹¤ëŠ” ë‚´ìš©ì´ ë‹´ê²¨ìˆë‹¤. êµ¬ê¸€ë§í•´ë´ë„ ì˜ ì•ˆë‚˜ì™€ì„œ í¬ê¸°í•˜ë ¤ë˜ ì°°ë¼ì— ìš°ì—°íˆ <code class="language-plaintext highlighter-rouge">torch.clone()</code> ë©”ì„œë“œì˜ ì •í™•í•œ ì‚¬ìš©ë²•ì´ ê¶ê¸ˆí•´ ê³µì‹ Docsë¥¼ ì½ê²Œ ë˜ì—ˆê³ , ê±°ê¸°ì„œ ì—„ì²­ë‚œ ì‚¬ì‹¤ì„ ë°œê²¬í–ˆë‹¤. <code class="language-plaintext highlighter-rouge">clone()</code> ë©”ì„œë“œê°€ ì…ë ¥ëœ í…ì„œì˜ í˜„ì¬ ë””ë°”ì´ìŠ¤ ìœ„ì¹˜ì— ë˜‘ê°™ì´ ë³µì‚¬ë  ê²ƒì´ë€ ì˜ˆìƒì€ í–ˆì§€ë§Œ, ì…ë ¥ í…ì„œì˜ ê³„ì‚°ê·¸ë˜í”„ê¹Œì§€ ë³µì‚¬ë  ê²ƒì´ë€ ìƒê°ì€ ì „í˜€ í•˜ì§€ ëª»í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ë˜ì„œ ìœ„ì™€ ê°™ì€ ì—ëŸ¬ë¥¼ ë§ˆì£¼í•˜ì§€ ì•Šìœ¼ë ¤ë©´, <code class="language-plaintext highlighter-rouge">clone()</code>ì„ í˜¸ì¶œí•  ë•Œ ë’¤ì— ë°˜ë“œì‹œ <code class="language-plaintext highlighter-rouge">detach()</code>ë¥¼ í•¨ê»˜ í˜¸ì¶œí•´ì¤˜ì•¼ í•œë‹¤.</p>

<p><code class="language-plaintext highlighter-rouge">clone()</code> ë©”ì„œë“œëŠ” ì…ë ¥ëœ í…ì„œì˜ ëª¨ë“  ê²ƒì„ ë³µì‚¬í•œë‹¤ëŠ” ì ì„ ë°˜ë“œì‹œ ê¸°ì–µí•˜ì.</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#linear-algebra" class="page__taxonomy-item p-category" rel="tag">Linear Algebra</a><span class="sep">, </span>
    
      <a href="/tags/#pytorch" class="page__taxonomy-item p-category" rel="tag">Pytorch</a><span class="sep">, </span>
    
      <a href="/tags/#tensor" class="page__taxonomy-item p-category" rel="tag">Tensor</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#framework-library" class="page__taxonomy-item p-category" rel="tag">Framework & Library</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-01-09">January 9, 2024</time></p>

      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=%F0%9F%94%A5%C2%A0Pytorch+Tensor+Indexing+%EC%9E%90%EC%A3%BC+%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94+%EB%A9%94%EC%84%9C%EB%93%9C+%EB%AA%A8%EC%9D%8C%EC%A7%91%20http%3A%2F%2Flocalhost%3A4000%2Fframework-library%2Ftorch-indexing-function" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fframework-library%2Ftorch-indexing-function" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fframework-library%2Ftorch-indexing-function" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/optimization-theory/product_quotient_rule" class="pagination--pager" title="ğŸ”¢Â Product &amp; Quotient Rule: ê³±ì˜ ë¯¸ë¶„, ëª«ì˜ ë¯¸ë¶„
">Previous</a>
    
    
      <a href="/ps/baekjoon-1987" class="pagination--pager" title="ğŸ‘©â€ğŸ’»ğŸ„ [baekjoon] 1987ë²ˆ: ì•ŒíŒŒë²³
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You may also enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/lora" rel="permalink">ğŸ”ª [LoRA] Low-Rank Adaptation of Large Language Models
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          12 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 28 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">LoRA Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/time_complexity2" rel="permalink">ğŸ‘¨â°ğŸÂ [Python] ì‹œê°„ë³µì¡ë„ 2
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          4 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 26 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ì‹œê°„ ë³µì¡ë„ ì¤„ì´ê¸°
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/python/time_complexity1" rel="permalink">ğŸ‘¨â°ğŸÂ [Python] ì‹œê°„ë³µì¡ë„ 1
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 26 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">ì‹œê°„ ë³µì¡ë„ì— ëŒ€í•œ ì´í•´
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/huggingface_emoji.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/nlp/linear_attention" rel="permalink">ğŸŒ† [Linear Attention] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention
</a>
      
    </h2>
    <!-- 

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          8 minute read
        
      </span>
    
  </p>

 -->
    
      <p class="page__meta"><i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i> March 14 2024</p>
    
    <p class="archive__item-excerpt" itemprop="description">Linear Attention Official Paper Review with Pytorch Implementation
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 qcqced. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>







    <script>
  'use strict';

  (function() {
    var commentContainer = document.querySelector('#utterances-comments');

    if (!commentContainer) {
      return;
    }

    var script = document.createElement('script');
    script.setAttribute('src', 'https://utteranc.es/client.js');
    script.setAttribute('repo', 'qcqced123/qcqced123.github.io');
    script.setAttribute('issue-term', 'pathname');
    
    script.setAttribute('theme', 'github-light');
    script.setAttribute('crossorigin', 'anonymous');

    commentContainer.appendChild(script);
  })();
</script>

  




<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
});
</script>

  </body>
</html>
